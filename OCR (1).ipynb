{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e103db5-e08c-4c2b-a01d-8f4e13253246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "from filelock import FileLock\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def click_and_select_all(url: str,\n",
    "                         processed_file: str,\n",
    "                         scraper_id: int,\n",
    "                         num_scrapers: int):\n",
    "    # Initialize file lock for safe concurrent access\n",
    "    lock = FileLock(processed_file + \".lock\")\n",
    "    if not os.path.exists(processed_file):\n",
    "        with lock:\n",
    "            with open(processed_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f)\n",
    "\n",
    "    # Setup headless Chrome\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        total = len(driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\"))\n",
    "\n",
    "        for idx in range(total):\n",
    "            # Distribute work among scrapers\n",
    "            if idx % num_scrapers != scraper_id:\n",
    "                continue\n",
    "\n",
    "            items = driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\")\n",
    "            if idx >= len(items):\n",
    "                total = len(items)\n",
    "                if idx >= total:\n",
    "                    break\n",
    "\n",
    "            item = items[idx]\n",
    "            name = item.text.strip()\n",
    "\n",
    "            # Check if already processed\n",
    "            with lock:\n",
    "                with open(processed_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    processed = json.load(f)\n",
    "            if name in processed:\n",
    "                print(f\"[{idx+1}/{total}] Skipping processed: {name}\")\n",
    "                continue\n",
    "\n",
    "            # Scroll into view and click\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", item)\n",
    "            time.sleep(0.5)\n",
    "            print(f\"[{idx+1}/{total}] Processing: {name}\")\n",
    "            item.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Click fit-height icon if present\n",
    "            try:\n",
    "                fit_btn = driver.find_element(By.CLASS_NAME, \"rc-fit-height-icon\")\n",
    "                fit_btn.click()\n",
    "                time.sleep(0.5)\n",
    "            except Exception:\n",
    "                print(\"  ⚠️ Fit-height icon not found, continuing\")\n",
    "\n",
    "            # Iterate through select options\n",
    "            select_elem = driver.find_element(By.ID, \"rc-page-select\")\n",
    "            select = Select(select_elem)\n",
    "            for opt_idx, opt in enumerate(select.options):\n",
    "                select.select_by_index(opt_idx)\n",
    "                option_text = opt.text.strip()\n",
    "                print(f\"    Selecting option: {option_text}\")\n",
    "                time.sleep(1.6)\n",
    "\n",
    "                # Capture the tile surface as PNG\n",
    "                try:\n",
    "                    surface = driver.find_element(By.CLASS_NAME, \"rc-ti-tile-surface\")\n",
    "                    safe_name = re.sub(r\"[^\\w\\- ]\", \"\", name).strip()\n",
    "                    safe_opt = re.sub(r\"[^\\w\\- ]\", \"\", option_text).strip().replace(\" \", \"_\")\n",
    "                    out_dir = os.path.join(os.getcwd(), \"proj_data2\", safe_name)\n",
    "                    os.makedirs(out_dir, exist_ok=True)\n",
    "                    file_path = os.path.join(out_dir, f\"{safe_opt}.png\")\n",
    "                    surface.screenshot(file_path)\n",
    "                    print(f\"      Saved screenshot: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"      ⚠️ Failed to capture surface: {e}\")\n",
    "\n",
    "            # Navigate back to the main listing\n",
    "            driver.back()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Mark as processed\n",
    "            with lock:\n",
    "                with open(processed_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    \n",
    "                    processed = json.load(f)\n",
    "                processed.append(name)\n",
    "                with open(processed_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(processed, f, indent=2)\n",
    "\n",
    "        print(f\"All done for scraper {scraper_id}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7d566-107b-4d63-a5a4-0b7be421948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    URL = \"https://box2.nmtvault.com/Hennepin2/jsp/RcWebSearchResults.jsp?result_start=0&result_items=48&result_layout=GRID&result_sort=Publication%20Date&collection1=7083e412-1de2-42fe-b070-7f82e5c869a4&query1_modifier=AND&query1_field=DATE_PUBLISHED_MILLIS&query1_min=-915148800000&query1_max=-631152000000\"\n",
    "    PROCESSED_FILE = \"processed_items.json\"\n",
    "    NUM_SCRAPERS = 6\n",
    "\n",
    "    threads = []\n",
    "    for i in range(NUM_SCRAPERS):\n",
    "        t = threading.Thread(\n",
    "            target=click_and_select_all,\n",
    "            args=(URL, PROCESSED_FILE, i, NUM_SCRAPERS),\n",
    "            daemon=True\n",
    "        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    # Wait for all threads to finish\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    print(\"All scrapers have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e34c7b-9917-4129-828c-1c153a301041",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f087ef-0546-41fb-9ef2-02174c19c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-cloud-vision google-auth tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adc5a0-b7f4-4f17-888f-e73a05905294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── Text Parsing ───────────────────────────────────────────────────────────\n",
    "\n",
    "def parse_entry(entry_text: str, year: int) -> dict:\n",
    "    txt = re.sub(r'\\s+', ' ', entry_text).strip()\n",
    "    m = re.match(r'^(?P<name>[^,]+)', txt)\n",
    "    name = m.group('name').strip() if m else None\n",
    "    rest = txt[len(name):].strip(' ,') if name else txt\n",
    "    parts = [p.strip() for p in rest.split(',') if p.strip()]\n",
    "\n",
    "    spouse = address = residence = occupation = employer = None\n",
    "    for part in parts:\n",
    "        low = part.lower()\n",
    "        if low.startswith('w. '):\n",
    "            spouse = part[3:].strip()\n",
    "        elif low.startswith(('h. ', 'res. ')):\n",
    "            ind, _, addr = part.partition(' ')\n",
    "            residence = ind.rstrip('.')\n",
    "            address = addr or None\n",
    "        elif ' at ' in low:\n",
    "            occ, emp = re.split(r' at ', part, flags=re.I, maxsplit=1)\n",
    "            occupation, employer = occ.strip(), emp.strip()\n",
    "        elif not address:\n",
    "            address = part\n",
    "        else:\n",
    "            occupation = (occupation + '; ' + part) if occupation else part\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"spouse\": spouse,\n",
    "        \"address\": address,\n",
    "        \"residence_indicator\": residence,\n",
    "        \"occupation\": occupation,\n",
    "        \"employer\": employer,\n",
    "        \"year\": year\n",
    "    }\n",
    "\n",
    "# ─── OCR via Google Cloud Vision ────────────────────────────────────────────\n",
    "\n",
    "def ocr_with_gcv(image_path: Path, client: vision.ImageAnnotatorClient) -> str:\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        content = img_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise RuntimeError(f\"GCV error: {response.error.message}\")\n",
    "    return response.full_text_annotation.text\n",
    "\n",
    "# ─── Folder Processing ──────────────────────────────────────────────────────\n",
    "\n",
    "def process_year_folder(folder: Path, year: int, client: vision.ImageAnnotatorClient):\n",
    "    entries = []\n",
    "    for img_file in tqdm(sorted(folder.iterdir()), desc=f\"Year {year}\"):\n",
    "        if img_file.suffix.lower() not in ('.png', '.jpg', '.jpeg', '.tif'):\n",
    "            continue\n",
    "        raw = ocr_with_gcv(img_file, client)\n",
    "        chunks = [chunk for chunk in raw.split('\\n\\n') if chunk.strip()]\n",
    "        for chunk in chunks:\n",
    "            entries.append(parse_entry(chunk, year))\n",
    "    return entries\n",
    "\n",
    "# ─── Main Pipeline ───────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    DATA_ROOT = Path(\"proj_data\")      \n",
    "    OUT_FILE  = \"residents_gcv.json\"\n",
    "\n",
    "    # Initialize Google Cloud Vision client\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "    )\n",
    "    client = vision.ImageAnnotatorClient(credentials=creds)\n",
    "\n",
    "    all_records = []\n",
    "    year_pattern = re.compile(r'(\\d{4})$')\n",
    "\n",
    "    for subdir in sorted(DATA_ROOT.iterdir()):\n",
    "        if not subdir.is_dir():\n",
    "            continue\n",
    "        m = year_pattern.search(subdir.name)\n",
    "        if not m:\n",
    "            print(f\"Skipping folder (no year): {subdir.name}\")\n",
    "            continue\n",
    "        year = int(m.group(1))\n",
    "        print(f\"\\n→ Processing '{subdir.name}' (year {year})\")\n",
    "        recs = process_year_folder(subdir, year, client)\n",
    "        print(f\"   → Parsed {len(recs)} entries\")\n",
    "        all_records.extend(recs)\n",
    "\n",
    "    with open(OUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_records, f, indent=2)\n",
    "\n",
    "    print(f\"Done! Total entries: {len(all_records)} → '{OUT_FILE}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862219c-3812-4fa5-9f9a-679602abee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Adjust this if your top-level folder is named differently\n",
    "ROOT = Path(\"proj_data\")\n",
    "YEAR_RE = re.compile(r\".*?(\\d{4})$\")\n",
    "\n",
    "if not ROOT.exists() or not ROOT.is_dir():\n",
    "    print(f\"Error: '{ROOT}' not found or is not a directory.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "for sub in sorted(ROOT.iterdir()):\n",
    "    if not sub.is_dir():\n",
    "        continue\n",
    "\n",
    "    match = YEAR_RE.match(sub.name)\n",
    "    if not match:\n",
    "        print(f\"Skipping (no year in name): '{sub.name}'\")\n",
    "        continue\n",
    "\n",
    "    year = match.group(1)\n",
    "    target = ROOT / year\n",
    "\n",
    "    if target.exists():\n",
    "        print(f\"⚠️  Target already exists, skipping: '{target.name}'\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"Renaming '{sub.name}' → '{year}'\")\n",
    "        sub.rename(target)\n",
    "    except Exception as e:\n",
    "        print(f\"Error renaming '{sub.name}': {e}\")\n",
    "\n",
    "print(\"Done! Directory names normalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc2eeb-e259-4539-95fc-3cf7c7c6fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "OCR & Parsing Pipeline using Google Cloud Vision (1900–1950)\n",
    "\n",
    "Dependencies:\n",
    "    pip install google-cloud-vision google-auth tqdm\n",
    "\n",
    "Set your Google credentials:\n",
    "    export GOOGLE_APPLICATION_CREDENTIALS=\"path/to/your-service-account.json\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── Text Parsing ───────────────────────────────────────────────────────────\n",
    "\n",
    "def parse_entry(entry_text: str, year: int) -> dict:\n",
    "    txt = re.sub(r'\\s+', ' ', entry_text).strip()\n",
    "    m = re.match(r'^(?P<name>[^,]+)', txt)\n",
    "    name = m.group('name').strip() if m else None\n",
    "    rest = txt[len(name):].strip(' ,') if name else txt\n",
    "    parts = [p.strip() for p in rest.split(',') if p.strip()]\n",
    "\n",
    "    spouse = address = residence = occupation = employer = None\n",
    "    for part in parts:\n",
    "        low = part.lower()\n",
    "        if low.startswith('w. '):\n",
    "            spouse = part[3:].strip()\n",
    "        elif low.startswith(('h. ', 'res. ')):\n",
    "            ind, _, addr = part.partition(' ')\n",
    "            residence = ind.rstrip('.')\n",
    "            address = addr or None\n",
    "        elif ' at ' in low:\n",
    "            occ, emp = re.split(r' at ', part, flags=re.I, maxsplit=1)\n",
    "            occupation, employer = occ.strip(), emp.strip()\n",
    "        elif not address:\n",
    "            address = part\n",
    "        else:\n",
    "            occupation = (occupation + '; ' + part) if occupation else part\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"spouse\": spouse,\n",
    "        \"address\": address,\n",
    "        \"residence_indicator\": residence,\n",
    "        \"occupation\": occupation,\n",
    "        \"employer\": employer,\n",
    "        \"year\": year\n",
    "    }\n",
    "\n",
    "# ─── OCR via Google Cloud Vision ────────────────────────────────────────────\n",
    "\n",
    "def ocr_with_gcv(image_path: Path, client: vision.ImageAnnotatorClient) -> str:\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        content = img_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise RuntimeError(f\"GCV error: {response.error.message}\")\n",
    "    return response.full_text_annotation.text\n",
    "\n",
    "# ─── Folder Processing ──────────────────────────────────────────────────────\n",
    "\n",
    "def process_year_folder(folder: Path, year: int, client: vision.ImageAnnotatorClient):\n",
    "    entries = []\n",
    "    for img_file in tqdm(sorted(folder.iterdir()), desc=f\"Year {year}\"):\n",
    "        if img_file.suffix.lower() not in ('.png', '.jpg', '.jpeg', '.tif'):\n",
    "            continue\n",
    "        raw = ocr_with_gcv(img_file, client)\n",
    "        chunks = [chunk for chunk in raw.split('\\n\\n') if chunk.strip()]\n",
    "        for chunk in chunks:\n",
    "            entries.append(parse_entry(chunk, year))\n",
    "    return entries\n",
    "\n",
    "# ─── Main Pipeline ───────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    DATA_ROOT = Path(\"proj_data\")      # top folder with subfolders “... 1900”, “... 1901”, …\n",
    "    OUT_FILE  = \"residents_gcv.json\"\n",
    "\n",
    "    # Initialize Google Cloud Vision client\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "    )\n",
    "    client = vision.ImageAnnotatorClient(credentials=creds)\n",
    "\n",
    "    all_records = []\n",
    "    year_pattern = re.compile(r'(\\d{4})$')\n",
    "\n",
    "    for subdir in sorted(DATA_ROOT.iterdir()):\n",
    "        if not subdir.is_dir():\n",
    "            continue\n",
    "        m = year_pattern.search(subdir.name)\n",
    "        if not m:\n",
    "            print(f\"Skipping folder (no year): {subdir.name}\")\n",
    "            continue\n",
    "        year = int(m.group(1))\n",
    "        print(f\"\\n→ Processing '{subdir.name}' (year {year})\")\n",
    "        recs = process_year_folder(subdir, year, client)\n",
    "        print(f\"   → Parsed {len(recs)} entries\")\n",
    "        all_records.extend(recs)\n",
    "\n",
    "    with open(OUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_records, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✅ Done! Total entries: {len(all_records)} → '{OUT_FILE}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1f368-c4cd-4688-b5a1-7286ff5ff4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge pillow pytesseract tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e4b6d-b0a5-435f-9586-99ac804a4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── Configuration ─────────────────────────────────────────────────────────\n",
    "\n",
    "DATA_ROOT   = Path(\"proj_data\")     # top‑level folder containing your year‑dirs\n",
    "OUTPUT_FILE = \"residents.json\"      # where we'll save the array of entries\n",
    "\n",
    "# simple decade thresholds if you want to tune per‑era\n",
    "DECADE_THRESH = {\n",
    "    (1850, 1879): 150,\n",
    "    (1880, 1899): 170,\n",
    "    (1900, 1950): 180,\n",
    "}\n",
    "\n",
    "# ─── Helpers ────────────────────────────────────────────────────────────────\n",
    "\n",
    "def get_threshold(year: int) -> int:\n",
    "    for (start, end), t in DECADE_THRESH.items():\n",
    "        if start <= year <= end:\n",
    "            return t\n",
    "    return 180\n",
    "\n",
    "def preprocess_image(path: Path, threshold: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Grayscale → point threshold → invert → return PIL.Image\n",
    "    threshold in [0..255]\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    # any pixel < threshold → white; else → black\n",
    "    bw  = img.point(lambda p: 255 if p < threshold else 0, mode=\"L\")\n",
    "    inv = ImageOps.invert(bw)\n",
    "    return inv\n",
    "\n",
    "def ocr_text(img: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Run Tesseract on a PIL image. psm 6 = assume a block of text.\n",
    "    \"\"\"\n",
    "    return pytesseract.image_to_string(img, config=\"--psm 6\")\n",
    "\n",
    "def parse_entry(txt: str, year: int) -> dict:\n",
    "    \"\"\"\n",
    "    From one block of text (one resident line), extract fields.\n",
    "    \"\"\"\n",
    "    s = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "    m = re.match(r\"^(?P<name>[^,]+)\", s)\n",
    "    name = m.group(\"name\").strip() if m else None\n",
    "    rest = s[len(name):].strip(\" ,\") if name else s\n",
    "    parts = [p.strip() for p in rest.split(\",\") if p.strip()]\n",
    "\n",
    "    spouse = address = residence = occupation = employer = None\n",
    "    for p in parts:\n",
    "        lp = p.lower()\n",
    "        if lp.startswith(\"w. \"):\n",
    "            spouse = p[3:].strip()\n",
    "        elif lp.startswith((\"h. \", \"res. \")):\n",
    "            ind, _, addr = p.partition(\" \")\n",
    "            residence = ind.rstrip(\".\")\n",
    "            address   = addr or None\n",
    "        elif \" at \" in lp:\n",
    "            occ, emp = re.split(r\" at \", p, flags=re.I, maxsplit=1)\n",
    "            occupation, employer = occ.strip(), emp.strip()\n",
    "        elif not address:\n",
    "            address = p\n",
    "        else:\n",
    "            occupation = (occupation + \"; \" + p) if occupation else p\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"spouse\": spouse,\n",
    "        \"address\": address,\n",
    "        \"residence_indicator\": residence,\n",
    "        \"occupation\": occupation,\n",
    "        \"employer\": employer,\n",
    "        \"year\": year\n",
    "    }\n",
    "\n",
    "# ─── Main Pipeline ─────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    all_entries = []\n",
    "    year_re     = re.compile(r\"(\\d{4})$\")\n",
    "\n",
    "    # iterate over every subfolder\n",
    "    for sub in sorted(DATA_ROOT.iterdir()):\n",
    "        if not sub.is_dir(): \n",
    "            continue\n",
    "\n",
    "        # find trailing 4‑digit year\n",
    "        m = year_re.search(sub.name)\n",
    "        if not m:\n",
    "            print(f\"Skipping (no year): {sub.name}\")\n",
    "            continue\n",
    "\n",
    "        year  = int(m.group(1))\n",
    "        thresh = get_threshold(year)\n",
    "        print(f\"\\n→ Year {year}  (threshold={thresh})\")\n",
    "\n",
    "        # OCR each image in that folder\n",
    "        for img_file in tqdm(sorted(sub.iterdir()), desc=f\"Y{year}\"):\n",
    "            if img_file.suffix.lower() not in (\".png\", \".jpg\", \".jpeg\", \".tif\"):\n",
    "                continue\n",
    "\n",
    "            # 1) preprocess & OCR\n",
    "            pil_img = preprocess_image(img_file, thresh)\n",
    "            raw_txt = ocr_text(pil_img)\n",
    "\n",
    "            # 2) split into blocks by blank lines\n",
    "            blocks = [blk for blk in raw_txt.split(\"\\n\\n\") if blk.strip()]\n",
    "            for blk in blocks:\n",
    "                entry = parse_entry(blk, year)\n",
    "                all_entries.append(entry)\n",
    "\n",
    "    # write JSON locally\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_entries, f, indent=2)\n",
    "\n",
    "    print(f\"Complete! Total entries: {len(all_entries)}\")\n",
    "    print(f\"JSON written to '{OUTPUT_FILE}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c64bfb-d403-457f-8f3d-3d86844da9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ─── Enhanced Preprocessing ────────────────────────────────────────────────\n",
    "\n",
    "def deskew_image(gray):\n",
    "    # threshold and find text contours for angle\n",
    "    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    coords = cv2.findNonZero(bw)\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    (h, w) = gray.shape\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    return cv2.warpAffine(gray, M, (w, h),\n",
    "                          flags=cv2.INTER_CUBIC,\n",
    "                          borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "def enhanced_preprocess(path, threshold=180):\n",
    "    \"\"\"\n",
    "    1. Read color → convert to grayscale\n",
    "    2. Bilateral filter for noise removal\n",
    "    3. Deskew based on text angle\n",
    "    4. Adaptive thresholding\n",
    "    5. Morphological opening\n",
    "    6. Invert to dark text on light background\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    den = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    desk = deskew_image(den)\n",
    "    thr = cv2.adaptiveThreshold(\n",
    "        desk, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        blockSize=15,\n",
    "        C=2\n",
    "    )\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "    opened = cv2.morphologyEx(thr, cv2.MORPH_OPEN, kernel)\n",
    "    inv = cv2.bitwise_not(opened)\n",
    "    return Image.fromarray(inv)\n",
    "\n",
    "# ─── OCR & Parsing Helpers ─────────────────────────────────────────────────\n",
    "\n",
    "def ocr_text(img):\n",
    "    return pytesseract.image_to_string(img, config=\"--psm 6\")\n",
    "\n",
    "def parse_entry(txt, year):\n",
    "    s = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "    m = re.match(r\"^(?P<name>[^,]+)\", s)\n",
    "    name = m.group(\"name\").strip() if m else None\n",
    "    rest = s[len(name):].strip(\" ,\") if name else s\n",
    "    parts = [p.strip() for p in rest.split(\",\") if p.strip()]\n",
    "\n",
    "    spouse = address = residence = occupation = employer = None\n",
    "    for p in parts:\n",
    "        lp = p.lower()\n",
    "        if lp.startswith(\"w. \"):\n",
    "            spouse = p[3:].strip()\n",
    "        elif lp.startswith((\"h. \", \"res. \")):\n",
    "            ind, _, addr = p.partition(\" \")\n",
    "            residence = ind.rstrip(\".\")\n",
    "            address   = addr or None\n",
    "        elif \" at \" in lp:\n",
    "            occ, emp = re.split(r\" at \", p, flags=re.I, maxsplit=1)\n",
    "            occupation, employer = occ.strip(), emp.strip()\n",
    "        elif not address:\n",
    "            address = p\n",
    "        else:\n",
    "            occupation = (occupation + \"; \" + p) if occupation else p\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"spouse\": spouse,\n",
    "        \"address\": address,\n",
    "        \"residence_indicator\": residence,\n",
    "        \"occupation\": occupation,\n",
    "        \"employer\": employer,\n",
    "        \"year\": year\n",
    "    }\n",
    "\n",
    "# ─── Main ───────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    DATA_FOLDER = Path(\"proj_data/1921\")\n",
    "    OUTPUT_FILE = \"residents_1921.json\"\n",
    "\n",
    "    if not DATA_FOLDER.is_dir():\n",
    "        print(f\"Error: folder not found: {DATA_FOLDER}\")\n",
    "        return\n",
    "\n",
    "    # extract year from folder name\n",
    "    m = re.search(r\"(\\d{4})$\", DATA_FOLDER.name)\n",
    "    year = int(m.group(1)) if m else None\n",
    "    if not year:\n",
    "        print(\"Error: could not determine year from folder name.\")\n",
    "        return\n",
    "\n",
    "    records = []\n",
    "    for img_path in tqdm(sorted(DATA_FOLDER.iterdir()), desc=f\"Year {year}\"):\n",
    "        if img_path.suffix.lower() not in (\".png\", \".jpg\", \".jpeg\", \".tif\"):\n",
    "            continue\n",
    "\n",
    "        # enhanced preprocess + OCR\n",
    "        pil_img = enhanced_preprocess(img_path, threshold=180)\n",
    "        raw_txt = ocr_text(pil_img)\n",
    "\n",
    "        # split and parse each block\n",
    "        for blk in [b for b in raw_txt.split(\"\\n\\n\") if b.strip()]:\n",
    "            rec = parse_entry(blk, year)\n",
    "            records.append(rec)\n",
    "\n",
    "    # write out JSON\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✅ Done: {len(records)} entries written to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e520a-d485-4d83-a246-365973b0f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import threading\n",
    "\n",
    "from filelock import FileLock\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def click_and_select_all(url: str,\n",
    "                         processed_file: str,\n",
    "                         scraper_id: int,\n",
    "                         num_scrapers: int):\n",
    "    lock = FileLock(processed_file + \".lock\")\n",
    "    if not os.path.exists(processed_file):\n",
    "        with lock:\n",
    "            with open(processed_file, \"w\") as f:\n",
    "                json.dump([], f)\n",
    "\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "        items = driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\")\n",
    "        total = len(items)\n",
    "\n",
    "        for idx in range(total):\n",
    "            if idx % num_scrapers != scraper_id:\n",
    "                continue\n",
    "\n",
    "            items = driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\")\n",
    "            if idx >= len(items):\n",
    "                break\n",
    "\n",
    "            item = items[idx]\n",
    "            name = item.text.strip()\n",
    "\n",
    "            with lock:\n",
    "                processed = json.load(open(processed_file, \"r\"))\n",
    "            if name in processed:\n",
    "                print(f\"[{idx+1}/{total}] Skipping: {name}\")\n",
    "                continue\n",
    "\n",
    "            # click the item\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", item)\n",
    "            time.sleep(0.5)\n",
    "            print(f\"[{idx+1}/{total}] Processing: {name}\")\n",
    "            item.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # ——— scroll pane from top→bottom in steps ———\n",
    "            try:\n",
    "                pane = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.CLASS_NAME, \"rc-thumbnail-pane\"))\n",
    "                )\n",
    "                # bring pane into view\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", pane)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                total_h = driver.execute_script(\"return arguments[0].scrollHeight;\", pane)\n",
    "                view_h  = driver.execute_script(\"return arguments[0].clientHeight;\", pane)\n",
    "\n",
    "                # step through in viewport-sized increments\n",
    "                for y in range(0, total_h, view_h):\n",
    "                    driver.execute_script(f\"arguments[0].scrollTop = {y};\", pane)\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                # ensure at very bottom\n",
    "                driver.execute_script(f\"arguments[0].scrollTop = {total_h};\", pane)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # now collect all thumbnails\n",
    "                thumbs = pane.find_elements(By.CLASS_NAME, \"rc-thumbnail\")\n",
    "                pg_idxs = []\n",
    "                for thumb in thumbs:\n",
    "                    try:\n",
    "                        src = thumb.find_element(By.TAG_NAME, \"img\") \\\n",
    "                                   .get_attribute(\"src\")\n",
    "                        m = re.search(r\"[?&]pg_idx=(\\d+)\", src)\n",
    "                        if m:\n",
    "                            pg_idxs.append(m.group(1))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                # save out to name.json\n",
    "                safe = re.sub(r\"[^\\w\\- ]\", \"\", name).strip().replace(\" \", \"_\")\n",
    "                out_dir = os.path.join(os.getcwd(), \"proj_data2\", safe)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                with open(os.path.join(out_dir, f\"{safe}.json\"), \"w\") as jf:\n",
    "                    json.dump(pg_idxs, jf, indent=2)\n",
    "                print(f\"    ▶ Saved pg_idx list for {name}\")\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(\"    ⚠️ Pane never appeared – skipping pg_idx\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ Error extracting pg_idx: {e}\")\n",
    "            # ——————————————————————————————————————\n",
    "\n",
    "            # rest of your existing fit‑height + screenshot logic…\n",
    "            try:\n",
    "                btn = driver.find_element(By.CLASS_NAME, \"rc-fit-height-icon\")\n",
    "                btn.click(); time.sleep(0.5)\n",
    "            except: pass\n",
    "\n",
    "            try:\n",
    "                sel = Select(driver.find_element(By.ID, \"rc-page-select\"))\n",
    "                for i_opt, opt in enumerate(sel.options):\n",
    "                    sel.select_by_index(i_opt)\n",
    "                    time.sleep(1.6)\n",
    "                    surf = driver.find_element(By.CLASS_NAME, \"rc-ti-tile-surface\")\n",
    "                    opt_name = re.sub(r\"[^\\w\\- ]\", \"\", opt.text).strip().replace(\" \", \"_\")\n",
    "                    surf.screenshot(os.path.join(out_dir, f\"{opt_name}.png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ Screenshot error: {e}\")\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(2)\n",
    "\n",
    "            with lock:\n",
    "                processed.append(name)\n",
    "                with open(processed_file, \"w\") as f:\n",
    "                    json.dump(processed, f, indent=2)\n",
    "\n",
    "        print(f\"Scraper {scraper_id} done\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    URL = (\n",
    "        \"https://box2.nmtvault.com/Hennepin2/jsp/RcWebSearchResults.jsp\"\n",
    "        \"?result_start=0&result_items=48&result_layout=GRID\"\n",
    "        \"&result_sort=Publication%20Date\"\n",
    "        \"&collection1=7083e412-1de2-42fe-b070-7f82e5c869a4\"\n",
    "        \"&query1_modifier=AND\"\n",
    "        \"&query1_field=DATE_PUBLISHED_MILLIS\"\n",
    "        \"&query1_min=-915148800000\"\n",
    "        \"&query1_max=-631152000000\"\n",
    "    )\n",
    "    PROCESSED = \"processed_items.json\"\n",
    "    NUM = 6\n",
    "\n",
    "    threads = []\n",
    "    for i in range(NUM):\n",
    "        t = threading.Thread(\n",
    "            target=click_and_select_all,\n",
    "            args=(URL, PROCESSED, i, NUM),\n",
    "            daemon=True\n",
    "        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    print(\"All scrapers finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f7f08-2ea7-43fa-a2da-d9b13f506e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import threading\n",
    "\n",
    "from filelock import FileLock\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "def click_and_select_all(url: str,\n",
    "                         processed_file: str,\n",
    "                         scraper_id: int,\n",
    "                         num_scrapers: int):\n",
    "    lock = FileLock(processed_file + \".lock\")\n",
    "    if not os.path.exists(processed_file):\n",
    "        with lock:\n",
    "            with open(processed_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump([], f)\n",
    "\n",
    "    # Run in headed mode with DevTools open for debugging\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "    options.add_argument(\"--auto-open-devtools-for-tabs\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        items = driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\")\n",
    "        total = len(items)\n",
    "\n",
    "        for idx in range(total):\n",
    "            # distribute across scrapers\n",
    "            if idx % num_scrapers != scraper_id:\n",
    "                continue\n",
    "\n",
    "            items = driver.find_elements(By.CLASS_NAME, \"rc-item-title-div\")\n",
    "            if idx >= len(items):\n",
    "                break\n",
    "\n",
    "            item = items[idx]\n",
    "            name = item.text.strip()\n",
    "\n",
    "            # skip already processed\n",
    "            with lock:\n",
    "                processed = json.load(open(processed_file, \"r\"))\n",
    "            if name in processed:\n",
    "                print(f\"[{idx+1}/{total}] Skipping: {name}\")\n",
    "                continue\n",
    "\n",
    "            # scroll this item into view & click\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", item)\n",
    "            time.sleep(0.5)\n",
    "            print(f\"[{idx+1}/{total}] Processing: {name}\")\n",
    "            item.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "            # ——— Debug: scroll thumbnail pane from top to bottom ———\n",
    "            try:\n",
    "                pane = WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.CLASS_NAME, \"rc-thumbnail-pane\"))\n",
    "                )\n",
    "                # bring the pane itself into view\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", pane)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                total_h = driver.execute_script(\"return arguments[0].scrollHeight;\", pane)\n",
    "                view_h  = driver.execute_script(\"return arguments[0].clientHeight;\", pane)\n",
    "                print(f\"DEBUG: pane.scrollHeight={total_h}, pane.clientHeight={view_h}\")\n",
    "\n",
    "                # scroll in increments of viewport height\n",
    "                for y in range(0, total_h + view_h, view_h):\n",
    "                    driver.execute_script(\"arguments[0].scrollTop = arguments[1];\", pane, y)\n",
    "                    # dispatch a real scroll event for lazy‑load\n",
    "                    driver.execute_script(\"\"\"\n",
    "                        let ev = new Event('scroll', { bubbles: true });\n",
    "                        arguments[0].dispatchEvent(ev);\n",
    "                    \"\"\", pane)\n",
    "                    curr = driver.execute_script(\"return arguments[0].scrollTop;\", pane)\n",
    "                    print(f\"DEBUG: scrolled to {curr}\")\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                # ensure at absolute bottom\n",
    "                driver.execute_script(\"arguments[0].scrollTop = arguments[1];\", pane, total_h)\n",
    "                driver.execute_script(\"\"\"\n",
    "                    let ev = new Event('scroll', { bubbles: true });\n",
    "                    arguments[0].dispatchEvent(ev);\n",
    "                \"\"\", pane)\n",
    "                print(f\"DEBUG: forced to bottom, scrollTop={driver.execute_script('return arguments[0].scrollTop;', pane)}\")\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # collect all thumbnails now\n",
    "                thumbs = pane.find_elements(By.CLASS_NAME, \"rc-thumbnail\")\n",
    "                pg_idxs = []\n",
    "                for thumb in thumbs:\n",
    "                    try:\n",
    "                        src = thumb.find_element(By.TAG_NAME, \"img\").get_attribute(\"src\")\n",
    "                        m = re.search(r\"[?&]pg_idx=(\\d+)\", src)\n",
    "                        if m:\n",
    "                            pg_idxs.append(m.group(1))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "\n",
    "                # write pg_idx list to name.json\n",
    "                safe = re.sub(r\"[^\\w\\- ]\", \"\", name).strip().replace(\" \", \"_\")\n",
    "                out_dir = os.path.join(os.getcwd(), \"proj_data2\", safe)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                json_path = os.path.join(out_dir, f\"{safe}.json\")\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
    "                    json.dump(pg_idxs, jf, indent=2)\n",
    "                print(f\"    ▶ Saved pg_idx list: {json_path}\")\n",
    "\n",
    "            except TimeoutException:\n",
    "                print(\"    ⚠️ Thumbnail pane never appeared – skipping pg_idx extraction\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ Error during pg_idx extraction: {e}\")\n",
    "            # ——————————————————————————————————————————————\n",
    "\n",
    "            # now your existing fit‑height & screenshot logic\n",
    "            try:\n",
    "                fit_btn = driver.find_element(By.CLASS_NAME, \"rc-fit-height-icon\")\n",
    "                fit_btn.click()\n",
    "                time.sleep(0.5)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                select = Select(driver.find_element(By.ID, \"rc-page-select\"))\n",
    "                for i_opt, opt in enumerate(select.options):\n",
    "                    select.select_by_index(i_opt)\n",
    "                    option_text = opt.text.strip()\n",
    "                    print(f\"    Selecting option: {option_text}\")\n",
    "                    time.sleep(1.6)\n",
    "\n",
    "                    surface = driver.find_element(By.CLASS_NAME, \"rc-ti-tile-surface\")\n",
    "                    safe_opt = re.sub(r\"[^\\w\\- ]\", \"\", option_text).strip().replace(\" \", \"_\")\n",
    "                    surface.screenshot(os.path.join(out_dir, f\"{safe_opt}.png\"))\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ Screenshot error: {e}\")\n",
    "\n",
    "            # return and mark processed\n",
    "            driver.back()\n",
    "            time.sleep(2)\n",
    "            with lock:\n",
    "                processed.append(name)\n",
    "                with open(processed_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(processed, f, indent=2)\n",
    "\n",
    "        print(f\"Scraper {scraper_id} done\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    URL = (\n",
    "        \"https://box2.nmtvault.com/Hennepin2/jsp/RcWebSearchResults.jsp\"\n",
    "        \"?result_start=0&result_items=48&result_layout=GRID\"\n",
    "        \"&result_sort=Publication%20Date\"\n",
    "        \"&collection1=7083e412-1de2-42fe-b070-7f82e5c869a4\"\n",
    "        \"&query1_modifier=AND\"\n",
    "        \"&query1_field=DATE_PUBLISHED_MILLIS\"\n",
    "        \"&query1_min=-915148800000\"\n",
    "        \"&query1_max=-631152000000\"\n",
    "    )\n",
    "    PROCESSED = \"processed_items.json\"\n",
    "    NUM = 6\n",
    "\n",
    "    threads = []\n",
    "    for i in range(NUM):\n",
    "        t = threading.Thread(\n",
    "            target=click_and_select_all,\n",
    "            args=(URL, PROCESSED, i, NUM),\n",
    "            daemon=True\n",
    "        )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    print(\"All scrapers finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3177500-b4c3-4f9d-837d-d4d033d38b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge opencv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95f5fc-ae3b-44f7-91ca-03899b5c796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-Accuracy OCR for 1900 Minneapolis City Directory\n",
    "# Optimized for Google Colab with GPU acceleration\n",
    "\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install all required packages for OCR processing\"\"\"\n",
    "    packages = [\n",
    "        \"easyocr\",\n",
    "        \"paddlepaddle\",\n",
    "        \"paddleocr\",\n",
    "        \"pytesseract\",\n",
    "        \"opencv-python\",\n",
    "        \"Pillow\",\n",
    "        \"transformers\",\n",
    "        \"torch\",\n",
    "        \"torchvision\"\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        except:\n",
    "            print(f\"Warning: Could not install {package}\")\n",
    "\n",
    "# Install packages\n",
    "print(\"Installing required packages...\")\n",
    "install_packages()\n",
    "\n",
    "# Import OCR libraries\n",
    "import easyocr\n",
    "import pytesseract\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "class HistoricalDirectoryOCR:\n",
    "    \"\"\"\n",
    "    Advanced OCR processor specifically designed for historical city directories\n",
    "    with multiple OCR engines for maximum accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Initializing OCR engines...\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize multiple OCR engines for ensemble processing\n",
    "            self.easyocr_reader = easyocr.Reader(['en'], gpu=True)\n",
    "            print(\"✅ EasyOCR initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ EasyOCR initialization failed: {e}\")\n",
    "            self.easyocr_reader = None\n",
    "        \n",
    "        logging.getLogger(\"paddleocr\").setLevel(logging.WARNING)\n",
    "\n",
    "        try:\n",
    "            # show_log has been removed – just omit it\n",
    "            self.paddle_ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "            print(\"✅ PaddleOCR initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ PaddleOCR initialization failed: {e}\")\n",
    "            self.paddle_ocr = None\n",
    "       \n",
    "        # Configure Tesseract for historical documents\n",
    "        self.tesseract_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,;:()&-\\' '\n",
    "        \n",
    "        print(\"OCR engines initialized successfully!\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Advanced image preprocessing for historical documents\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing image for optimal OCR...\")\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        original = img.copy()\n",
    "        \n",
    "        # Convert to PIL for advanced processing\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Enhance image quality\n",
    "        enhancer = ImageEnhance.Contrast(pil_img)\n",
    "        pil_img = enhancer.enhance(1.5)\n",
    "        \n",
    "        enhancer = ImageEnhance.Sharpness(pil_img)\n",
    "        pil_img = enhancer.enhance(1.2)\n",
    "        \n",
    "        enhancer = ImageEnhance.Brightness(pil_img)\n",
    "        pil_img = enhancer.enhance(1.1)\n",
    "        \n",
    "        # Convert back to OpenCV format\n",
    "        img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Noise reduction\n",
    "        img = cv2.medianBlur(img, 3)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Adaptive thresholding for better text extraction\n",
    "        processed = cv2.adaptiveThreshold(\n",
    "            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "        \n",
    "        # Morphological operations to clean up text\n",
    "        kernel = np.ones((1,1), np.uint8)\n",
    "        processed = cv2.morphologyEx(processed, cv2.MORPH_CLOSE, kernel)\n",
    "        processed = cv2.morphologyEx(processed, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return original, processed\n",
    "    \n",
    "    def extract_text_easyocr(self, image):\n",
    "        \"\"\"Extract text using EasyOCR with confidence scoring\"\"\"\n",
    "        if not self.easyocr_reader:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            results = self.easyocr_reader.readtext(image, detail=1, paragraph=False)\n",
    "            text_blocks = []\n",
    "            \n",
    "            for (bbox, text, conf) in results:\n",
    "                if conf > 0.3:  # Filter low confidence detections\n",
    "                    x1, y1 = int(bbox[0][0]), int(bbox[0][1])\n",
    "                    x2, y2 = int(bbox[2][0]), int(bbox[2][1])\n",
    "                    text_blocks.append({\n",
    "                        'text': text.strip(),\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'confidence': conf,\n",
    "                        'method': 'easyocr'\n",
    "                    })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            print(f\"EasyOCR error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_text_paddle(self, image):\n",
    "        \"\"\"Extract text using PaddleOCR\"\"\"\n",
    "        if not self.paddle_ocr:\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            results = self.paddle_ocr.ocr(image, cls=True)\n",
    "            text_blocks = []\n",
    "            \n",
    "            if results and results[0]:\n",
    "                for item in results[0]:\n",
    "                    if len(item) >= 2:\n",
    "                        bbox_points = item[0]\n",
    "                        text_info = item[1]\n",
    "                        \n",
    "                        if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:\n",
    "                            text = text_info[0]\n",
    "                            conf = text_info[1]\n",
    "                            \n",
    "                            if conf > 0.3:\n",
    "                                # Convert bbox to x1,y1,x2,y2 format\n",
    "                                x_coords = [point[0] for point in bbox_points]\n",
    "                                y_coords = [point[1] for point in bbox_points]\n",
    "                                x1, y1 = int(min(x_coords)), int(min(y_coords))\n",
    "                                x2, y2 = int(max(x_coords)), int(max(y_coords))\n",
    "                                \n",
    "                                text_blocks.append({\n",
    "                                    'text': text.strip(),\n",
    "                                    'bbox': [x1, y1, x2, y2],\n",
    "                                    'confidence': conf,\n",
    "                                    'method': 'paddle'\n",
    "                                })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            print(f\"PaddleOCR error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_text_tesseract(self, image):\n",
    "        \"\"\"Extract text using Tesseract OCR\"\"\"\n",
    "        try:\n",
    "            # Get detailed data from Tesseract\n",
    "            data = pytesseract.image_to_data(image, config=self.tesseract_config, output_type=pytesseract.Output.DICT)\n",
    "            text_blocks = []\n",
    "            \n",
    "            for i in range(len(data['text'])):\n",
    "                text = data['text'][i].strip()\n",
    "                conf = int(data['conf'][i])\n",
    "                \n",
    "                if text and conf > 30:  # Filter low confidence\n",
    "                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "                    text_blocks.append({\n",
    "                        'text': text,\n",
    "                        'bbox': [x, y, x + w, y + h],\n",
    "                        'confidence': conf / 100.0,\n",
    "                        'method': 'tesseract'\n",
    "                    })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            print(f\"Tesseract error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def ensemble_ocr(self, image):\n",
    "        \"\"\"\n",
    "        Combine results from multiple OCR engines for maximum accuracy\n",
    "        \"\"\"\n",
    "        print(\"Running ensemble OCR with multiple engines...\")\n",
    "        \n",
    "        all_blocks = []\n",
    "        \n",
    "        # Extract text with all OCR engines\n",
    "        easyocr_blocks = self.extract_text_easyocr(image)\n",
    "        paddle_blocks = self.extract_text_paddle(image)\n",
    "        tesseract_blocks = self.extract_text_tesseract(image)\n",
    "        \n",
    "        all_blocks.extend(easyocr_blocks)\n",
    "        all_blocks.extend(paddle_blocks)\n",
    "        all_blocks.extend(tesseract_blocks)\n",
    "        \n",
    "        print(f\"Found {len(all_blocks)} text blocks across all OCR engines\")\n",
    "        \n",
    "        # Sort by vertical position for proper reading order\n",
    "        all_blocks.sort(key=lambda x: (x['bbox'][1], x['bbox'][0]))\n",
    "        \n",
    "        return all_blocks\n",
    "    \n",
    "    def parse_directory_entry(self, text_line):\n",
    "        \"\"\"\n",
    "        Parse a single directory entry into structured data\n",
    "        Handles various formats found in 1900 city directories\n",
    "        \"\"\"\n",
    "        entry = {\n",
    "            \"FirstName\": None,\n",
    "            \"LastName\": None, \n",
    "            \"Spouse\": None,\n",
    "            \"Occupation\": None,\n",
    "            \"CompanyName\": None,\n",
    "            \"HomeAddress\": {\n",
    "                \"StreetNumber\": None,\n",
    "                \"StreetName\": None,\n",
    "                \"ApartmentOrUnit\": None,\n",
    "                \"ResidenceIndicator\": None\n",
    "            },\n",
    "            \"WorkAddress\": None,\n",
    "            \"Telephone\": None,\n",
    "            \"DirectoryName\": \"Minneapolis 1900\",\n",
    "            \"PageNumber\": None\n",
    "        }\n",
    "        \n",
    "        # Clean the text\n",
    "        text = re.sub(r'\\s+', ' ', text_line.strip())\n",
    "        \n",
    "        # Pattern for typical directory entry\n",
    "        # Format: LastName FirstName (spouse) occupation, company, address\n",
    "        \n",
    "        # Extract name (usually at the beginning)\n",
    "        name_match = re.match(r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]*)*)\\s+([A-Z][a-z]*(?:\\s+[A-Z])?)', text)\n",
    "        if name_match:\n",
    "            entry[\"LastName\"] = name_match.group(1)\n",
    "            entry[\"FirstName\"] = name_match.group(2)\n",
    "        \n",
    "        # Extract spouse (usually in parentheses)\n",
    "        spouse_match = re.search(r'\\(([^)]+)\\)', text)\n",
    "        if spouse_match:\n",
    "            entry[\"Spouse\"] = spouse_match.group(1)\n",
    "        \n",
    "        # Extract address (numbers followed by street names)\n",
    "        address_match = re.search(r'(\\d+)\\s+([A-Za-z\\s]+(?:av|Ave|st|St|Ave|avenue|street|rd|Rd|road))', text)\n",
    "        if address_match:\n",
    "            entry[\"HomeAddress\"][\"StreetNumber\"] = address_match.group(1)\n",
    "            entry[\"HomeAddress\"][\"StreetName\"] = address_match.group(2).strip()\n",
    "            entry[\"HomeAddress\"][\"ResidenceIndicator\"] = \"h\"\n",
    "        \n",
    "        # Extract apartment/unit info\n",
    "        apt_match = re.search(r'apt\\s*(\\d+|[A-Z])', text, re.IGNORECASE)\n",
    "        if apt_match:\n",
    "            entry[\"HomeAddress\"][\"ApartmentOrUnit\"] = f\"apt {apt_match.group(1)}\"\n",
    "        \n",
    "        # Extract occupation (common occupations in 1900)\n",
    "        occupations = [\n",
    "            'clerk', 'salesman', 'carpenter', 'laborer', 'machinist', 'engineer',\n",
    "            'teacher', 'physician', 'lawyer', 'merchant', 'blacksmith', 'tailor',\n",
    "            'shoemaker', 'baker', 'barber', 'painter', 'plumber', 'electrician'\n",
    "        ]\n",
    "        \n",
    "        for occ in occupations:\n",
    "            if occ in text.lower():\n",
    "                entry[\"Occupation\"] = occ.title()\n",
    "                break\n",
    "        \n",
    "        return entry\n",
    "    \n",
    "    def group_text_into_lines(self, text_blocks, line_threshold=20):\n",
    "        \"\"\"\n",
    "        Group text blocks into logical lines based on vertical positioning\n",
    "        \"\"\"\n",
    "        if not text_blocks:\n",
    "            return []\n",
    "        \n",
    "        # Sort by vertical position\n",
    "        sorted_blocks = sorted(text_blocks, key=lambda x: x['bbox'][1])\n",
    "        \n",
    "        lines = []\n",
    "        current_line = [sorted_blocks[0]]\n",
    "        current_y = sorted_blocks[0]['bbox'][1]\n",
    "        \n",
    "        for block in sorted_blocks[1:]:\n",
    "            block_y = block['bbox'][1]\n",
    "            \n",
    "            # If blocks are on the same line (within threshold)\n",
    "            if abs(block_y - current_y) <= line_threshold:\n",
    "                current_line.append(block)\n",
    "            else:\n",
    "                # Sort current line by horizontal position and join\n",
    "                current_line.sort(key=lambda x: x['bbox'][0])\n",
    "                line_text = ' '.join([b['text'] for b in current_line])\n",
    "                lines.append(line_text.strip())\n",
    "                \n",
    "                # Start new line\n",
    "                current_line = [block]\n",
    "                current_y = block_y\n",
    "        \n",
    "        # Add the last line\n",
    "        if current_line:\n",
    "            current_line.sort(key=lambda x: x['bbox'][0])\n",
    "            line_text = ' '.join([b['text'] for b in current_line])\n",
    "            lines.append(line_text.strip())\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    def extract_directory_data(self, image_path, page_number=None):\n",
    "        \"\"\"\n",
    "        Main function to extract structured directory data from image\n",
    "        \"\"\"\n",
    "        print(f\"Processing directory page: {image_path}\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        original, processed = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Extract text using ensemble OCR\n",
    "        text_blocks = self.ensemble_ocr(processed)\n",
    "        \n",
    "        # Group text blocks into logical lines\n",
    "        text_lines = self.group_text_into_lines(text_blocks)\n",
    "        \n",
    "        print(f\"Extracted {len(text_lines)} text lines from the image\")\n",
    "        \n",
    "        # Parse each line into structured data\n",
    "        directory_entries = []\n",
    "        \n",
    "        for i, line in enumerate(text_lines):\n",
    "            if len(line.strip()) > 10:  # Filter out very short lines\n",
    "                entry = self.parse_directory_entry(line)\n",
    "                if page_number:\n",
    "                    entry[\"PageNumber\"] = page_number\n",
    "                \n",
    "                # Only add entries that have at least a name\n",
    "                if entry[\"FirstName\"] or entry[\"LastName\"]:\n",
    "                    directory_entries.append(entry)\n",
    "        \n",
    "        print(f\"Successfully parsed {len(directory_entries)} directory entries\")\n",
    "        \n",
    "        return directory_entries, text_lines, original\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    # Initialize OCR processor\n",
    "    ocr_processor = HistoricalDirectoryOCR()\n",
    "    # Image path (update this to your image file in Colab)\n",
    "    image_path = \"/Users/darshilshukla/Desktop/104.png\"  # Change this to your image filename\n",
    "    \n",
    "    try:\n",
    "        # Extract directory data\n",
    "        directory_entries, raw_text_lines, original_image = ocr_processor.extract_directory_data(\n",
    "            image_path, page_number=104\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EXTRACTED DIRECTORY ENTRIES (JSON FORMAT)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Pretty print JSON\n",
    "        json_output = json.dumps(directory_entries, indent=2, ensure_ascii=False)\n",
    "        print(json_output)\n",
    "        \n",
    "        # Save to file\n",
    "        output_filename = \"/Users/darshilshukla/Desktop/extracted_directory_data.json\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(directory_entries, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\n✅ Data saved to: {output_filename}\")\n",
    "        print(f\"📊 Total entries extracted: {len(directory_entries)}\")\n",
    "        \n",
    "        # Display raw text for verification\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"RAW EXTRACTED TEXT LINES\")\n",
    "        print(\"=\"*80)\n",
    "        for i, line in enumerate(raw_text_lines[:10]):  # Show first 10 lines\n",
    "            print(f\"{i+1:2d}: {line}\")\n",
    "        \n",
    "        if len(raw_text_lines) > 10:\n",
    "            print(f\"... and {len(raw_text_lines) - 10} more lines\")\n",
    "        \n",
    "        # Display original image\n",
    "        plt.figure(figsize=(12, 16))\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Original Directory Page\")\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return directory_entries\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: Image file not found at {image_path}\")\n",
    "        print(\"Please upload your directory page image to the /content/ folder in Colab\")\n",
    "        print(\"and update the image_path variable with the correct filename.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing image: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Starting High-Accuracy OCR for 1900 Minneapolis Directory\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Run the main extraction\n",
    "    extracted_data = main()\n",
    "    \n",
    "    if extracted_data:\n",
    "        print(\"\\n✅ Extraction completed successfully!\")\n",
    "        print(\"📁 JSON data is available in the 'extracted_data' variable\")\n",
    "        print(\"💾 Data has been saved to '/content/extracted_directory_data.json'\")\n",
    "    else:\n",
    "        print(\"\\n❌ Extraction failed. Please check the image path and try again.\")\n",
    "\n",
    "\n",
    "def validate_extraction_quality(extracted_data):\n",
    "    \"\"\"Validate the quality of extracted data\"\"\"\n",
    "    if not extracted_data:\n",
    "        return \"No data extracted\"\n",
    "    \n",
    "    total_entries = len(extracted_data)\n",
    "    complete_entries = 0\n",
    "    \n",
    "    for entry in extracted_data:\n",
    "        score = 0\n",
    "        if entry.get(\"FirstName\"): score += 1\n",
    "        if entry.get(\"LastName\"): score += 1  \n",
    "        if entry.get(\"Occupation\"): score += 1\n",
    "        if entry.get(\"HomeAddress\", {}).get(\"StreetName\"): score += 1\n",
    "        \n",
    "        if score >= 3:  # At least 3 fields filled\n",
    "            complete_entries += 1\n",
    "    \n",
    "    quality_score = (complete_entries / total_entries) * 100 if total_entries > 0 else 0\n",
    "    \n",
    "    return f\"Quality Score: {quality_score:.1f}% ({complete_entries}/{total_entries} complete entries)\"\n",
    "\n",
    "# Display sample format\n",
    "display_sample_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4213bd2-eb58-431d-a054-dff709e4e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Historical Directory OCR System\n",
    "# High-performance, production-ready OCR with ML-based text parsing\n",
    "\n",
    "import json\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class AddressInfo:\n",
    "    \"\"\"Structured address information\"\"\"\n",
    "    street_number: Optional[str] = None\n",
    "    street_name: Optional[str] = None\n",
    "    apartment_or_unit: Optional[str] = None\n",
    "    residence_indicator: Optional[str] = None\n",
    "    city: Optional[str] = None\n",
    "    state: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class DirectoryEntry:\n",
    "    \"\"\"Complete directory entry with all possible fields\"\"\"\n",
    "    first_name: Optional[str] = None\n",
    "    middle_name: Optional[str] = None\n",
    "    last_name: Optional[str] = None\n",
    "    suffix: Optional[str] = None\n",
    "    spouse: Optional[str] = None\n",
    "    occupation: Optional[str] = None\n",
    "    company_name: Optional[str] = None\n",
    "    home_address: Optional[AddressInfo] = None\n",
    "    work_address: Optional[str] = None\n",
    "    telephone: Optional[str] = None\n",
    "    directory_name: str = \"Minneapolis 1900\"\n",
    "    page_number: Optional[int] = None\n",
    "    confidence_score: float = 0.0\n",
    "    raw_text: Optional[str] = None\n",
    "\n",
    "class OCREngineManager:\n",
    "    \"\"\"Manages multiple OCR engines with fallback mechanisms\"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu: bool = True):\n",
    "        self.use_gpu = use_gpu\n",
    "        self.engines = {}\n",
    "        self.engine_weights = {\n",
    "            'easyocr': 0.4,\n",
    "            'paddle': 0.35,\n",
    "            'tesseract': 0.25\n",
    "        }\n",
    "        self._initialize_engines()\n",
    "    \n",
    "    def _install_packages(self):\n",
    "        \"\"\"Install required packages with better error handling\"\"\"\n",
    "        packages = {\n",
    "            \"easyocr\": \"easyocr\",\n",
    "            \"paddlepaddle\": \"paddlepaddle\",\n",
    "            \"paddleocr\": \"paddleocr\",\n",
    "            \"pytesseract\": \"pytesseract\",\n",
    "            \"opencv-python\": \"cv2\",\n",
    "            \"Pillow\": \"PIL\",\n",
    "            \"transformers\": \"transformers\",\n",
    "            \"torch\": \"torch\",\n",
    "            \"torchvision\": \"torchvision\",\n",
    "            \"scikit-learn\": \"sklearn\",\n",
    "            \"nltk\": \"nltk\"\n",
    "        }\n",
    "        \n",
    "        for package, import_name in packages.items():\n",
    "            try:\n",
    "                __import__(import_name)\n",
    "                logger.info(f\"✅ {package} already installed\")\n",
    "            except ImportError:\n",
    "                try:\n",
    "                    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "                    logger.info(f\"✅ Successfully installed {package}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"⚠️ Failed to install {package}: {e}\")\n",
    "    \n",
    "    def _initialize_engines(self):\n",
    "        \"\"\"Initialize OCR engines with proper error handling\"\"\"\n",
    "        self._install_packages()\n",
    "        \n",
    "        # Initialize EasyOCR\n",
    "        try:\n",
    "            import easyocr\n",
    "            self.engines['easyocr'] = easyocr.Reader(['en'], gpu=self.use_gpu)\n",
    "            logger.info(\"✅ EasyOCR initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"⚠️ EasyOCR failed to initialize: {e}\")\n",
    "        \n",
    "        # Initialize PaddleOCR\n",
    "        try:\n",
    "            from paddleocr import PaddleOCR\n",
    "            # Suppress PaddleOCR logs\n",
    "            logging.getLogger(\"paddleocr\").setLevel(logging.WARNING)\n",
    "            self.engines['paddle'] = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=self.use_gpu)\n",
    "            logger.info(\"✅ PaddleOCR initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"⚠️ PaddleOCR failed to initialize: {e}\")\n",
    "        \n",
    "        # Initialize Tesseract\n",
    "        try:\n",
    "            import pytesseract\n",
    "            self.engines['tesseract'] = pytesseract\n",
    "            # Test if tesseract is available\n",
    "            pytesseract.get_tesseract_version()\n",
    "            logger.info(\"✅ Tesseract initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"⚠️ Tesseract failed to initialize: {e}\")\n",
    "        \n",
    "        if not self.engines:\n",
    "            raise RuntimeError(\"No OCR engines could be initialized\")\n",
    "    \n",
    "    def extract_with_easyocr(self, image: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Extract text using EasyOCR\"\"\"\n",
    "        if 'easyocr' not in self.engines:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = self.engines['easyocr'].readtext(image, detail=1, paragraph=False)\n",
    "            text_blocks = []\n",
    "            \n",
    "            for bbox, text, conf in results:\n",
    "                if conf > 0.3:\n",
    "                    x1, y1 = int(bbox[0][0]), int(bbox[0][1])\n",
    "                    x2, y2 = int(bbox[2][0]), int(bbox[2][1])\n",
    "                    text_blocks.append({\n",
    "                        'text': text.strip(),\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'confidence': conf,\n",
    "                        'engine': 'easyocr'\n",
    "                    })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"EasyOCR extraction failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_with_paddle(self, image: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Extract text using PaddleOCR\"\"\"\n",
    "        if 'paddle' not in self.engines:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = self.engines['paddle'].ocr(image, cls=True)\n",
    "            text_blocks = []\n",
    "            \n",
    "            if results and results[0]:\n",
    "                for item in results[0]:\n",
    "                    if len(item) >= 2:\n",
    "                        bbox_points = item[0]\n",
    "                        text_info = item[1]\n",
    "                        \n",
    "                        if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:\n",
    "                            text, conf = text_info[0], text_info[1]\n",
    "                            \n",
    "                            if conf > 0.3:\n",
    "                                x_coords = [point[0] for point in bbox_points]\n",
    "                                y_coords = [point[1] for point in bbox_points]\n",
    "                                x1, y1 = int(min(x_coords)), int(min(y_coords))\n",
    "                                x2, y2 = int(max(x_coords)), int(max(y_coords))\n",
    "                                \n",
    "                                text_blocks.append({\n",
    "                                    'text': text.strip(),\n",
    "                                    'bbox': [x1, y1, x2, y2],\n",
    "                                    'confidence': conf,\n",
    "                                    'engine': 'paddle'\n",
    "                                })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"PaddleOCR extraction failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def extract_with_tesseract(self, image: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"Extract text using Tesseract\"\"\"\n",
    "        if 'tesseract' not in self.engines:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            pytesseract = self.engines['tesseract']\n",
    "            config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,;:()&-\\' '\n",
    "            \n",
    "            data = pytesseract.image_to_data(image, config=config, output_type=pytesseract.Output.DICT)\n",
    "            text_blocks = []\n",
    "            \n",
    "            for i in range(len(data['text'])):\n",
    "                text = data['text'][i].strip()\n",
    "                conf = int(data['conf'][i])\n",
    "                \n",
    "                if text and conf > 30:\n",
    "                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "                    text_blocks.append({\n",
    "                        'text': text,\n",
    "                        'bbox': [x, y, x + w, y + h],\n",
    "                        'confidence': conf / 100.0,\n",
    "                        'engine': 'tesseract'\n",
    "                    })\n",
    "            \n",
    "            return text_blocks\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tesseract extraction failed: {e}\")\n",
    "            return []\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    \"\"\"Advanced image preprocessing for historical documents\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def enhance_image(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply comprehensive image enhancement\"\"\"\n",
    "        # Convert to PIL for advanced processing\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Multiple enhancement steps\n",
    "        enhancers = [\n",
    "            (ImageEnhance.Contrast, 1.5),\n",
    "            (ImageEnhance.Sharpness, 1.3),\n",
    "            (ImageEnhance.Brightness, 1.1)\n",
    "        ]\n",
    "        \n",
    "        for enhancer_class, factor in enhancers:\n",
    "            enhancer = enhancer_class(pil_img)\n",
    "            pil_img = enhancer.enhance(factor)\n",
    "        \n",
    "        return cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    @staticmethod\n",
    "    def denoise_image(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply advanced denoising\"\"\"\n",
    "        # Multiple denoising techniques\n",
    "        denoised = cv2.medianBlur(image, 3)\n",
    "        denoised = cv2.bilateralFilter(denoised, 9, 75, 75)\n",
    "        return denoised\n",
    "    \n",
    "    @staticmethod\n",
    "    def adaptive_threshold(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply adaptive thresholding with multiple methods\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Try multiple thresholding methods and combine\n",
    "        thresh1 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        # Combine results\n",
    "        combined = cv2.bitwise_and(thresh1, thresh2)\n",
    "        \n",
    "        # Morphological operations\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)\n",
    "        combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    @classmethod\n",
    "    def preprocess_pipeline(cls, image_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "        # Load image\n",
    "        original = cv2.imread(image_path)\n",
    "        if original is None:\n",
    "            raise FileNotFoundError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Apply enhancements\n",
    "        enhanced = cls.enhance_image(original)\n",
    "        denoised = cls.denoise_image(enhanced)\n",
    "        processed = cls.adaptive_threshold(denoised)\n",
    "        \n",
    "        return original, processed\n",
    "\n",
    "class TextParser:\n",
    "    \"\"\"Advanced text parsing with ML-based pattern recognition\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name_patterns = self._compile_name_patterns()\n",
    "        self.address_patterns = self._compile_address_patterns()\n",
    "        self.occupation_patterns = self._compile_occupation_patterns()\n",
    "        \n",
    "    def _compile_name_patterns(self) -> List[re.Pattern]:\n",
    "        \"\"\"Compile patterns for name extraction\"\"\"\n",
    "        patterns = [\n",
    "            # Last, First Middle\n",
    "            re.compile(r'^([A-Z][a-z]+),\\s+([A-Z][a-z]+)(?:\\s+([A-Z][a-z]*))?\\s*(.*)$'),\n",
    "            # First Middle Last\n",
    "            re.compile(r'^([A-Z][a-z]+)\\s+([A-Z][a-z]*)\\s+([A-Z][a-z]+)\\s*(.*)$'),\n",
    "            # First Last\n",
    "            re.compile(r'^([A-Z][a-z]+)\\s+([A-Z][a-z]+)\\s*(.*)$'),\n",
    "        ]\n",
    "        return patterns\n",
    "    \n",
    "    def _compile_address_patterns(self) -> List[re.Pattern]:\n",
    "        \"\"\"Compile patterns for address extraction\"\"\"\n",
    "        street_types = r'(?:av|ave|avenue|st|street|rd|road|blvd|boulevard|ln|lane|ct|court|pl|place|way|dr|drive)'\n",
    "        patterns = [\n",
    "            # Number + Street Name + Type\n",
    "            re.compile(rf'(\\d+)\\s+([A-Za-z\\s]+)\\s+({street_types})', re.IGNORECASE),\n",
    "            # Number + Street Name (without explicit type)\n",
    "            re.compile(r'(\\d+)\\s+([A-Za-z\\s]+(?:av|Ave|st|St))', re.IGNORECASE),\n",
    "        ]\n",
    "        return patterns\n",
    "    \n",
    "    def _compile_occupation_patterns(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Compile occupation patterns with categories\"\"\"\n",
    "        return {\n",
    "            'professional': ['lawyer', 'attorney', 'physician', 'doctor', 'engineer', 'architect', 'teacher', 'professor'],\n",
    "            'trades': ['carpenter', 'blacksmith', 'tailor', 'shoemaker', 'baker', 'barber', 'painter', 'plumber'],\n",
    "            'clerical': ['clerk', 'bookkeeper', 'stenographer', 'secretary', 'accountant'],\n",
    "            'sales': ['salesman', 'merchant', 'shopkeeper', 'grocer'],\n",
    "            'labor': ['laborer', 'worker', 'operative', 'machinist', 'factory worker'],\n",
    "            'service': ['waiter', 'cook', 'janitor', 'porter', 'driver']\n",
    "        }\n",
    "    \n",
    "    def extract_names(self, text: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "        \"\"\"Extract first, middle, and last names\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        for pattern in self.name_patterns:\n",
    "            match = pattern.match(text)\n",
    "            if match:\n",
    "                groups = match.groups()\n",
    "                if len(groups) >= 3 and groups[0] and groups[1]:\n",
    "                    # Handle different pattern formats\n",
    "                    if ',' in text:  # Last, First format\n",
    "                        return groups[1], groups[2], groups[0]  # first, middle, last\n",
    "                    else:  # First Last or First Middle Last format\n",
    "                        if groups[2]:  # First Middle Last\n",
    "                            return groups[0], groups[1], groups[2]\n",
    "                        else:  # First Last\n",
    "                            return groups[0], None, groups[1]\n",
    "        \n",
    "        return None, None, None\n",
    "    \n",
    "    def extract_address(self, text: str) -> Optional[AddressInfo]:\n",
    "        \"\"\"Extract address information\"\"\"\n",
    "        for pattern in self.address_patterns:\n",
    "            match = pattern.search(text)\n",
    "            if match:\n",
    "                return AddressInfo(\n",
    "                    street_number=match.group(1),\n",
    "                    street_name=match.group(2).strip(),\n",
    "                    residence_indicator=\"h\"\n",
    "                )\n",
    "        return None\n",
    "    \n",
    "    def extract_occupation(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract occupation with category mapping\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for category, occupations in self.occupation_patterns.items():\n",
    "            for occupation in occupations:\n",
    "                if occupation in text_lower:\n",
    "                    return occupation.title()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def parse_directory_line(self, text: str) -> DirectoryEntry:\n",
    "        \"\"\"Parse a complete directory line\"\"\"\n",
    "        entry = DirectoryEntry()\n",
    "        entry.raw_text = text\n",
    "        \n",
    "        # Extract names\n",
    "        first, middle, last = self.extract_names(text)\n",
    "        entry.first_name = first\n",
    "        entry.middle_name = middle\n",
    "        entry.last_name = last\n",
    "        \n",
    "        # Extract spouse (in parentheses)\n",
    "        spouse_match = re.search(r'\\(([^)]+)\\)', text)\n",
    "        if spouse_match:\n",
    "            entry.spouse = spouse_match.group(1)\n",
    "        \n",
    "        # Extract address\n",
    "        entry.home_address = self.extract_address(text)\n",
    "        \n",
    "        # Extract occupation\n",
    "        entry.occupation = self.extract_occupation(text)\n",
    "        \n",
    "        # Calculate confidence score\n",
    "        entry.confidence_score = self._calculate_confidence(entry)\n",
    "        \n",
    "        return entry\n",
    "    \n",
    "    def _calculate_confidence(self, entry: DirectoryEntry) -> float:\n",
    "        \"\"\"Calculate confidence score based on extracted fields\"\"\"\n",
    "        score = 0.0\n",
    "        weights = {\n",
    "            'first_name': 0.25,\n",
    "            'last_name': 0.25,\n",
    "            'occupation': 0.20,\n",
    "            'home_address': 0.20,\n",
    "            'spouse': 0.10\n",
    "        }\n",
    "        \n",
    "        if entry.first_name:\n",
    "            score += weights['first_name']\n",
    "        if entry.last_name:\n",
    "            score += weights['last_name']\n",
    "        if entry.occupation:\n",
    "            score += weights['occupation']\n",
    "        if entry.home_address and entry.home_address.street_name:\n",
    "            score += weights['home_address']\n",
    "        if entry.spouse:\n",
    "            score += weights['spouse']\n",
    "        \n",
    "        return score\n",
    "\n",
    "class AdvancedHistoricalOCR:\n",
    "    \"\"\"Main OCR system with ensemble processing and ML-based parsing\"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu: bool = True):\n",
    "        self.ocr_manager = OCREngineManager(use_gpu)\n",
    "        self.preprocessor = ImagePreprocessor()\n",
    "        self.parser = TextParser()\n",
    "        self.stats = defaultdict(int)\n",
    "    \n",
    "    def _merge_overlapping_blocks(self, blocks: List[Dict], overlap_threshold: float = 0.5) -> List[Dict]:\n",
    "        \"\"\"Merge overlapping text blocks from different OCR engines\"\"\"\n",
    "        if not blocks:\n",
    "            return blocks\n",
    "        \n",
    "        merged = []\n",
    "        blocks = sorted(blocks, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        for block in blocks:\n",
    "            is_merged = False\n",
    "            \n",
    "            for merged_block in merged:\n",
    "                if self._calculate_overlap(block['bbox'], merged_block['bbox']) > overlap_threshold:\n",
    "                    # Merge with higher confidence text\n",
    "                    if block['confidence'] > merged_block['confidence']:\n",
    "                        merged_block.update(block)\n",
    "                    is_merged = True\n",
    "                    break\n",
    "            \n",
    "            if not is_merged:\n",
    "                merged.append(block)\n",
    "        \n",
    "        return merged\n",
    "    \n",
    "    def _calculate_overlap(self, bbox1: List[int], bbox2: List[int]) -> float:\n",
    "        \"\"\"Calculate overlap ratio between two bounding boxes\"\"\"\n",
    "        x1_1, y1_1, x2_1, y2_1 = bbox1\n",
    "        x1_2, y1_2, x2_2, y2_2 = bbox2\n",
    "        \n",
    "        # Calculate intersection\n",
    "        x1_i = max(x1_1, x1_2)\n",
    "        y1_i = max(y1_1, y1_2)\n",
    "        x2_i = min(x2_1, x2_2)\n",
    "        y2_i = min(y2_1, y2_2)\n",
    "        \n",
    "        if x2_i <= x1_i or y2_i <= y1_i:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "        \n",
    "        return intersection / min(area1, area2)\n",
    "    \n",
    "    def _group_text_into_lines(self, blocks: List[Dict], line_threshold: int = 20) -> List[str]:\n",
    "        \"\"\"Group text blocks into logical lines\"\"\"\n",
    "        if not blocks:\n",
    "            return []\n",
    "        \n",
    "        # Sort by vertical position\n",
    "        sorted_blocks = sorted(blocks, key=lambda x: x['bbox'][1])\n",
    "        \n",
    "        lines = []\n",
    "        current_line = [sorted_blocks[0]]\n",
    "        current_y = sorted_blocks[0]['bbox'][1]\n",
    "        \n",
    "        for block in sorted_blocks[1:]:\n",
    "            block_y = block['bbox'][1]\n",
    "            \n",
    "            if abs(block_y - current_y) <= line_threshold:\n",
    "                current_line.append(block)\n",
    "            else:\n",
    "                # Sort by horizontal position and join\n",
    "                current_line.sort(key=lambda x: x['bbox'][0])\n",
    "                line_text = ' '.join([b['text'] for b in current_line])\n",
    "                lines.append(line_text.strip())\n",
    "                \n",
    "                current_line = [block]\n",
    "                current_y = block_y\n",
    "        \n",
    "        # Add the last line\n",
    "        if current_line:\n",
    "            current_line.sort(key=lambda x: x['bbox'][0])\n",
    "            line_text = ' '.join([b['text'] for b in current_line])\n",
    "            lines.append(line_text.strip())\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    def extract_directory_entries(self, image_path: str, page_number: Optional[int] = None) -> Tuple[List[DirectoryEntry], Dict]:\n",
    "        \"\"\"Main extraction function\"\"\"\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Processing directory page: {image_path}\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        original, processed = self.preprocessor.preprocess_pipeline(image_path)\n",
    "        \n",
    "        # Extract text using all OCR engines\n",
    "        all_blocks = []\n",
    "        \n",
    "        # Run OCR engines in parallel for better performance\n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            futures = {\n",
    "                executor.submit(self.ocr_manager.extract_with_easyocr, processed): 'easyocr',\n",
    "                executor.submit(self.ocr_manager.extract_with_paddle, processed): 'paddle',\n",
    "                executor.submit(self.ocr_manager.extract_with_tesseract, processed): 'tesseract'\n",
    "            }\n",
    "            \n",
    "            for future in futures:\n",
    "                try:\n",
    "                    blocks = future.result(timeout=60)  # 60 second timeout\n",
    "                    all_blocks.extend(blocks)\n",
    "                    self.stats[f'{futures[future]}_blocks'] += len(blocks)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"OCR engine {futures[future]} failed: {e}\")\n",
    "        \n",
    "        # Merge overlapping blocks\n",
    "        merged_blocks = self._merge_overlapping_blocks(all_blocks)\n",
    "        \n",
    "        # Group blocks into lines\n",
    "        text_lines = self._group_text_into_lines(merged_blocks)\n",
    "        \n",
    "        # Parse each line\n",
    "        directory_entries = []\n",
    "        for line in text_lines:\n",
    "            if len(line.strip()) > 10:  # Filter short lines\n",
    "                entry = self.parser.parse_directory_line(line)\n",
    "                if page_number:\n",
    "                    entry.page_number = page_number\n",
    "                \n",
    "                # Only add entries with reasonable confidence\n",
    "                if entry.confidence_score > 0.3:\n",
    "                    directory_entries.append(entry)\n",
    "        \n",
    "        # Update statistics\n",
    "        processing_time = time.time() - start_time\n",
    "        stats = {\n",
    "            'processing_time': processing_time,\n",
    "            'total_blocks': len(all_blocks),\n",
    "            'merged_blocks': len(merged_blocks),\n",
    "            'text_lines': len(text_lines),\n",
    "            'directory_entries': len(directory_entries),\n",
    "            'average_confidence': np.mean([e.confidence_score for e in directory_entries]) if directory_entries else 0,\n",
    "            'engines_used': list(self.ocr_manager.engines.keys())\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Extracted {len(directory_entries)} entries in {processing_time:.2f}s\")\n",
    "        \n",
    "        return directory_entries, stats\n",
    "    \n",
    "    def save_results(self, entries: List[DirectoryEntry], output_path: str, format: str = 'json'):\n",
    "        \"\"\"Save results in various formats\"\"\"\n",
    "        if format == 'json':\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump([asdict(entry) for entry in entries], f, indent=2, ensure_ascii=False)\n",
    "        elif format == 'csv':\n",
    "            df = pd.DataFrame([asdict(entry) for entry in entries])\n",
    "            df.to_csv(output_path, index=False)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format: {format}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        # Initialize OCR system\n",
    "        ocr_system = AdvancedHistoricalOCR(use_gpu=True)\n",
    "        \n",
    "        # Update this path to your image\n",
    "        image_path = \"/Users/darshilshukla/Desktop/104.png\"\n",
    "        \n",
    "        if not Path(image_path).exists():\n",
    "            logger.error(f\"Image file not found: {image_path}\")\n",
    "            return\n",
    "        \n",
    "        # Extract directory entries\n",
    "        entries, stats = ocr_system.extract_directory_entries(image_path, page_number=104)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EXTRACTION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Processing time: {stats['processing_time']:.2f}s\")\n",
    "        print(f\"Total entries: {stats['directory_entries']}\")\n",
    "        print(f\"Average confidence: {stats['average_confidence']:.2f}\")\n",
    "        print(f\"OCR engines used: {', '.join(stats['engines_used'])}\")\n",
    "        \n",
    "        # Save results\n",
    "        output_path = \"/Users/darshilshukla/Desktop/advanced_directory_data.json\"\n",
    "        ocr_system.save_results(entries, output_path)\n",
    "        logger.info(f\"Results saved to: {output_path}\")\n",
    "        \n",
    "        # Display sample entries\n",
    "        print(\"\\nSAMPLE ENTRIES:\")\n",
    "        for i, entry in enumerate(entries[:5]):\n",
    "            print(f\"\\n{i+1}. {entry.first_name} {entry.last_name}\")\n",
    "            if entry.occupation:\n",
    "                print(f\"   Occupation: {entry.occupation}\")\n",
    "            if entry.home_address and entry.home_address.street_name:\n",
    "                print(f\"   Address: {entry.home_address.street_number} {entry.home_address.street_name}\")\n",
    "            print(f\"   Confidence: {entry.confidence_score:.2f}\")\n",
    "        \n",
    "        return entries\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Fatal error: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Advanced Historical Directory OCR System\")\n",
    "    print(\"=\"*80)\n",
    "    extracted_data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf2a7a3-3dd4-4879-89f2-01e353ca6769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b315389-970e-47d0-9fba-c3c7e55afcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Advanced Historical Directory OCR System (Hard-Coded Paths)\n",
    "\n",
    "Runs an ensemble OCR pipeline on a single 1900 Minneapolis directory page (104),\n",
    "splits into tiles, performs advanced preprocessing, merges multiple OCR engines,\n",
    "and parses entries into structured JSON.\n",
    "\"\"\"\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import pytesseract\n",
    "try:\n",
    "    import easyocr\n",
    "except ImportError:\n",
    "    easyocr = None\n",
    "try:\n",
    "    from paddleocr import PaddleOCR\n",
    "except ImportError:\n",
    "    PaddleOCR = None\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "TESSERACT_CMD = \"/usr/local/bin/tesseract\"             # Path to Tesseract executable\n",
    "IMAGE_PATH = Path(\"/Users/darshilshukla/Desktop/104.png\")  # Input image\n",
    "OUTPUT_FILE = Path(\"/Users/darshilshukla/Desktop/extracted_directory_data.json\")  # JSON output\n",
    "TILE_SIZE = (800, 800)  # width, height of tiles\n",
    "MIN_CONFIDENCE = 0.3    # minimum entry confidence for final filtering\n",
    "USE_GPU = True          # enable GPU for EasyOCR/PaddleOCR if available\n",
    "MAX_WORKERS = 4         # thread pool size for OCR engines\n",
    "\n",
    "# Ensure Tesseract CMD is set\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD\n",
    "\n",
    "@dataclass\n",
    "class AddressInfo:\n",
    "    street_number: str\n",
    "    street_name: str\n",
    "    apartment_or_unit: str = None\n",
    "    residence_indicator: str = None\n",
    "\n",
    "@dataclass\n",
    "class DirectoryEntry:\n",
    "    first_name: str = None\n",
    "    middle_name: str = None\n",
    "    last_name: str = None\n",
    "    suffix: str = None\n",
    "    spouse: str = None\n",
    "    occupation: str = None\n",
    "    company_name: str = None\n",
    "    home_address: AddressInfo = None\n",
    "    work_address: str = None\n",
    "    telephone: str = None\n",
    "    directory_name: str = \"Minneapolis 1900\"\n",
    "    page_number: int = 104\n",
    "    confidence_score: float = 0.0\n",
    "    raw_text: str = None\n",
    "\n",
    "class OCREngineManager:\n",
    "    \"\"\"Manages Tesseract, EasyOCR, and PaddleOCR engines with fallback\"\"\"\n",
    "    def __init__(self):\n",
    "        self.engines = {}\n",
    "        # Initialize Tesseract\n",
    "        try:\n",
    "            pytesseract.get_tesseract_version()\n",
    "            self.engines['tesseract'] = pytesseract\n",
    "            logger.info(\"✅ Tesseract initialized\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"⚠️ Tesseract init failed: {e}\")\n",
    "        # EasyOCR\n",
    "        if easyocr:\n",
    "            try:\n",
    "                reader = easyocr.Reader(['en'], gpu=USE_GPU)\n",
    "                self.engines['easyocr'] = reader\n",
    "                logger.info(\"✅ EasyOCR initialized\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"⚠️ EasyOCR init failed: {e}\")\n",
    "        # PaddleOCR\n",
    "        if PaddleOCR:\n",
    "            try:\n",
    "                ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=USE_GPU)\n",
    "                self.engines['paddle'] = ocr\n",
    "                logger.info(\"✅ PaddleOCR initialized\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"⚠️ PaddleOCR init failed: {e}\")\n",
    "\n",
    "    def extract_blocks(self, image: np.ndarray) -> List[Dict]:\n",
    "        blocks = []\n",
    "        # Tesseract\n",
    "        if 'tesseract' in self.engines:\n",
    "            data = self.engines['tesseract'].image_to_data(\n",
    "                image, config='--oem 3 --psm 6', output_type=pytesseract.Output.DICT\n",
    "            )\n",
    "            for i, txt in enumerate(data['text']):\n",
    "                conf = int(data['conf'][i]) / 100.0\n",
    "                if txt.strip() and conf > 0.3:\n",
    "                    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "                    blocks.append({'text': txt.strip(), 'bbox': [x, y, x+w, y+h], 'confidence': conf, 'engine': 'tesseract'})\n",
    "        # EasyOCR\n",
    "        if 'easyocr' in self.engines:\n",
    "            try:\n",
    "                results = self.engines['easyocr'].readtext(image, detail=1)\n",
    "                for bbox, txt, conf in results:\n",
    "                    if conf > 0.3:\n",
    "                        x1, y1 = map(int, bbox[0])\n",
    "                        x2, y2 = map(int, bbox[2])\n",
    "                        blocks.append({'text': txt.strip(), 'bbox': [x1, y1, x2, y2], 'confidence': conf, 'engine': 'easyocr'})\n",
    "            except Exception:\n",
    "                pass\n",
    "        # PaddleOCR\n",
    "        if 'paddle' in self.engines:\n",
    "            try:\n",
    "                res = self.engines['paddle'].ocr(image, cls=True)\n",
    "                for line in (res[0] if res else []):\n",
    "                    coords, info = line\n",
    "                    txt, conf = info\n",
    "                    if conf > 0.3:\n",
    "                        xs = [pt[0] for pt in coords]; ys = [pt[1] for pt in coords]\n",
    "                        blocks.append({'text': txt.strip(), 'bbox': [min(xs), min(ys), max(xs), max(ys)], 'confidence': conf, 'engine': 'paddle'})\n",
    "            except Exception:\n",
    "                pass\n",
    "        return blocks\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    \"\"\"Enhancement, denoising, and adaptive thresholding\"\"\"\n",
    "    @staticmethod\n",
    "    def preprocess(image: np.ndarray) -> np.ndarray:\n",
    "        pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        pil = ImageEnhance.Contrast(pil).enhance(1.5)\n",
    "        pil = ImageEnhance.Sharpness(pil).enhance(1.3)\n",
    "        gray = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2GRAY)\n",
    "        den = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "        return cv2.adaptiveThreshold(den, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "class TextParser:\n",
    "    \"\"\"Regex-based parsing to DirectoryEntry\"\"\"\n",
    "    name_patterns = [re.compile(r\"^([A-Za-z]+),\\s*([A-Za-z.]+)(?:\\s+w\\s*([A-Za-z.]+))?\"),\n",
    "                     re.compile(r\"^([A-Za-z]+)\\s+([A-Za-z.]+)\")]\n",
    "    addr_pattern = re.compile(r\"(\\d+)\\s+([A-Za-z. ]+)\")\n",
    "\n",
    "    def parse_line(self, line: str) -> Optional[DirectoryEntry]:\n",
    "        for pat in self.name_patterns:\n",
    "            m = pat.match(line)\n",
    "            if m:\n",
    "                groups = m.groups()\n",
    "                last = groups[0]; first = groups[1]; spouse = groups[2] if len(groups) > 2 else None\n",
    "                entry = DirectoryEntry(first_name=first, last_name=last, spouse=spouse, raw_text=line)\n",
    "                # address\n",
    "                am = self.addr_pattern.search(line)\n",
    "                if am:\n",
    "                    entry.home_address = AddressInfo(street_number=am.group(1), street_name=am.group(2).strip(), residence_indicator='h')\n",
    "                # occupation as anything after first comma\n",
    "                parts = line.split(',')\n",
    "                if len(parts) > 1:\n",
    "                    entry.occupation = parts[1].strip()\n",
    "                # confidence dummy metric\n",
    "                entry.confidence_score = 0.5 + (0.5 if entry.home_address else 0)\n",
    "                return entry\n",
    "        return None\n",
    "\n",
    "class AdvancedHistoricalOCR:\n",
    "    \"\"\"Orchestrates preprocessing, OCR, merging, and parsing\"\"\"\n",
    "    def __init__(self):\n",
    "        self.manager = OCREngineManager()\n",
    "        self.parser = TextParser()\n",
    "\n",
    "    def _merge_blocks(self, blocks: List[Dict], thresh: float = 0.5) -> List[Dict]:\n",
    "        merged = []\n",
    "        for blk in sorted(blocks, key=lambda b: b['confidence'], reverse=True):\n",
    "            placed = False\n",
    "            for m in merged:\n",
    "                # overlap calc\n",
    "                x1, y1, x2, y2 = blk['bbox']; a1, b1, a2, b2 = m['bbox']\n",
    "                ix = max(0, min(x2, a2) - max(x1, a1)); iy = max(0, min(y2, b2) - max(y1, b1))\n",
    "                inter = ix * iy; area = min((x2-x1)*(y2-y1), (a2-a1)*(b2-b1))\n",
    "                if area and inter/area > thresh:\n",
    "                    placed = True; break\n",
    "            if not placed:\n",
    "                merged.append(blk)\n",
    "        return merged\n",
    "\n",
    "    def _group_lines(self, blocks: List[Dict], yth=20) -> List[str]:\n",
    "        if not blocks: return []\n",
    "        bl = sorted(blocks, key=lambda b: b['bbox'][1])\n",
    "        lines, curr = [], [bl[0]]\n",
    "        base_y = bl[0]['bbox'][1]\n",
    "        for b in bl[1:]:\n",
    "            if abs(b['bbox'][1] - base_y) <= yth:\n",
    "                curr.append(b)\n",
    "            else:\n",
    "                lines.append(' '.join([c['text'] for c in sorted(curr, key=lambda x: x['bbox'][0])]))\n",
    "                curr, base_y = [b], b['bbox'][1]\n",
    "        lines.append(' '.join([c['text'] for c in sorted(curr, key=lambda x: x['bbox'][0])]))\n",
    "        return lines\n",
    "\n",
    "    def extract_directory_entries(self, img_path: Path, page: int) -> Tuple[List[DirectoryEntry], Dict]:\n",
    "        start = time.time()\n",
    "        img = cv2.imread(str(img_path))\n",
    "        proc = ImagePreprocessor.preprocess(img)\n",
    "        h, w = proc.shape\n",
    "        # tile OCR\n",
    "        blocks = []\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "            futures = []\n",
    "            for y in range(0, h, TILE_SIZE[1]):\n",
    "                for x in range(0, w, TILE_SIZE[0]):\n",
    "                    tile = proc[y:min(y+TILE_SIZE[1],h), x:min(x+TILE_SIZE[0],w)]\n",
    "                    futures.append(ex.submit(self.manager.extract_blocks, tile))\n",
    "            for f in futures:\n",
    "                blocks.extend(f.result())\n",
    "        merged = self._merge_blocks(blocks)\n",
    "        lines = self._group_lines(merged)\n",
    "        entries = []\n",
    "        for ln in lines:\n",
    "            if len(ln) > 10:\n",
    "                ent = self.parser.parse_line(ln)\n",
    "                if ent and ent.confidence_score >= MIN_CONFIDENCE:\n",
    "                    ent.page_number = page\n",
    "                    entries.append(ent)\n",
    "        stats = {'time': time.time()-start, 'blocks': len(blocks), 'entries': len(entries)}\n",
    "        return entries, stats\n",
    "\n",
    "    def save_results(self, entries: List[DirectoryEntry], out_path: Path):\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([asdict(e) for e in entries], f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ——— MAIN ———\n",
    "def main():\n",
    "    if not IMAGE_PATH.exists():\n",
    "        logger.error(f\"Image not found: {IMAGE_PATH}\")\n",
    "        return\n",
    "    ocr = AdvancedHistoricalOCR()\n",
    "    entries, stats = ocr.extract_directory_entries(IMAGE_PATH, page=104)\n",
    "    ocr.save_results(entries, OUTPUT_FILE)\n",
    "    logger.info(f\"Extracted {stats['entries']} entries in {stats['time']:.2f}s → {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f522b16-98ca-4978-bb36-b6fb4cb1b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1862 words → clustering into regions…\n",
      "Formed 19 text‐dense regions (eps=100, min_samples=5).\n",
      "\n",
      "--- Region 1 (5 words) ---\n",
      "VN YOU\n",
      "us for an\n",
      "r income.\n",
      "\n",
      "--- Region 2 (5 words) ---\n",
      "ENNEP\n",
      "BENREF\n",
      "SAVINGS & LOAN ASSOCIATION\n",
      "\n",
      "--- Region 3 (135 words) ---\n",
      "oducts | BARTLETT\n",
      "\" D E r22 Washn av S\n",
      ": 7612 ;}\"\" Donald S (Katharine) treas W A White Brokerage\n",
      "Co h810 Pence bidg\n",
      "h3945 |\" Douglas W (Phyllis M) driver Harry W Smith Co\n",
      "h1010 20th av NE\n",
      "\" Karle W (Effie) pharmacist Zwisler Pharmacy\n",
      "n4448 Ist av S\n",
      "\" Edw G (Edith) pntr h2420 Oakland ay\n",
      "\" Eliz hd409 Dupont av S\n",
      "nerson |\"! Emelie T Mrs rd10 Groveland av\n",
      "\" Emory W (Leah N) driver Norris Creameries\n",
      "Inc h n3425 Sheridan av N\n",
      "\" Gertrude E slswn Amluxen Co r922 E 24th\n",
      "\" Horace L (Mary A) pntr 601 E 22d h do\n",
      "t r211/\" Irving J (Lillian F) pres Calhoun Sales Inc h\n",
      "105 W Minnehaha pkwy\n",
      "1 Ser-|' Irving J jr treas Calhoun Sales Inc r105 W\n",
      "Minnehaha pkwy\n",
      "\" Jas W mach opr r5031 Colfax av S\n",
      "ke apt)\" John clk Acme Hotel r22314 Marquette av\n",
      "\" John W fire motor opr h4231 Ist av S\n",
      "\" June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "vaoor |}! LE M Co Lawrence M Bartlett mgr power plant\n",
      "\n",
      "--- Region 4 (344 words) ---\n",
      "} | BARTH Bartholomew Adeline R Mrs asmblr Melco Products\n",
      "\" Co Inc J Guy Enos pres-treas Mrs Dorothy D r2540 4th av §\n",
      "Enos v-pres Bertil H Larson sec jwlr mfrs 29|'\" ‘Allen (Agnes) driver Widholm Transfer r612\n",
      ") Glenwood ay 13th av 8\n",
      "\" Edna counterwn Grain Exchange Lunch 12708 |\" Ann M (wid Claude A) elk US Treas Dept h3945\n",
      "} Grand av. Bryant av S apt 10\n",
      "\" Esther E (wid Champ) mach opr hd5426 Hamp-|' Ardys M clk Tel Co r211 W 31st\n",
      "shire dr \" Aug J (Florence M) driver h1407 S 8th\n",
      "\" Geo A (Eleanor A) h3549 10th av S apt 3 “ Barbara slswn r1821 Emerson av S\n",
      "\"' Geo F (Martha A) slsmn McCaskey Register Co|' Bert (Betty) driver h2959 Aldrich av N\n",
      "h1611 Bryant av N \" Bohn e (Effie L) electn CB&Q h2709 Emerson\n",
      "\" Gertrude A (wid Leo T) bkpr h2206 N ay .\n",
      "\" Helen TTuieH “pe see eeeee he ae Queen av Ning Lewis jr (Cath 1). pres Bart Supplies Inc h\n",
      "\" Jennie waitress Strom’s Coffee Shop 12635 Har- :\n",
      "mae we s Strom’s Coffee Shop 12635 Har \" ari Ww (Alice) r211 bel 31st . 5\n",
      "a Lawrence J clk rl'611 Bryant av N arte rs asst cook Community Chest r211\n",
      "aw. A 3 .\n",
      "Laster 6 (Edna) driver Gen] Paper 12708 Grand | ,, Clarence F (Mary ; Bartholomew Standard Ser-\n",
      "i Mary Ww elk Travelers rl611 Bryant av N_ \" oe aie wastes av §\n",
      "| ; “ches Co 303 Pee er Haston Barington |< metry J (Mardelle J) sign pntr hl27 W Lake apt\n",
      "alph sten Soo Li 2 Clif F y feat :\n",
      "\"Tena J caterer 4436 Aldrich av 8 1 do cc See FY pai Donat G) MAC Wallow ant 6\n",
      ". . : rwin (Irene) h1350 Russell av N\n",
      "Barthany Edwin J (Emily C) h3027 22d av S '' Ethel M sten Langdon-Warren Mines h4325\n",
      "Barthe Lynn E Mrs sten Dunham-Scott r Hotel Bryant av S apt 35\n",
      "fuller Py] B ; h ' :\n",
      "‘| Barthel Alois N hlpr h3511 Newton av N Sere Ft ng) ofe Whe Bart supplies\n",
      "\" Allo 1. (Morente A) lab Northrup King h754|\" Wioyd A (Marie) crater Bemis Bro h615 James\n",
      "af N\n",
      ". u Beralee C tech Benson Optical r3511 Newton avin Fred R (Stella L) prntr h2501 Irving av S\n",
      "= \" Fr Nellie E) h2707\n",
      "\"| \" Chas ctr Royal Stationery & Prig r RD 1)\" Geraldine M studt 13048 ITin ay S me\n",
      "New Brighton \" Harold (Eleanor) shipping clk h910 21st av S\n",
      "\" Cherry studt h2440 Blaisdell av \" Harris (Gussie) dockmn Widholm Transfer h\n",
      "\"Clara M emp Fanny Farmer 13511 Newton av N 1303 S 6th\n",
      "\" Dorothy emp Pako Corp r919 University av|' Ida L (wid Robt) h612 13th av S\n",
      "NE “ Jack O (Viola M) mech Norris Creameries r\n",
      "\" Edwin N (Florence) unloader Genl Mills r Al- 1201 W 28th\n",
      "-f  __bertville © = ~~ | John (Esther) asmblr h1325 LaSalle av apt B\n",
      "\n",
      "--- Region 5 (5 words) ---\n",
      "_&\n",
      "\n",
      "--- Region 6 (42 words) ---\n",
      "\" John W fire motor opr h4231 Ist av S\n",
      "\" June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "\"LM Co Lawrence M Bartlett mgr power plant\n",
      "equip 517 'N 3d\n",
      "\" Lawrence M mgr L M Bartleit Co r Brown-\n",
      "dale Pk\n",
      "\" horsains D clk Minn Mil Dist (USA) 2229 N\n",
      "6th\n",
      "\" Malcolm W (Irene) mgr Schaecher-Kux Lumber\n",
      "Cor StPaul\n",
      "\" Mary E ofc sec Springfield Fire & Marine Ins\n",
      "ri231 1st av S\n",
      "\" Mavis E Mrs tchr Blaine Sch r3507 Newton av\n",
      "\n",
      "--- Region 7 (25 words) ---\n",
      "os Fuller -\n",
      "Distributed by | Barthel Alois N hip:\n",
      "Wy\n",
      "MINNEAPOLIS ANS J Mblorence\n",
      "CITY a DIST. \" Bernice C tech Be\n",
      ". N\n",
      "1507 So. 6th St. ™ Chas ctr Royal\n",
      "CORNELIUS New Brighton\n",
      "BEVERAGE CO. \" Cherry studt h244\n",
      "6315 Cedar Ave. \"Clara M emp Fant\n",
      "So ' Dorothy emp Pal\n",
      "\n",
      "--- Region 8 (942 words) ---\n",
      "NO ORE RRNA eS Tar ee | meee AEM OO TAR AR Rie Meee SO Ae - Free: au (Nellie E) h27 irl 4rvillg ad¥ © Co r StPaul -\n",
      "\"Chas ctr Royal Stationery & Prig r RD 1}1 Geraldine M studt 13948 I7th ars) “ Maty Ei bie see Sprihgield Wire & Murine Ins\n",
      "aw. meoton. ; \" Harold (Eleanor) shipping clk h910 21st av S|\" Mavis E Mrs tchr Blaine Sch r3507 Newt\n",
      "i. cherry stunt ise Blaisdell ar Newt \" \" ec Kegs) dockmn Widholm Transfer h N Saree: ee\n",
      "\"Clara M emp Fanny Farmer r Newton av N 3 \" ill j i i i\n",
      "t! Bovey emp Pako Corp r919 University avi\" Ida L (wid Robt) h612 13th av S eer oeistae (aiiidred) chief Nopkalser BHA =\n",
      "tt Edwin N (Florence) unloader Gen] Mills r Al- \" sa ae Wy ORI M) mech Norris Creameries T |\" ee usher Campus Theatre 1710 SE Dela-\n",
      "bertville \" John (Esther) asmblr h1325 LaSalle av apt B \" Ollie € Margt 26!\n",
      "7 Heanor © pet Miss Morris Candies 13511 New- |\" John x. folctte) sec-treas Frank Karker Co|\" Ora H nny ives bisa Ne Main av SE\n",
      "No Inc 15 Bloomington av \" Orval H (J iv i\n",
      "u is pie ae Mayme Hoye Cinrs hi\" ieuuen E (Evelyn A) reprmn Tel Co 4820 4324 ine oe Henry Mengelkoch Co b\n",
      "etl ryant av 8S \" ;\n",
      "\" Francis D clk Texas Co r1938 W Bway ' Leo J supt Pullman Co r StPaul Pearl rs27 38th E * ’ ~\n",
      "\"Fredk J (Grace A) purch agt hal49 Wash- |» Mardelle J Mrs cash HJ Minar Co bi27 WLake|| P@azl,V Mrs mangle girl Garber’s Inc r#815\n",
      "; . apt 21 We: ‘ ; '\n",
      "\" Gilbert mach Char-Lynn Co r Edina \" Patricia clk Buttrey Stores r4401 Washburn av Phyllis M Mrs clk Northrup King b1010 20th\n",
      "\" Harold plmbr Wm A Quinn 1910 Portland av apt Ss \" Reva J (Mildred E) n4047 T\n",
      "4 6 . ; \" Paul W (Virginia C) asst sls mgr Minn & On-|\" Robt B (Lorraine K) ak k die a N\n",
      "Harriet E sorter Investors Diversified Serv tario Paper h5940 10th av S \" Robt H (Gertrude; Twent PFO th St Tire C\n",
      "\" pane? Dupont ay. Ss \" Raymond (Rose M) roofer hi227 S 6th r Spring Park ’ Ze ire Co)\n",
      "\"Horie (Genorive W) taster Mle Glass |” \"'Brvant a's apie’ OM BEETS 79945) nobt Vera AS e150 Content a\n",
      "3606 Irving ay N r ryant av S apt 10 \" Roscoe W (Bernice S) hipr NPRy h3523 N 4th\n",
      "Roberta waitress Kresge’s r1303 6th \" Ruth M nursé h3337 Bloomingto t 1\n",
      "\" Herman T (Ella) paper ctr h3850 Portland av \" Rose (wid Jos) h2540 4th av S \" Rutherford J elev opr Lbr Exch bldg 1408 27th\n",
      "Ton Irma A mach opr r3511 Newton av N BARTHOLOMEW STANDARD SERVICE (Clar- av NE\n",
      "Jas M (Mary) clk Royal Stationery & Prntg ence F Bartholomew), Washing, Greasing, |'' Shirley clk h611 Ridgewood av apt 207\n",
      "1 174606 ‘Camden av ; Atlas Tires, Also Accessories 4453 Nicollet av, |'' Theo elevator opr 12300 5th av S\n",
      "Johannes dairy wkr Franklin Co-op Crmy h Tel Regent 8643 \" Thos E (Dorothy B) eng Gen! Hosp h4609 Xerxes\n",
      "pated Waa eh)” wide 13005, § g | Feist aenmapin art TBD ® ae\n",
      ": 5 Emerson av r12 ennepin av \" Vivian M M h 282 a\n",
      "\" ‘eander 7 enor) ee Geo A Clark &|\" Vernal = (Bernadette L) city policemn h2905 |\" Walter (Mary E) seo OMlisen Willan Go bs031\n",
      "; , , remont av Colf\n",
      "\"Leo M (Margt) mach Mpls Moline h1938 W/|\" Wm N (Clara) pntr h211 W 31st \" We Ht ibell: E) carrier PO h710 Delaware\n",
      "a Bway Bartholow Harold E (Verna) parts mgr Lake St|\"\" Wm M (Shirley A) collr Mutual Serv Corp h\n",
      "\" LeRoy H emp Pako Corp r919 University ay NE Pontiac r RD 3 Anoka 4639 Pleasant av\n",
      "otet a oer Eliz Kenny Institute r3511 New- \" Robt Ge ear a emp Mols Gas ria6 E 18th apt 3|\" Willie M (Freda) h4407 Irving av N\n",
      ". Robt | ut! social wkr h2315 Girard av S i\n",
      "y Martha B mach 13511 Newton av N \" Ruth E Mzs sten Osborne McMillan 1736 E BAECS jane, Mme Gol Myndall Calm Beauty\n",
      "1 a) av Le ap Wy ; $ 7 49\n",
      "\" Nellie M Mrs h1100 WB Carrie (wid John) 13937 20th av S\n",
      "\" Norbert L (Cecilia) sismn Massolt Bilg r St Bartviachy t Eau claire Wis Stockland Road yu ae W Sue! Sa Bartley: ales Boy) bles\n",
      "nv sphtichacl . Bartko Alberta R acct 72421 Butler pl \" Brencis -R {Lois A) mtcemn Clty Div Pub Re\n",
      "n ae mae (Coltetey Newiat ay a i nt Andrew (gait) mildr Cheney Fdry h701 Laurel lief h8417 22d av S = °\n",
      ") Masso Ig r av W ap Wy ield 60!\n",
      "wv yaatbertvitle - __|\" Arnold tech Boos Dental Laby 2421 Butler pl{n Hored a dyer 1) eh Pati osth av §\n",
      "ars = te M) sls asst Intl Milling h3355 |\" Paul (Agnes M) formn Cheney Fdry h261 20th av|\" John J (Olga) partsmn h1415 Grand i NE\n",
      "\" Walter J (Helen 8) loader h2314 N 4th \" John (Mary) h66 27th av SE iy QoUn F abade maa0s Jam ay 8 apt st\n",
      "\"Walter M (Agnes M) grinder h919 Univ av|\" John (Minite) mldr Acme Fdry h930 21st av S| Leys EB mes oF) alk Western Walon, HAe0s\n",
      "Bantneld Robt F lab Wabash Screen Door r RD 3/1\"! Jonn careken ¥2421 Butler pl \" hems Mae) Scy sistan Teh Consens Newton\n",
      "sseo it . A ; : ay | ;\n",
      "Barthell Kathleen tel opr r2432 Girard av § , Jobn jr (Mary) oiler h66 27th av SE | = =|\" Margie S Mrs (Bartley Sales Co) h120 Groveland\n",
      "Barthelme Laura M tchr r4024 Pleasiat ay Mea Mins fcty wer Keller Mig BGG 27th, ar ay\n",
      "Barthine Elaine clk Land O’Lakes 12644 Harriet |\" i ] \" Maynard M (Ellrith M) ofc wkr h2630 Grand av\n",
      "Bartel. Ueeia a (Rozalia I) buyer Aslesen Co Mathew (Anna) sectionmn TCRT h2421 Butler | , nerien K (Mary J) slsmn Kee-Lox Mfg h700\n",
      "2628 Humboldt av S \" Minnie of i‘ Organ av\n",
      "\" hay E (Margt). dictating machs 616 Bldrs Exch |\" Ruth E a av 8 abt 2 \" Sadie J clk Smith Wldg Equip r300 Ridgewood\n",
      "y 8 Fremont av Bartkosk ' av\n",
      "Mm Rogelta I Mrs sten A-D-M h2628 Humboldt av |\" aTavuioad (Lois yt ior 2006. s 344 n do \" nae Co a and Mis Maret & Bartley)\n",
      "Bartle Ervin R (Frances P) supvr US Prod - & sups io\n",
      "Bartholdt Geo C (Sue L) acct Lynn Mfg h3605|\"\" keting Admin Datry Br isi? Washburn av |\" Thos 7 Cite) Durch. agt, DeSote Cemy & Exod\n",
      "Bartholt tate J (wid Warren) h3341 University |\" Rey E chemist A-D-M 14517 Washburn av § \" Vera hi nurse Eliz Kenny Institute h3713 29th\n",
      ". \" Wm lather Theo S Larson r3101 Girard a BY. : -\n",
      "Barinolnew Thos J Jubemn Slawik Mtrs r Como Sta Hurilenen Haier piler Sayer Gleator apr n934 i Warren a oa Danone 921 i al .\n",
      "4th av 1\n",
      "Bartholoma Irene J Mrs proof rdr Miller Publ h4314 Bartlett Amanda E (wid Henry) h3020 16th av|\" Vitesd F (Gertrude K) pntr 2549 Dupont av S\n",
      "enn av }\n",
      "\" qeaune rear aes penn ay q r \" Anna d, Mrs slswn Sears r1701 Portland av S Ben (Amene) YP Ubatnen ate . R\n",
      "rene electn | C enn av 2 apt 15 artness Roya sther pr Dayton Rogers\n",
      "Haxilolomael Albert H colin mgr Safety Loan h/\" Archie W (Helen A) mtcemn Pure Oi] h1104 § Mfg h315 Knox av N\n",
      "4 nox av 8th Bartnof Morris Rev h1431 James av N\n",
      "Bartholome Earl F (Lauretta) slsmn Insulation|\" Betty J emp Forum Cafeteria 1438 Main NE Barto Edna smstrs h3046 Blaisdell av apt 16\n",
      "n Sls r StLouis Pk ; \" Chas H (Mary) h3918 Vincent av N ' Fred W (Marion M) barber Paris Beauty Salon\n",
      "Judith E slswn Woolworth’s r StLouis Pk \" Claude tstr NSP 112400 Fairfield W h5720 Pillsbury av\n",
      "rc lee it cS A SS SR TE I TT\n",
      "f . k\n",
      "\n",
      "--- Region 9 (10 words) ---\n",
      "Stationery & Pr\n",
      ") Blaisdell av\n",
      "y Farmer r3511 N\n",
      "o Corp r919 Ur\n",
      "2) unloader Genl\n",
      "\n",
      "--- Region 10 (11 words) ---\n",
      "Harold (Eleanor) s\n",
      "Harris (Gussie) dc\n",
      "1303 S 6th\n",
      "Ida L (wid Robt) t\n",
      "Jack O (Viola M)\n",
      "1201 W 28th\n",
      "John (Esther) asmb\n",
      "\n",
      "--- Region 11 (12 words) ---\n",
      "| Newton avy N 13¢\n",
      "University avi\"! Ida I\n",
      "\" Jack\n",
      "nl Mills r Al- 120\n",
      "\" John\n",
      "es 13511 New- |\" John\n",
      "Inc\n",
      "Hoye Clinrs hj\" Kenn\n",
      "\n",
      "--- Region 12 (15 words) ---\n",
      "DAVIDSON\n",
      "DIST. CO. \"\n",
      "332 46th Ave. S.\n",
      "CHARLES \"\n",
      "GANZER DIST. \"\n",
      "co.\n",
      "4239 Russell tt\n",
      "Ave. N. at\n",
      "\n",
      "--- Region 13 (4 words) ---\n",
      "s Theatre\n",
      "in h1i06 2\n",
      "h438 NE MW\n",
      "r Henry\n",
      "\n",
      "--- Region 14 (8 words) ---\n",
      "‘e 1710 SE Dela-\n",
      "26th av SE\n",
      "Main\n",
      "Mengelkoch Co h\n",
      "\n",
      "--- Region 15 (5 words) ---\n",
      "r1303 6th\n",
      "v i$\n",
      "D SERVICE\n",
      "Washing, G\n",
      "ries 4453 Nice\n",
      "\n",
      "--- Region 16 (10 words) ---\n",
      "Freda) h4407 Irvin:\n",
      "ne Mrs opr Mynd\n",
      "032 2d av S\n",
      "| John) £3937 20th\n",
      "Margie S; Bartley\n",
      "1 av\n",
      "(Lois A) mtcemn {\n",
      "\n",
      "--- Region 17 (12 words) ---\n",
      "tip r300 Ridgewood\n",
      "Margie S Bartley).\n",
      "2Soto Crmy & Prod\n",
      "nstitute h3713 29th\n",
      "321 25th av S\n",
      "av Sr do\n",
      "- 2549 Dupont av &\n",
      "\n",
      "--- Region 18 (46 words) ---\n",
      "Warren A (Lucille) slsmn r921 25th av §\n",
      "\" Willard E pntr 2549 Dupont av S r do\n",
      "\" Vitesd F (Gertrude K) pntr 2549 Dupont\n",
      "o\n",
      "\" Wm (Arlene) slsmn r6032 2d av S\n",
      "Bartness Royal V (Esther) hlpr Dayton |]\n",
      "Mfg h315 Knox av iN\n",
      "Bartnof Morris Rev h1431 James av N\n",
      "Barto Edna smstrs h3046 Blaisdell av apt\n",
      "\" Fred W (Marion M) barber Paris Beauty\n",
      "h5720 Pillsbury av\n",
      "\n",
      "--- Region 19 (13 words) ---\n",
      "s r1701 Portland av §\n",
      "‘eemn Pure Oil h1104 S\n",
      "teria r438 Main NE\n",
      "incent av N\n",
      "Fairfield W\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "OCR via word‐box clustering (DBSCAN) → large regions → block OCR.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import DBSCAN\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIG ———\n",
    "IMAGE_PATH    = Path(\"/Users/darshilshukla/Desktop/104.png\")\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "EPS_PIXELS    = 100      # clustering radius (px)\n",
    "MIN_SAMPLES   = 5        # min words to form a region\n",
    "PADDING       = 10       # px padding around each region\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "def get_word_boxes(img: np.ndarray) -> List[WordBox]:\n",
    "    \"\"\"Run Tesseract to get word‐level boxes and confidences.\"\"\"\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT, config=TS_CONFIG)\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        if not txt.strip():\n",
    "            continue\n",
    "        conf = int(data['conf'][i])\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l = data['left'][i]\n",
    "        t = data['top'][i]\n",
    "        w = data['width'][i]\n",
    "        h = data['height'][i]\n",
    "        cx = l + w / 2\n",
    "        cy = t + h / 2\n",
    "        boxes.append(WordBox(txt.strip(), l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "def cluster_regions(boxes: List[WordBox]) -> List[Tuple[int,int,int,int,List[WordBox]]]:\n",
    "    \"\"\"\n",
    "    DBSCAN cluster on the word‐centroids (cx,cy), then compute\n",
    "    one bounding box per cluster plus the list of member WordBoxes.\n",
    "    \"\"\"\n",
    "    pts = np.array([[b.cx, b.cy] for b in boxes])\n",
    "    db = DBSCAN(eps=EPS_PIXELS, min_samples=MIN_SAMPLES).fit(pts)\n",
    "    labels = db.labels_\n",
    "    regions = {}\n",
    "    for lbl, wb in zip(labels, boxes):\n",
    "        if lbl == -1:\n",
    "            continue\n",
    "        regions.setdefault(lbl, []).append(wb)\n",
    "    out = []\n",
    "    for members in regions.values():\n",
    "        xs = [b.left for b in members] + [b.left + b.width for b in members]\n",
    "        ys = [b.top  for b in members] + [b.top  + b.height for b in members]\n",
    "        x1, x2 = min(xs), max(xs)\n",
    "        y1, y2 = min(ys), max(ys)\n",
    "        out.append((x1, y1, x2 - x1, y2 - y1, members))\n",
    "    # sort top→bottom, left→right\n",
    "    out.sort(key=lambda r: (r[1], r[0]))\n",
    "    return out\n",
    "\n",
    "def ocr_block(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    \"\"\"Crop + OCR block → return non‐empty lines.\"\"\"\n",
    "    x, y, w, h = region\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "def main():\n",
    "    img = cv2.imread(str(IMAGE_PATH))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot load image: {IMAGE_PATH}\")\n",
    "\n",
    "    # 1) Preprocess lightly to help Tesseract word detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2) Get word boxes\n",
    "    word_boxes = get_word_boxes(gray)\n",
    "    print(f\"Detected {len(word_boxes)} words → clustering into regions…\")\n",
    "\n",
    "    # 3) Cluster into large regions\n",
    "    regions = cluster_regions(word_boxes)\n",
    "    print(f\"Formed {len(regions)} text‐dense regions (eps={EPS_PIXELS}, min_samples={MIN_SAMPLES}).\\n\")\n",
    "\n",
    "    # 4) OCR each region as a block\n",
    "    all_lines = []\n",
    "    for idx, (x, y, w, h, members) in enumerate(regions, 1):\n",
    "        # apply padding\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(img.shape[1], x + w + PADDING)\n",
    "        yb = min(img.shape[0], y + h + PADDING)\n",
    "\n",
    "        lines = ocr_block(img, (xa, ya, xb-xa, yb-ya))\n",
    "        print(f\"--- Region {idx} ({len(members)} words) ---\")\n",
    "        for ln in lines:\n",
    "            print(ln)\n",
    "        print()\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "    # 5) (Optional) You now have `all_lines` as your final text.\n",
    "    # You can further dedupe or resort if needed.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b58751-fe25-49cd-9114-84829568019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1862 words → clustering into regions…\n",
      "Formed 19 text‐dense regions (eps=100, min_samples=5).\n",
      "\n",
      "--- Region 1 (5 words) ---\n",
      "VN YOU\n",
      "us for an\n",
      "r income.\n",
      "\n",
      "--- Region 2 (5 words) ---\n",
      "ENNEP\n",
      "BENREF\n",
      "SAVINGS & LOAN ASSOCIATION\n",
      "\n",
      "--- Region 3 (135 words) ---\n",
      "oducts | BARTLETT\n",
      "\" D E r22 Washn av S\n",
      ": 7612 ;}\"\" Donald S (Katharine) treas W A White Brokerage\n",
      "Co h810 Pence bidg\n",
      "h3945 |\" Douglas W (Phyllis M) driver Harry W Smith Co\n",
      "h1010 20th av NE\n",
      "\" Karle W (Effie) pharmacist Zwisler Pharmacy\n",
      "n4448 Ist av S\n",
      "\" Edw G (Edith) pntr h2420 Oakland ay\n",
      "\" Eliz hd409 Dupont av S\n",
      "nerson |\"! Emelie T Mrs rd10 Groveland av\n",
      "\" Emory W (Leah N) driver Norris Creameries\n",
      "Inc h n3425 Sheridan av N\n",
      "\" Gertrude E slswn Amluxen Co r922 E 24th\n",
      "\" Horace L (Mary A) pntr 601 E 22d h do\n",
      "t r211/\" Irving J (Lillian F) pres Calhoun Sales Inc h\n",
      "105 W Minnehaha pkwy\n",
      "1 Ser-|' Irving J jr treas Calhoun Sales Inc r105 W\n",
      "Minnehaha pkwy\n",
      "\" Jas W mach opr r5031 Colfax av S\n",
      "ke apt)\" John clk Acme Hotel r22314 Marquette av\n",
      "\" John W fire motor opr h4231 Ist av S\n",
      "\" June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "vaoor |}! LE M Co Lawrence M Bartlett mgr power plant\n",
      "\n",
      "--- Region 4 (344 words) ---\n",
      "} | BARTH Bartholomew Adeline R Mrs asmblr Melco Products\n",
      "\" Co Inc J Guy Enos pres-treas Mrs Dorothy D r2540 4th av §\n",
      "Enos v-pres Bertil H Larson sec jwlr mfrs 29|'\" ‘Allen (Agnes) driver Widholm Transfer r612\n",
      ") Glenwood ay 13th av 8\n",
      "\" Edna counterwn Grain Exchange Lunch 12708 |\" Ann M (wid Claude A) elk US Treas Dept h3945\n",
      "} Grand av. Bryant av S apt 10\n",
      "\" Esther E (wid Champ) mach opr hd5426 Hamp-|' Ardys M clk Tel Co r211 W 31st\n",
      "shire dr \" Aug J (Florence M) driver h1407 S 8th\n",
      "\" Geo A (Eleanor A) h3549 10th av S apt 3 “ Barbara slswn r1821 Emerson av S\n",
      "\"' Geo F (Martha A) slsmn McCaskey Register Co|' Bert (Betty) driver h2959 Aldrich av N\n",
      "h1611 Bryant av N \" Bohn e (Effie L) electn CB&Q h2709 Emerson\n",
      "\" Gertrude A (wid Leo T) bkpr h2206 N ay .\n",
      "\" Helen TTuieH “pe see eeeee he ae Queen av Ning Lewis jr (Cath 1). pres Bart Supplies Inc h\n",
      "\" Jennie waitress Strom’s Coffee Shop 12635 Har- :\n",
      "mae we s Strom’s Coffee Shop 12635 Har \" ari Ww (Alice) r211 bel 31st . 5\n",
      "a Lawrence J clk rl'611 Bryant av N arte rs asst cook Community Chest r211\n",
      "aw. A 3 .\n",
      "Laster 6 (Edna) driver Gen] Paper 12708 Grand | ,, Clarence F (Mary ; Bartholomew Standard Ser-\n",
      "i Mary Ww elk Travelers rl611 Bryant av N_ \" oe aie wastes av §\n",
      "| ; “ches Co 303 Pee er Haston Barington |< metry J (Mardelle J) sign pntr hl27 W Lake apt\n",
      "alph sten Soo Li 2 Clif F y feat :\n",
      "\"Tena J caterer 4436 Aldrich av 8 1 do cc See FY pai Donat G) MAC Wallow ant 6\n",
      ". . : rwin (Irene) h1350 Russell av N\n",
      "Barthany Edwin J (Emily C) h3027 22d av S '' Ethel M sten Langdon-Warren Mines h4325\n",
      "Barthe Lynn E Mrs sten Dunham-Scott r Hotel Bryant av S apt 35\n",
      "fuller Py] B ; h ' :\n",
      "‘| Barthel Alois N hlpr h3511 Newton av N Sere Ft ng) ofe Whe Bart supplies\n",
      "\" Allo 1. (Morente A) lab Northrup King h754|\" Wioyd A (Marie) crater Bemis Bro h615 James\n",
      "af N\n",
      ". u Beralee C tech Benson Optical r3511 Newton avin Fred R (Stella L) prntr h2501 Irving av S\n",
      "= \" Fr Nellie E) h2707\n",
      "\"| \" Chas ctr Royal Stationery & Prig r RD 1)\" Geraldine M studt 13048 ITin ay S me\n",
      "New Brighton \" Harold (Eleanor) shipping clk h910 21st av S\n",
      "\" Cherry studt h2440 Blaisdell av \" Harris (Gussie) dockmn Widholm Transfer h\n",
      "\"Clara M emp Fanny Farmer 13511 Newton av N 1303 S 6th\n",
      "\" Dorothy emp Pako Corp r919 University av|' Ida L (wid Robt) h612 13th av S\n",
      "NE “ Jack O (Viola M) mech Norris Creameries r\n",
      "\" Edwin N (Florence) unloader Genl Mills r Al- 1201 W 28th\n",
      "-f  __bertville © = ~~ | John (Esther) asmblr h1325 LaSalle av apt B\n",
      "\n",
      "--- Region 5 (5 words) ---\n",
      "_&\n",
      "\n",
      "--- Region 6 (42 words) ---\n",
      "\" John W fire motor opr h4231 Ist av S\n",
      "\" June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "\"LM Co Lawrence M Bartlett mgr power plant\n",
      "equip 517 'N 3d\n",
      "\" Lawrence M mgr L M Bartleit Co r Brown-\n",
      "dale Pk\n",
      "\" horsains D clk Minn Mil Dist (USA) 2229 N\n",
      "6th\n",
      "\" Malcolm W (Irene) mgr Schaecher-Kux Lumber\n",
      "Cor StPaul\n",
      "\" Mary E ofc sec Springfield Fire & Marine Ins\n",
      "ri231 1st av S\n",
      "\" Mavis E Mrs tchr Blaine Sch r3507 Newton av\n",
      "\n",
      "--- Region 7 (25 words) ---\n",
      "os Fuller -\n",
      "Distributed by | Barthel Alois N hip:\n",
      "Wy\n",
      "MINNEAPOLIS ANS J Mblorence\n",
      "CITY a DIST. \" Bernice C tech Be\n",
      ". N\n",
      "1507 So. 6th St. ™ Chas ctr Royal\n",
      "CORNELIUS New Brighton\n",
      "BEVERAGE CO. \" Cherry studt h244\n",
      "6315 Cedar Ave. \"Clara M emp Fant\n",
      "So ' Dorothy emp Pal\n",
      "\n",
      "--- Region 8 (942 words) ---\n",
      "NO ORE RRNA eS Tar ee | meee AEM OO TAR AR Rie Meee SO Ae - Free: au (Nellie E) h27 irl 4rvillg ad¥ © Co r StPaul -\n",
      "\"Chas ctr Royal Stationery & Prig r RD 1}1 Geraldine M studt 13948 I7th ars) “ Maty Ei bie see Sprihgield Wire & Murine Ins\n",
      "aw. meoton. ; \" Harold (Eleanor) shipping clk h910 21st av S|\" Mavis E Mrs tchr Blaine Sch r3507 Newt\n",
      "i. cherry stunt ise Blaisdell ar Newt \" \" ec Kegs) dockmn Widholm Transfer h N Saree: ee\n",
      "\"Clara M emp Fanny Farmer r Newton av N 3 \" ill j i i i\n",
      "t! Bovey emp Pako Corp r919 University avi\" Ida L (wid Robt) h612 13th av S eer oeistae (aiiidred) chief Nopkalser BHA =\n",
      "tt Edwin N (Florence) unloader Gen] Mills r Al- \" sa ae Wy ORI M) mech Norris Creameries T |\" ee usher Campus Theatre 1710 SE Dela-\n",
      "bertville \" John (Esther) asmblr h1325 LaSalle av apt B \" Ollie € Margt 26!\n",
      "7 Heanor © pet Miss Morris Candies 13511 New- |\" John x. folctte) sec-treas Frank Karker Co|\" Ora H nny ives bisa Ne Main av SE\n",
      "No Inc 15 Bloomington av \" Orval H (J iv i\n",
      "u is pie ae Mayme Hoye Cinrs hi\" ieuuen E (Evelyn A) reprmn Tel Co 4820 4324 ine oe Henry Mengelkoch Co b\n",
      "etl ryant av 8S \" ;\n",
      "\" Francis D clk Texas Co r1938 W Bway ' Leo J supt Pullman Co r StPaul Pearl rs27 38th E * ’ ~\n",
      "\"Fredk J (Grace A) purch agt hal49 Wash- |» Mardelle J Mrs cash HJ Minar Co bi27 WLake|| P@azl,V Mrs mangle girl Garber’s Inc r#815\n",
      "; . apt 21 We: ‘ ; '\n",
      "\" Gilbert mach Char-Lynn Co r Edina \" Patricia clk Buttrey Stores r4401 Washburn av Phyllis M Mrs clk Northrup King b1010 20th\n",
      "\" Harold plmbr Wm A Quinn 1910 Portland av apt Ss \" Reva J (Mildred E) n4047 T\n",
      "4 6 . ; \" Paul W (Virginia C) asst sls mgr Minn & On-|\" Robt B (Lorraine K) ak k die a N\n",
      "Harriet E sorter Investors Diversified Serv tario Paper h5940 10th av S \" Robt H (Gertrude; Twent PFO th St Tire C\n",
      "\" pane? Dupont ay. Ss \" Raymond (Rose M) roofer hi227 S 6th r Spring Park ’ Ze ire Co)\n",
      "\"Horie (Genorive W) taster Mle Glass |” \"'Brvant a's apie’ OM BEETS 79945) nobt Vera AS e150 Content a\n",
      "3606 Irving ay N r ryant av S apt 10 \" Roscoe W (Bernice S) hipr NPRy h3523 N 4th\n",
      "Roberta waitress Kresge’s r1303 6th \" Ruth M nursé h3337 Bloomingto t 1\n",
      "\" Herman T (Ella) paper ctr h3850 Portland av \" Rose (wid Jos) h2540 4th av S \" Rutherford J elev opr Lbr Exch bldg 1408 27th\n",
      "Ton Irma A mach opr r3511 Newton av N BARTHOLOMEW STANDARD SERVICE (Clar- av NE\n",
      "Jas M (Mary) clk Royal Stationery & Prntg ence F Bartholomew), Washing, Greasing, |'' Shirley clk h611 Ridgewood av apt 207\n",
      "1 174606 ‘Camden av ; Atlas Tires, Also Accessories 4453 Nicollet av, |'' Theo elevator opr 12300 5th av S\n",
      "Johannes dairy wkr Franklin Co-op Crmy h Tel Regent 8643 \" Thos E (Dorothy B) eng Gen! Hosp h4609 Xerxes\n",
      "pated Waa eh)” wide 13005, § g | Feist aenmapin art TBD ® ae\n",
      ": 5 Emerson av r12 ennepin av \" Vivian M M h 282 a\n",
      "\" ‘eander 7 enor) ee Geo A Clark &|\" Vernal = (Bernadette L) city policemn h2905 |\" Walter (Mary E) seo OMlisen Willan Go bs031\n",
      "; , , remont av Colf\n",
      "\"Leo M (Margt) mach Mpls Moline h1938 W/|\" Wm N (Clara) pntr h211 W 31st \" We Ht ibell: E) carrier PO h710 Delaware\n",
      "a Bway Bartholow Harold E (Verna) parts mgr Lake St|\"\" Wm M (Shirley A) collr Mutual Serv Corp h\n",
      "\" LeRoy H emp Pako Corp r919 University ay NE Pontiac r RD 3 Anoka 4639 Pleasant av\n",
      "otet a oer Eliz Kenny Institute r3511 New- \" Robt Ge ear a emp Mols Gas ria6 E 18th apt 3|\" Willie M (Freda) h4407 Irving av N\n",
      ". Robt | ut! social wkr h2315 Girard av S i\n",
      "y Martha B mach 13511 Newton av N \" Ruth E Mzs sten Osborne McMillan 1736 E BAECS jane, Mme Gol Myndall Calm Beauty\n",
      "1 a) av Le ap Wy ; $ 7 49\n",
      "\" Nellie M Mrs h1100 WB Carrie (wid John) 13937 20th av S\n",
      "\" Norbert L (Cecilia) sismn Massolt Bilg r St Bartviachy t Eau claire Wis Stockland Road yu ae W Sue! Sa Bartley: ales Boy) bles\n",
      "nv sphtichacl . Bartko Alberta R acct 72421 Butler pl \" Brencis -R {Lois A) mtcemn Clty Div Pub Re\n",
      "n ae mae (Coltetey Newiat ay a i nt Andrew (gait) mildr Cheney Fdry h701 Laurel lief h8417 22d av S = °\n",
      ") Masso Ig r av W ap Wy ield 60!\n",
      "wv yaatbertvitle - __|\" Arnold tech Boos Dental Laby 2421 Butler pl{n Hored a dyer 1) eh Pati osth av §\n",
      "ars = te M) sls asst Intl Milling h3355 |\" Paul (Agnes M) formn Cheney Fdry h261 20th av|\" John J (Olga) partsmn h1415 Grand i NE\n",
      "\" Walter J (Helen 8) loader h2314 N 4th \" John (Mary) h66 27th av SE iy QoUn F abade maa0s Jam ay 8 apt st\n",
      "\"Walter M (Agnes M) grinder h919 Univ av|\" John (Minite) mldr Acme Fdry h930 21st av S| Leys EB mes oF) alk Western Walon, HAe0s\n",
      "Bantneld Robt F lab Wabash Screen Door r RD 3/1\"! Jonn careken ¥2421 Butler pl \" hems Mae) Scy sistan Teh Consens Newton\n",
      "sseo it . A ; : ay | ;\n",
      "Barthell Kathleen tel opr r2432 Girard av § , Jobn jr (Mary) oiler h66 27th av SE | = =|\" Margie S Mrs (Bartley Sales Co) h120 Groveland\n",
      "Barthelme Laura M tchr r4024 Pleasiat ay Mea Mins fcty wer Keller Mig BGG 27th, ar ay\n",
      "Barthine Elaine clk Land O’Lakes 12644 Harriet |\" i ] \" Maynard M (Ellrith M) ofc wkr h2630 Grand av\n",
      "Bartel. Ueeia a (Rozalia I) buyer Aslesen Co Mathew (Anna) sectionmn TCRT h2421 Butler | , nerien K (Mary J) slsmn Kee-Lox Mfg h700\n",
      "2628 Humboldt av S \" Minnie of i‘ Organ av\n",
      "\" hay E (Margt). dictating machs 616 Bldrs Exch |\" Ruth E a av 8 abt 2 \" Sadie J clk Smith Wldg Equip r300 Ridgewood\n",
      "y 8 Fremont av Bartkosk ' av\n",
      "Mm Rogelta I Mrs sten A-D-M h2628 Humboldt av |\" aTavuioad (Lois yt ior 2006. s 344 n do \" nae Co a and Mis Maret & Bartley)\n",
      "Bartle Ervin R (Frances P) supvr US Prod - & sups io\n",
      "Bartholdt Geo C (Sue L) acct Lynn Mfg h3605|\"\" keting Admin Datry Br isi? Washburn av |\" Thos 7 Cite) Durch. agt, DeSote Cemy & Exod\n",
      "Bartholt tate J (wid Warren) h3341 University |\" Rey E chemist A-D-M 14517 Washburn av § \" Vera hi nurse Eliz Kenny Institute h3713 29th\n",
      ". \" Wm lather Theo S Larson r3101 Girard a BY. : -\n",
      "Barinolnew Thos J Jubemn Slawik Mtrs r Como Sta Hurilenen Haier piler Sayer Gleator apr n934 i Warren a oa Danone 921 i al .\n",
      "4th av 1\n",
      "Bartholoma Irene J Mrs proof rdr Miller Publ h4314 Bartlett Amanda E (wid Henry) h3020 16th av|\" Vitesd F (Gertrude K) pntr 2549 Dupont av S\n",
      "enn av }\n",
      "\" qeaune rear aes penn ay q r \" Anna d, Mrs slswn Sears r1701 Portland av S Ben (Amene) YP Ubatnen ate . R\n",
      "rene electn | C enn av 2 apt 15 artness Roya sther pr Dayton Rogers\n",
      "Haxilolomael Albert H colin mgr Safety Loan h/\" Archie W (Helen A) mtcemn Pure Oi] h1104 § Mfg h315 Knox av N\n",
      "4 nox av 8th Bartnof Morris Rev h1431 James av N\n",
      "Bartholome Earl F (Lauretta) slsmn Insulation|\" Betty J emp Forum Cafeteria 1438 Main NE Barto Edna smstrs h3046 Blaisdell av apt 16\n",
      "n Sls r StLouis Pk ; \" Chas H (Mary) h3918 Vincent av N ' Fred W (Marion M) barber Paris Beauty Salon\n",
      "Judith E slswn Woolworth’s r StLouis Pk \" Claude tstr NSP 112400 Fairfield W h5720 Pillsbury av\n",
      "rc lee it cS A SS SR TE I TT\n",
      "f . k\n",
      "\n",
      "--- Region 9 (10 words) ---\n",
      "Stationery & Pr\n",
      ") Blaisdell av\n",
      "y Farmer r3511 N\n",
      "o Corp r919 Ur\n",
      "2) unloader Genl\n",
      "\n",
      "--- Region 10 (11 words) ---\n",
      "Harold (Eleanor) s\n",
      "Harris (Gussie) dc\n",
      "1303 S 6th\n",
      "Ida L (wid Robt) t\n",
      "Jack O (Viola M)\n",
      "1201 W 28th\n",
      "John (Esther) asmb\n",
      "\n",
      "--- Region 11 (12 words) ---\n",
      "| Newton avy N 13¢\n",
      "University avi\"! Ida I\n",
      "\" Jack\n",
      "nl Mills r Al- 120\n",
      "\" John\n",
      "es 13511 New- |\" John\n",
      "Inc\n",
      "Hoye Clinrs hj\" Kenn\n",
      "\n",
      "--- Region 12 (15 words) ---\n",
      "DAVIDSON\n",
      "DIST. CO. \"\n",
      "332 46th Ave. S.\n",
      "CHARLES \"\n",
      "GANZER DIST. \"\n",
      "co.\n",
      "4239 Russell tt\n",
      "Ave. N. at\n",
      "\n",
      "--- Region 13 (4 words) ---\n",
      "s Theatre\n",
      "in h1i06 2\n",
      "h438 NE MW\n",
      "r Henry\n",
      "\n",
      "--- Region 14 (8 words) ---\n",
      "‘e 1710 SE Dela-\n",
      "26th av SE\n",
      "Main\n",
      "Mengelkoch Co h\n",
      "\n",
      "--- Region 15 (5 words) ---\n",
      "r1303 6th\n",
      "v i$\n",
      "D SERVICE\n",
      "Washing, G\n",
      "ries 4453 Nice\n",
      "\n",
      "--- Region 16 (10 words) ---\n",
      "Freda) h4407 Irvin:\n",
      "ne Mrs opr Mynd\n",
      "032 2d av S\n",
      "| John) £3937 20th\n",
      "Margie S; Bartley\n",
      "1 av\n",
      "(Lois A) mtcemn {\n",
      "\n",
      "--- Region 17 (12 words) ---\n",
      "tip r300 Ridgewood\n",
      "Margie S Bartley).\n",
      "2Soto Crmy & Prod\n",
      "nstitute h3713 29th\n",
      "321 25th av S\n",
      "av Sr do\n",
      "- 2549 Dupont av &\n",
      "\n",
      "--- Region 18 (46 words) ---\n",
      "Warren A (Lucille) slsmn r921 25th av §\n",
      "\" Willard E pntr 2549 Dupont av S r do\n",
      "\" Vitesd F (Gertrude K) pntr 2549 Dupont\n",
      "o\n",
      "\" Wm (Arlene) slsmn r6032 2d av S\n",
      "Bartness Royal V (Esther) hlpr Dayton |]\n",
      "Mfg h315 Knox av iN\n",
      "Bartnof Morris Rev h1431 James av N\n",
      "Barto Edna smstrs h3046 Blaisdell av apt\n",
      "\" Fred W (Marion M) barber Paris Beauty\n",
      "h5720 Pillsbury av\n",
      "\n",
      "--- Region 19 (13 words) ---\n",
      "s r1701 Portland av §\n",
      "‘eemn Pure Oil h1104 S\n",
      "teria r438 Main NE\n",
      "incent av N\n",
      "Fairfield W\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edd3bf58-835d-4c3d-bf67-2354a160b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1862 words → clustering into regions…\n",
      "Formed 19 text-dense regions\n",
      "\n",
      "Extracted 57 entries:\n",
      "\n",
      "Entry 1: D E r22 Washn av S : 7612 ;}\"\" Donald S (Katharine) treas W A White Brokerage Co h810 Pence bidg h3945 |\" Douglas W (Phyllis M) driver Harry W Smith Co h1010 20th av NE\n",
      "\n",
      "Entry 2: Karle W (Effie) pharmacist Zwisler Pharmacy n4448 Ist av S\n",
      "\n",
      "Entry 3: Edw G (Edith) pntr h2420 Oakland ay\n",
      "\n",
      "Entry 4: Eliz hd409 Dupont av S nerson |\"! Emelie T Mrs rd10 Groveland av\n",
      "\n",
      "Entry 5: Emory W (Leah N) driver Norris Creameries Inc h n3425 Sheridan av N\n",
      "\n",
      "Entry 6: Gertrude E slswn Amluxen Co r922 E 24th\n",
      "\n",
      "Entry 7: Horace L (Mary A) pntr 601 E 22d h do t r211/\" Irving J (Lillian F) pres Calhoun Sales Inc h 105 W Minnehaha pkwy 1 Ser-|' Irving J jr treas Calhoun Sales Inc r105 W Minnehaha pkwy\n",
      "\n",
      "Entry 8: Jas W mach opr r5031 Colfax av S ke apt)\" John clk Acme Hotel r22314 Marquette av\n",
      "\n",
      "Entry 9: John W fire motor opr h4231 Ist av S\n",
      "\n",
      "Entry 10: June Mrs nurse Asbury Hosp h4324 Irving av N vaoor |}! LE M Co Lawrence M Bartlett mgr power plant } | BARTH Bartholomew Adeline R Mrs asmblr Melco Products\n",
      "\n",
      "Entry 11: Co Inc J Guy Enos pres-treas Mrs Dorothy D r2540 4th av § Enos v-pres Bertil H Larson sec jwlr mfrs 29|'\" ‘Allen (Agnes) driver Widholm Transfer r612 ) Glenwood ay 13th av 8\n",
      "\n",
      "Entry 12: Edna counterwn Grain Exchange Lunch 12708 |\" Ann M (wid Claude A) elk US Treas Dept h3945 } Grand av. Bryant av S apt 10\n",
      "\n",
      "Entry 13: Esther E (wid Champ) mach opr hd5426 Hamp-|' Ardys M clk Tel Co r211 W 31st shire dr \" Aug J (Florence M) driver h1407 S 8th\n",
      "\n",
      "Entry 14: Geo A (Eleanor A) h3549 10th av S apt 3 “ Barbara slswn r1821 Emerson av S\n",
      "\n",
      "Entry 15: ' Geo F (Martha A) slsmn McCaskey Register Co|' Bert (Betty) driver h2959 Aldrich av N h1611 Bryant av N \" Bohn e (Effie L) electn CB&Q h2709 Emerson\n",
      "\n",
      "Entry 16: Gertrude A (wid Leo T) bkpr h2206 N ay .\n",
      "\n",
      "Entry 17: Helen TTuieH “pe see eeeee he ae Queen av Ning Lewis jr (Cath 1). pres Bart Supplies Inc h\n",
      "\n",
      "Entry 18: Jennie waitress Strom’s Coffee Shop 12635 Har- : mae we s Strom’s Coffee Shop 12635 Har \" ari Ww (Alice) r211 bel 31st . 5 a Lawrence J clk rl'611 Bryant av N arte rs asst cook Community Chest r211 aw. A 3 . Laster 6 (Edna) driver Gen] Paper 12708 Grand | ,, Clarence F (Mary ; Bartholomew Standard Ser- i Mary Ww elk Travelers rl611 Bryant av N_ \" oe aie wastes av § | ; “ches Co 303 Pee er Haston Barington |< metry J (Mardelle J) sign pntr hl27 W Lake apt alph sten Soo Li 2 Clif F y feat :\n",
      "\n",
      "Entry 19: Tena J caterer 4436 Aldrich av 8 1 do cc See FY pai Donat G) MAC Wallow ant 6 . . : rwin (Irene) h1350 Russell av N Barthany Edwin J (Emily C) h3027 22d av S '' Ethel M sten Langdon-Warren Mines h4325 Barthe Lynn E Mrs sten Dunham-Scott r Hotel Bryant av S apt 35 fuller Py] B ; h ' : ‘| Barthel Alois N hlpr h3511 Newton av N Sere Ft ng) ofe Whe Bart supplies\n",
      "\n",
      "Entry 20: Allo 1. (Morente A) lab Northrup King h754|\" Wioyd A (Marie) crater Bemis Bro h615 James af N . u Beralee C tech Benson Optical r3511 Newton avin Fred R (Stella L) prntr h2501 Irving av S = \" Fr Nellie E) h2707\n",
      "\n",
      "Entry 21: | \" Chas ctr Royal Stationery & Prig r RD 1)\" Geraldine M studt 13048 ITin ay S me New Brighton \" Harold (Eleanor) shipping clk h910 21st av S\n",
      "\n",
      "Entry 22: Cherry studt h2440 Blaisdell av \" Harris (Gussie) dockmn Widholm Transfer h\n",
      "\n",
      "Entry 23: Clara M emp Fanny Farmer 13511 Newton av N 1303 S 6th\n",
      "\n",
      "Entry 24: Dorothy emp Pako Corp r919 University av|' Ida L (wid Robt) h612 13th av S NE “ Jack O (Viola M) mech Norris Creameries r\n",
      "\n",
      "Entry 25: Edwin N (Florence) unloader Genl Mills r Al- 1201 W 28th -f  __bertville © = ~~ | John (Esther) asmblr h1325 LaSalle av apt B _&\n",
      "\n",
      "Entry 26: John W fire motor opr h4231 Ist av S\n",
      "\n",
      "Entry 27: June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "\n",
      "Entry 28: LM Co Lawrence M Bartlett mgr power plant equip 517 'N 3d\n",
      "\n",
      "Entry 29: Lawrence M mgr L M Bartleit Co r Brown- dale Pk\n",
      "\n",
      "Entry 30: horsains D clk Minn Mil Dist (USA) 2229 N 6th\n",
      "\n",
      "Entry 31: Malcolm W (Irene) mgr Schaecher-Kux Lumber Cor StPaul\n",
      "\n",
      "Entry 32: Mary E ofc sec Springfield Fire & Marine Ins ri231 1st av S\n",
      "\n",
      "Entry 33: Mavis E Mrs tchr Blaine Sch r3507 Newton av os Fuller - Distributed by | Barthel Alois N hip: Wy MINNEAPOLIS ANS J Mblorence CITY a DIST. \" Bernice C tech Be . N 1507 So. 6th St. ™ Chas ctr Royal CORNELIUS New Brighton BEVERAGE CO. \" Cherry studt h244 6315 Cedar Ave. \"Clara M emp Fant So ' Dorothy emp Pal NO ORE RRNA eS Tar ee | meee AEM OO TAR AR Rie Meee SO Ae - Free: au (Nellie E) h27 irl 4rvillg ad¥ © Co r StPaul -\n",
      "\n",
      "Entry 34: Chas ctr Royal Stationery & Prig r RD 1}1 Geraldine M studt 13948 I7th ars) “ Maty Ei bie see Sprihgield Wire & Murine Ins aw. meoton. ; \" Harold (Eleanor) shipping clk h910 21st av S|\" Mavis E Mrs tchr Blaine Sch r3507 Newt i. cherry stunt ise Blaisdell ar Newt \" \" ec Kegs) dockmn Widholm Transfer h N Saree: ee\n",
      "\n",
      "Entry 35: Clara M emp Fanny Farmer r Newton av N 3 \" ill j i i i t! Bovey emp Pako Corp r919 University avi\" Ida L (wid Robt) h612 13th av S eer oeistae (aiiidred) chief Nopkalser BHA = tt Edwin N (Florence) unloader Gen] Mills r Al- \" sa ae Wy ORI M) mech Norris Creameries T |\" ee usher Campus Theatre 1710 SE Dela- bertville \" John (Esther) asmblr h1325 LaSalle av apt B \" Ollie € Margt 26! 7 Heanor © pet Miss Morris Candies 13511 New- |\" John x. folctte) sec-treas Frank Karker Co|\" Ora H nny ives bisa Ne Main av SE No Inc 15 Bloomington av \" Orval H (J iv i u is pie ae Mayme Hoye Cinrs hi\" ieuuen E (Evelyn A) reprmn Tel Co 4820 4324 ine oe Henry Mengelkoch Co b etl ryant av 8S \" ;\n",
      "\n",
      "Entry 36: Francis D clk Texas Co r1938 W Bway ' Leo J supt Pullman Co r StPaul Pearl rs27 38th E * ’ ~\n",
      "\n",
      "Entry 37: Fredk J (Grace A) purch agt hal49 Wash- |» Mardelle J Mrs cash HJ Minar Co bi27 WLake|| P@azl,V Mrs mangle girl Garber’s Inc r#815 ; . apt 21 We: ‘ ; '\n",
      "\n",
      "Entry 38: Gilbert mach Char-Lynn Co r Edina \" Patricia clk Buttrey Stores r4401 Washburn av Phyllis M Mrs clk Northrup King b1010 20th\n",
      "\n",
      "Entry 39: Harold plmbr Wm A Quinn 1910 Portland av apt Ss \" Reva J (Mildred E) n4047 T 4 6 . ; \" Paul W (Virginia C) asst sls mgr Minn & On-|\" Robt B (Lorraine K) ak k die a N Harriet E sorter Investors Diversified Serv tario Paper h5940 10th av S \" Robt H (Gertrude; Twent PFO th St Tire C\n",
      "\n",
      "Entry 40: pane? Dupont ay. Ss \" Raymond (Rose M) roofer hi227 S 6th r Spring Park ’ Ze ire Co)\n",
      "\n",
      "Entry 41: Horie (Genorive W) taster Mle Glass |” \"'Brvant a's apie’ OM BEETS 79945) nobt Vera AS e150 Content a 3606 Irving ay N r ryant av S apt 10 \" Roscoe W (Bernice S) hipr NPRy h3523 N 4th Roberta waitress Kresge’s r1303 6th \" Ruth M nursé h3337 Bloomingto t 1\n",
      "\n",
      "Entry 42: Herman T (Ella) paper ctr h3850 Portland av \" Rose (wid Jos) h2540 4th av S \" Rutherford J elev opr Lbr Exch bldg 1408 27th Ton Irma A mach opr r3511 Newton av N BARTHOLOMEW STANDARD SERVICE (Clar- av NE Jas M (Mary) clk Royal Stationery & Prntg ence F Bartholomew), Washing, Greasing, |'' Shirley clk h611 Ridgewood av apt 207 1 174606 ‘Camden av ; Atlas Tires, Also Accessories 4453 Nicollet av, |'' Theo elevator opr 12300 5th av S Johannes dairy wkr Franklin Co-op Crmy h Tel Regent 8643 \" Thos E (Dorothy B) eng Gen! Hosp h4609 Xerxes pated Waa eh)” wide 13005, § g | Feist aenmapin art TBD ® ae : 5 Emerson av r12 ennepin av \" Vivian M M h 282 a\n",
      "\n",
      "Entry 43: ‘eander 7 enor) ee Geo A Clark &|\" Vernal = (Bernadette L) city policemn h2905 |\" Walter (Mary E) seo OMlisen Willan Go bs031 ; , , remont av Colf\n",
      "\n",
      "Entry 44: Leo M (Margt) mach Mpls Moline h1938 W/|\" Wm N (Clara) pntr h211 W 31st \" We Ht ibell: E) carrier PO h710 Delaware a Bway Bartholow Harold E (Verna) parts mgr Lake St|\"\" Wm M (Shirley A) collr Mutual Serv Corp h\n",
      "\n",
      "Entry 45: LeRoy H emp Pako Corp r919 University ay NE Pontiac r RD 3 Anoka 4639 Pleasant av otet a oer Eliz Kenny Institute r3511 New- \" Robt Ge ear a emp Mols Gas ria6 E 18th apt 3|\" Willie M (Freda) h4407 Irving av N . Robt | ut! social wkr h2315 Girard av S i y Martha B mach 13511 Newton av N \" Ruth E Mzs sten Osborne McMillan 1736 E BAECS jane, Mme Gol Myndall Calm Beauty 1 a) av Le ap Wy ; $ 7 49\n",
      "\n",
      "Entry 46: Nellie M Mrs h1100 WB Carrie (wid John) 13937 20th av S\n",
      "\n",
      "Entry 47: Norbert L (Cecilia) sismn Massolt Bilg r St Bartviachy t Eau claire Wis Stockland Road yu ae W Sue! Sa Bartley: ales Boy) bles nv sphtichacl . Bartko Alberta R acct 72421 Butler pl \" Brencis -R {Lois A) mtcemn Clty Div Pub Re n ae mae (Coltetey Newiat ay a i nt Andrew (gait) mildr Cheney Fdry h701 Laurel lief h8417 22d av S = ° ) Masso Ig r av W ap Wy ield 60! wv yaatbertvitle - __|\" Arnold tech Boos Dental Laby 2421 Butler pl{n Hored a dyer 1) eh Pati osth av § ars = te M) sls asst Intl Milling h3355 |\" Paul (Agnes M) formn Cheney Fdry h261 20th av|\" John J (Olga) partsmn h1415 Grand i NE\n",
      "\n",
      "Entry 48: Walter J (Helen 8) loader h2314 N 4th \" John (Mary) h66 27th av SE iy QoUn F abade maa0s Jam ay 8 apt st\n",
      "\n",
      "Entry 49: Walter M (Agnes M) grinder h919 Univ av|\" John (Minite) mldr Acme Fdry h930 21st av S| Leys EB mes oF) alk Western Walon, HAe0s Bantneld Robt F lab Wabash Screen Door r RD 3/1\"! Jonn careken ¥2421 Butler pl \" hems Mae) Scy sistan Teh Consens Newton sseo it . A ; : ay | ; Barthell Kathleen tel opr r2432 Girard av § , Jobn jr (Mary) oiler h66 27th av SE | = =|\" Margie S Mrs (Bartley Sales Co) h120 Groveland Barthelme Laura M tchr r4024 Pleasiat ay Mea Mins fcty wer Keller Mig BGG 27th, ar ay Barthine Elaine clk Land O’Lakes 12644 Harriet |\" i ] \" Maynard M (Ellrith M) ofc wkr h2630 Grand av Bartel. Ueeia a (Rozalia I) buyer Aslesen Co Mathew (Anna) sectionmn TCRT h2421 Butler | , nerien K (Mary J) slsmn Kee-Lox Mfg h700 2628 Humboldt av S \" Minnie of i‘ Organ av\n",
      "\n",
      "Entry 50: hay E (Margt). dictating machs 616 Bldrs Exch |\" Ruth E a av 8 abt 2 \" Sadie J clk Smith Wldg Equip r300 Ridgewood y 8 Fremont av Bartkosk ' av Mm Rogelta I Mrs sten A-D-M h2628 Humboldt av |\" aTavuioad (Lois yt ior 2006. s 344 n do \" nae Co a and Mis Maret & Bartley) Bartle Ervin R (Frances P) supvr US Prod - & sups io Bartholdt Geo C (Sue L) acct Lynn Mfg h3605|\"\" keting Admin Datry Br isi? Washburn av |\" Thos 7 Cite) Durch. agt, DeSote Cemy & Exod Bartholt tate J (wid Warren) h3341 University |\" Rey E chemist A-D-M 14517 Washburn av § \" Vera hi nurse Eliz Kenny Institute h3713 29th . \" Wm lather Theo S Larson r3101 Girard a BY. : - Barinolnew Thos J Jubemn Slawik Mtrs r Como Sta Hurilenen Haier piler Sayer Gleator apr n934 i Warren a oa Danone 921 i al . 4th av 1 Bartholoma Irene J Mrs proof rdr Miller Publ h4314 Bartlett Amanda E (wid Henry) h3020 16th av|\" Vitesd F (Gertrude K) pntr 2549 Dupont av S enn av }\n",
      "\n",
      "Entry 51: qeaune rear aes penn ay q r \" Anna d, Mrs slswn Sears r1701 Portland av S Ben (Amene) YP Ubatnen ate . R rene electn | C enn av 2 apt 15 artness Roya sther pr Dayton Rogers Haxilolomael Albert H colin mgr Safety Loan h/\" Archie W (Helen A) mtcemn Pure Oi] h1104 § Mfg h315 Knox av N 4 nox av 8th Bartnof Morris Rev h1431 James av N Bartholome Earl F (Lauretta) slsmn Insulation|\" Betty J emp Forum Cafeteria 1438 Main NE Barto Edna smstrs h3046 Blaisdell av apt 16 n Sls r StLouis Pk ; \" Chas H (Mary) h3918 Vincent av N ' Fred W (Marion M) barber Paris Beauty Salon Judith E slswn Woolworth’s r StLouis Pk \" Claude tstr NSP 112400 Fairfield W h5720 Pillsbury av rc lee it cS A SS SR TE I TT f . k Stationery & Pr ) Blaisdell av y Farmer r3511 N o Corp r919 Ur 2) unloader Genl Harold (Eleanor) s Harris (Gussie) dc 1303 S 6th Ida L (wid Robt) t Jack O (Viola M) 1201 W 28th John (Esther) asmb | Newton avy N 13¢ University avi\"! Ida I\n",
      "\n",
      "Entry 52: Jack nl Mills r Al- 120\n",
      "\n",
      "Entry 53: John es 13511 New- |\" John Inc Hoye Clinrs hj\" Kenn DAVIDSON DIST. CO. \" 332 46th Ave. S. CHARLES \" GANZER DIST. \" co. 4239 Russell tt Ave. N. at s Theatre in h1i06 2 h438 NE MW r Henry ‘e 1710 SE Dela- 26th av SE Main Mengelkoch Co h r1303 6th v i$ D SERVICE Washing, G ries 4453 Nice Freda) h4407 Irvin: ne Mrs opr Mynd 032 2d av S | John) £3937 20th Margie S; Bartley 1 av (Lois A) mtcemn { tip r300 Ridgewood Margie S Bartley). 2Soto Crmy & Prod nstitute h3713 29th 321 25th av S av Sr do - 2549 Dupont av & Warren A (Lucille) slsmn r921 25th av §\n",
      "\n",
      "Entry 54: Willard E pntr 2549 Dupont av S r do\n",
      "\n",
      "Entry 55: Vitesd F (Gertrude K) pntr 2549 Dupont o\n",
      "\n",
      "Entry 56: Wm (Arlene) slsmn r6032 2d av S Bartness Royal V (Esther) hlpr Dayton |] Mfg h315 Knox av iN Bartnof Morris Rev h1431 James av N Barto Edna smstrs h3046 Blaisdell av apt\n",
      "\n",
      "Entry 57: Fred W (Marion M) barber Paris Beauty h5720 Pillsbury av s r1701 Portland av § ‘eemn Pure Oil h1104 S teria r438 Main NE incent av N Fairfield W\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "OCR via word-box clustering (DBSCAN) → large regions → block OCR → entry grouping.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import DBSCAN\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIG ———\n",
    "IMAGE_PATH    = Path(\"/Users/darshilshukla/Desktop/104.png\")  # updated path to your image\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "EPS_PIXELS    = 100      # clustering radius (px)\n",
    "MIN_SAMPLES   = 5        # min words to form a region\n",
    "PADDING       = 10       # px padding around each region\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "\n",
    "def get_word_boxes(img: np.ndarray) -> List[WordBox]:\n",
    "    \"\"\"Run Tesseract to get word-level boxes and confidences.\"\"\"\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT, config=TS_CONFIG)\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        if not txt.strip():\n",
    "            continue\n",
    "        conf = int(data['conf'][i])\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l = data['left'][i]\n",
    "        t = data['top'][i]\n",
    "        w = data['width'][i]\n",
    "        h = data['height'][i]\n",
    "        cx = l + w / 2\n",
    "        cy = t + h / 2\n",
    "        boxes.append(WordBox(txt.strip(), l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def cluster_regions(boxes: List[WordBox]) -> List[Tuple[int,int,int,int,List[WordBox]]]:\n",
    "    \"\"\"\n",
    "    DBSCAN cluster on the word-centroids (cx,cy), then compute\n",
    "    one bounding box per cluster plus the list of member WordBoxes.\n",
    "    \"\"\"\n",
    "    pts = np.array([[b.cx, b.cy] for b in boxes])\n",
    "    db = DBSCAN(eps=EPS_PIXELS, min_samples=MIN_SAMPLES).fit(pts)\n",
    "    labels = db.labels_\n",
    "    regions = {}\n",
    "    for lbl, wb in zip(labels, boxes):\n",
    "        if lbl == -1:\n",
    "            continue\n",
    "        regions.setdefault(lbl, []).append(wb)\n",
    "    out = []\n",
    "    for members in regions.values():\n",
    "        xs = [b.left for b in members] + [b.left + b.width for b in members]\n",
    "        ys = [b.top  for b in members] + [b.top  + b.height for b in members]\n",
    "        x1, x2 = min(xs), max(xs)\n",
    "        y1, y2 = min(ys), max(ys)\n",
    "        out.append((x1, y1, x2 - x1, y2 - y1, members))\n",
    "    out.sort(key=lambda r: (r[1], r[0]))\n",
    "    return out\n",
    "\n",
    "\n",
    "def ocr_block(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    \"\"\"Crop + OCR block → return non-empty lines.\"\"\"\n",
    "    x, y, w, h = region\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "\n",
    "def group_entries(lines: List[str]) -> List[str]:\n",
    "    \"\"\"Combine lines into entries: new entry starts with '\"'. Skip partition bars.\"\"\"\n",
    "    entries = []\n",
    "    current = \"\"\n",
    "    for ln in lines:\n",
    "        stripped = ln.strip()\n",
    "        # skip vertical partition lines\n",
    "        if stripped and set(stripped) == {'|'}:\n",
    "            continue\n",
    "        # new entry if line starts with double-quote\n",
    "        if stripped.startswith('\"'):\n",
    "            if current:\n",
    "                entries.append(current.strip())\n",
    "            current = stripped.lstrip('\" ').strip()\n",
    "        else:\n",
    "            # continuation of same entry\n",
    "            if current:\n",
    "                current += \" \" + stripped\n",
    "    if current:\n",
    "        entries.append(current.strip())\n",
    "    return entries\n",
    "\n",
    "\n",
    "def main():\n",
    "    img = cv2.imread(str(IMAGE_PATH))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot load image: {IMAGE_PATH}\")\n",
    "\n",
    "    # get word boxes\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    word_boxes = get_word_boxes(gray)\n",
    "    print(f\"Detected {len(word_boxes)} words → clustering into regions…\")\n",
    "\n",
    "    # cluster into regions\n",
    "    regions = cluster_regions(word_boxes)\n",
    "    print(f\"Formed {len(regions)} text-dense regions\")\n",
    "\n",
    "    # OCR all regions, collect lines\n",
    "    all_lines = []\n",
    "    for (x, y, w, h, members) in regions:\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(img.shape[1], x + w + PADDING)\n",
    "        yb = min(img.shape[0], y + h + PADDING)\n",
    "        lines = ocr_block(img, (xa, ya, xb-xa, yb-ya))\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "    # group into entries\n",
    "    entries = group_entries(all_lines)\n",
    "    print(f\"\\nExtracted {len(entries)} entries:\\n\")\n",
    "    for i, e in enumerate(entries, 1):\n",
    "        print(f\"Entry {i}: {e}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d019caa-5c13-4dc8-adae-3816f80da197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1777 words, extracting 7 regions...\n",
      "Found 7 regions\n",
      "\n",
      "----- Region 1 -----\n",
      "NOW TRY\n",
      "MELLOW -\n",
      "DRY\n",
      "(3) (Gry\n",
      "As) CUB)\n",
      "Distributed by\n",
      "MINNEAPOLIS\n",
      "CITY a DIST.\n",
      "1507 So. 6th St.\n",
      "CORNELIUS\n",
      "BEVERAGE CO.\n",
      "6315 Cedar Ave.\n",
      "DAVIDSON\n",
      "DIST. CO.\n",
      "3332 46th Ave. S.\n",
      "CHARLES\n",
      "GANZER DIST.\n",
      "co.\n",
      "\n",
      "4239 Russell\n",
      "Ave. N.\n",
      "Jacob Schmidt\n",
      "Brewing Co.\n",
      "ST. PAUL, MINN.\n",
      "F. H.\n",
      "WwW\n",
      "A\n",
      "G\n",
      "N\n",
      "E\n",
      "R\n",
      "Agency\n",
      "| THEO, H.\n",
      "\n",
      "and\n",
      "BLANCHE E.\n",
      "RITTENHOUSE\n",
      "Co-Owners\n",
      "e\n",
      "- @\n",
      "536\n",
      "PLYMOUTH\n",
      "BUILDING\n",
      "Phone\n",
      "GENEVA\n",
      "| 6082 \n",
      "\n",
      "----- Region 2 -----\n",
      "HE \"FEDERAL See u\n",
      "\n",
      "SAVINGS & LOAN ASSOCIATION your |\n",
      "\n",
      "PARTH\n",
      "\n",
      "Co Inc J Guy Enos pres-treas Mrs Dorothy D\n",
      "Enos v-pres Bertil H Larson sec jwlr mfrs 29\n",
      "Glenwood ay\n",
      "\n",
      "Edna counterwn Grain Exchange Lunch 12708\n",
      "Grand av.\n",
      "\n",
      "Esther E (wid Champ) mach opr hd426 Hamp-\n",
      "shire dr\n",
      "\n",
      "Geo A (Eleanor A) h3549 10th av S apt 3\n",
      "\n",
      "Geo F (Martha A) slsmn McCaskey Register Co \n",
      "\n",
      "----- Region 3 -----\n",
      "HEN YOU BUY, BUILD OR Ff\n",
      "See us for an easy-payment home loan m\n",
      "your income. Low interest rates—no co\n",
      "A MARQUETTE AVE.\n",
      "othy D r2540 4th av §\n",
      "nfrs 299 Allen (Agnes) driver Widholm Transfer\n",
      "13th av 8\n",
      "7270S\" Ann M (wid Claude A) clk US Treas Dept |\n",
      "Bryant av S apt 10\n",
      "Hamp-j' Ardys M clk Tel Co r211 W 31st\n",
      "' Aug J (Florence M) driver 61407 S 8th\n",
      "' Barbara slswn r1821 Emerson av S\n",
      "ster Col’ Bert (Betty) driver h2959 Aldrich av N- \n",
      "\n",
      "----- Region 4 -----\n",
      "commission SAVINGS & LOAN ASSOCIATION\n",
      ";\n",
      "AT. 5328 ‘3 uy\n",
      "PrOouuCcta BARTLETT\n",
      "\" 2D E r22 Washn av S\n",
      "er r619§\"' Donald S (Katharine) treas W A White Brokerage\n",
      "Co h810 Pence bidg\n",
      "pt h39498\"' Douglas W (Phyllis M) driver Harry W Smith Co\n",
      "h1010 20th av NE\n",
      "\" Karle W (Effie) pharmacist Zwisler Pharmacy\n",
      ". n4448 Ist av S\n",
      "\" Edw G (Edith) pntr h2420 Oakland ay\n",
      "N (\"Eliz 15409 Dupont av S \n",
      "\n",
      "----- Region 5 -----\n",
      "h1611 Bryant av N sO ' Bohn g (Effie L) electn CB&Q |\n",
      "Gertrude A (wid Leo T) bkpr h2206 Queen av NM, , 2\" >. |\n",
      "Helen mach opr r3711 Emerson av N Cc penis de (Cath Uy pres Bart |\n",
      "Jennie waitress Strom’s Coffee Shop 12635 Har-9, Carl W (Alice) 1211 W 3ist\n",
      "\n",
      "riet av 1 F\n",
      "Lawrence J clk T1611 Bryant av N 5 Clara Mrs asst cook Commun\n",
      "Lester 6 (Edna) driver Gen] Paper 12708 Grandyy, Clarence F (Mary; Bartholomew\n",
      "Mary Ww elk Travelers zi611 Bryant ay N ; i oe aie wuts av §\n",
      "Paul (Sylvia D) sis mgr Baston Barington#, 7; :\n",
      "\n",
      "Chey, Co 9021 Garfield av out Dixon J (Mardelle J) sign pntr hl\n",
      "Ralph sten Soo Line 120: ifton av Ko ies We (eat ; :\n",
      "Tena J caterer 4436 Aldrich av S r do ; fan Uo Cesena wil\n",
      "arthany Edwin J (Emily C) 3027 22dav S_ ' Ethel M sten Langdon-Warren\n",
      "arthe Lynn E Mrs sten Dunham-Scott r Hoiel Bryant av S apt 35\n",
      "\n",
      "Fuller 7 Florence B (wid Chas L) ofe wkr\n",
      "arthel Alois N hipr h3511 Newton av N . h2632 Oakland av §\n",
      "mie te (Florence A) lab Northrup King h754 Floyd A (Marie) crater Bemis B\n",
      "\n",
      "ackson av N\n",
      "‘Bernice C tech Benson Optical r3511 Newton av Fred R (Stella L) prntr h2501 Ir\n",
      "\n",
      "N Freeman (Nellie E) h2707 ist av\n",
      "Chas ctr Royal Stationery & Prtg r RD 19\" Geraldine M studt 13548 17th av\n",
      "\n",
      "New Brighton Harold (Eleanor) shipping clk h\n",
      "Cherry studt h2440 Blaisdell av ' Harris (Gussie) dockmn Widhol\n",
      "‘Clara M emp Fanny Farmer r3511 Newton av N 1303 S 6th\n",
      "Dorothy emp Pako Corp r919 University av Ida L (wid Robt) h612 13th av §&\n",
      "\n",
      "NE Jack O (Viola M) mech Norris\n",
      "Edwin N (Florence) unloader Genl Mills r Al- 1201 W 28th\n",
      "\n",
      "bertville John (Esther) asmblr h1325 LaSal\n",
      "Eleanor C pkr Miss Morris Candies 13511 New- John E (Collette) sec-treas Fra\n",
      "\n",
      "ton avy N Inc h5615 Bloomington av\n",
      "Elroy J (Felicia) driver Mayme Hoye Clinrs h Kenneth E (Evelyn A) reprmn\n",
      "\n",
      "2712 Pillsbury av Bryant av S\n",
      "Francis D clk Texas Co r1938 W Bway Leo J supt Pullman Co r StPau\n",
      "Fredk J (Grace A) purch agt hi5049 Wash- Mardelle J Mrs cash H J Minar Cx\n",
      "\n",
      "burn av S apt 216\n",
      "Gilbert mach Char-Lynn Co r Edina Patricia clk Buttrey Stores r4401\n",
      "Harold plmbr Wm A Quinn 1910 Portland av apt 8\n",
      "\n",
      "6 Paul W (Virginia C) asst sls mg\n",
      "Harriet E sorter Investors Diversified Serv tario Paper h5940 10th av S\n",
      "\n",
      "73252 Dupont av. S Raymond (Rose M) roofer hi227\n",
      "Harry ctr Jensen Prtg r2504 Humboldt av S Robt C slsmn Droney O M B\n",
      "Herbert N (Genevieve W) glazier Mpls Glass h Bryant av S apt 10\n",
      "\n",
      "2606 Irving ay N Roberta waitress Kresge’s 61303\n",
      "Herman T (Ella) paper ctr h3850 Portland av Rose (wid Jos) h2540 4th av S\n",
      "Irma A mach opr r3511 Newton av N ARTHOLOMEW STANDARD SE\n",
      "Jas M (Mary) clk Royal Stationery & Prntg ence F Bartholomew), Washi\n",
      "\n",
      "hi606 Camden av Atlas Tires, Also Accessories 44\n",
      "Johannes dairy wkr Franklin Co-op Crmy h Tel Regent 8643\n",
      "\n",
      "508 E 15th apt 5 Thos mech Slawik Serv r RD 5\n",
      "Laurice W (Helen) widr h3005 Emerson av S V ri24 Hennepin av\n",
      "Leander L (Lenora) whsemn Geo A Clark & Vernal E (Bernadette L) city p\n",
      "\n",
      "Son r RD 6 Camden Sta Fremont av S\n",
      "Leo M (Margt) mach Mpls Moline h1938 W Wm N (Clara) pntr h211 W 31st\n",
      "\n",
      "Bway artholow Harold E (Verna) parts\n",
      "LeRoy H emp Pako Corp r919 University av NE Pontiac r RD 3 Anoka\n",
      "Margt M pkr Eliz Kenny Institute 13511 New-[ Robt G (Ruth E) emp Mpls Gas r7:\n",
      "\n",
      "ton av N Robt G (Ruth E) social wkr h2315\n",
      "Martha B mach r3511 Newton av N Ruth E Mrs sten Osborne Mch\n",
      "Nellie (wid Peter) h1015 23d av N 18th apt 3\n",
      "‘Nellie M Mrs h1100 W Bway artick Fredk G (Mary) emp St\n",
      "Norbert L (Cecilia) slsmn Massolt Btlg r St Machy r Eau Claire Wis\n",
      "\n",
      "Michael artko Alberta R acct r2421 Butler\n",
      "Rita F mach opr r3511 Newton av N Andrew (Edith) mldr Cheney Fdr\n",
      "Roman W_ (Collette) rtemn Massolt Bilg r av W apt 1\n",
      "\n",
      "Albertville Arnold tech Boos Dental Laby r:'\n",
      "‘Vernard A (Eliz M) sls asst Intl Milling h3355 Dan} (Agnes M) formn Cheney Fd\n",
      "\n",
      "Oliver av N Ss\n",
      "Walter J (Helen S) loader h2314 N 4th John (Mary) h66 27th av SE\n",
      "Waller M (Agnes M) grinder h919 Univ av John (Minnie) midr Acme Fdry I\n",
      "\n",
      "i apt 2\n",
      "artheld Robt F lab Wabash Screen Door r RD 3 John trucker r2421 Butler pl\n",
      "\n",
      "Osseo John jr (Mary) oiler h66 27th av\n",
      "arthell Kathleen tel opr r2432 Girard ay S Mary Mrs fcty wkr Keller Mfg\n",
      "arthelme Laura M tchr r4024 Pleasant ay SE\n",
      "arthine Elaine clk Land O’Lakes r2644 Harriet Mathew (Anna) sectionmn TCRT\n",
      "artholdi Marvin A (Rozalia I) buyer Aslesen Co pl ‘\n",
      "\n",
      "h2628 Humboldt av S Minnie ofc wkr r930 21st av S al\n",
      "Ray E (Margt) dictating machs 616 Bldrs Exch Ruth E r727 Superior\n",
      "\n",
      "bldg h2418 Fremont av § artkoske Aug (Clara) gro 1500 NE\n",
      "Rozalia I Mrs sten A-D-M h2628 Humboldt av Raymond (Lois A) driver h2006 §\n",
      "\n",
      "s artle Ervin R (Frances P) supvr U\n",
      "aethoidt Gee C (Sue L) acct Lynn Mfg h3605 keting Admin Dairy Br h4#517\n",
      "\n",
      "41st av . Ss\n",
      "artholf Kate J (wid Warren) h3341 University Roy E chemist A-D-M 14517 Was!\n",
      "\n",
      "av SE Wm lather Theo S Larson r3101\n",
      "artholmew Thos J lubemn Slawik Mtrs r Como Sta MRartleman Elmer piler Sawyer Cle \n",
      "\n",
      "----- Region 6 -----\n",
      "lectn CB&Q h2709 Emersom\" Emelie T Mrs 1510 Groveland av ;\n",
      "\" Emory W (Leah N) driver Norris Creamerie\n",
      "4) pres Bart Supplies Inc n3425 Sheridan av N\n",
      "Ss \" Gertrude E slswn Amluxen Co r922 E 24th\n",
      "1 W 3i1st \" Horace L (Mary A) pntr 601 E 22d h do\n",
      "200k Community Chest r219§\"' Irving J (Lillian F) pres Calhoun Sales Inc h\n",
      ". 105 W Minnehaha pkwy\n",
      "Bartholomew Standard Ser¥\"' inying 4, ua ana Calhoun Sales Inc 1105 W\n",
      "tland avy S Minnehaha pkwy\n",
      "av S \" Jas W mach opr r5031 Colfax av S\n",
      ") sign pntr h127 W Lake api\" John clk Acme Hotel 122314 Marquette av\n",
      ". \" John W fire motor opr h4231 Ist av S\n",
      ") h1401 Willow apt 6 \" June Mrs nurse Asbury Hosp h4324 Irving av N\n",
      "toe atten Mines nigog” LM Co Lawrence M Bartlett mgr power plant\n",
      "n= 4 equip »\n",
      "35 . \" Lawrence M mgr L M Bartlett Co r Brown-\n",
      "+ L) ofc wkr Bart Supplie dale Pk\n",
      "\"Wy ; ; i i ‘ n2229 >\n",
      "ater Bemis Bro h615 Jame Thornaine D clk Minn Mil Dist (USA) 82229 N\n",
      ". . \" Malcolm W (Irene) mgr Schaecher-Kux Lumber\n",
      "rntr h2501 Irving av S Cor StPaul\n",
      "h2707 Ist av S apt 1 \" Mary E ofc sec Springfield Fire & Marine Ins\n",
      "3548 17th av S T4231 1st av S\n",
      "hipping clk h910 21st av Si\" wavis E Mrs tchr Blaine Sch r3507 Newton av\n",
      "ckmn Widholm Transfer N\n",
      "\" Merrill jr (Mildred) chief appraiser FHA r\n",
      "612 13th av S Excelsior\n",
      "mech Norris Creameries \" Merritt usher Campus Theatre r710 SE Dela-\n",
      "ware\n",
      "ir h1325 LaSalle av apt B \" Ollie C (Margt) custdn h1106 26th av SE\n",
      "sec-treas Frank Karker Cq@j\"' Ora H (Freda) driver h438 NE Main\n",
      "ngton av \" Orval H (June) driver Henry Mengelkoch Co hi\n",
      ". A) reprmn Tel Co h482 4324 Irving av N\n",
      "\" Pearl r4821 38th E\n",
      "1 Co r StPaul \", ‘ ir]: ’ FA\n",
      "HJ Minar Co h127 W Lak Pea Yes mangle girl Garber’s Inc r4815\n",
      "t § bh lli d 5 th.\n",
      "- Stores r4401 Washburn a Phyl iS a Mrs clk Northrup King h1010 20th\n",
      "| . \" Raymond J (Mildred E) h1047 Thomas av N\n",
      ") asst sls mer Minn & Ong\" Robt B (Lorraine K) sta kpr h3025 N 2d\n",
      ") 10th av S \" Robt_H (Gertrude; Twenty-Fourth St Tire Co)\n",
      "roofer hi227 S 6th r Spring Park\n",
      "ney O M Beverage 13943\" Robt V formn NSP ri450 Central av\n",
      "10 ; \" Roscoe W (Bernice S) hilpr NPRy h3523 N 4th\n",
      "resge’s ©1303 6th \" Ruth M nursé h3537 Bloomington av apt 1\n",
      "10 4th an s RV cl \" Buttered J elev opr Lbr Exch bldg h1408 27th\n",
      "ANDARD SERVICE ar av }\n",
      "mew), Washing, Greasing§j\" Shirley clk h611 Ridgewood av apt 207\n",
      "Accessories 4453 Nicollet avgy'' Theo elevator opr 12300 5th av S\n",
      "\" Thos £ (Dorothy B) eng Genl Hosp h4609 Xerxes\n",
      "erv r RD 5 av\n",
      "V . \" Vivian M Mrs mach opr h2822 Colfax av N\n",
      "tte L) city policemn h2903%\" Walter (Mary ) sec Allison-Williams Co h5031\n",
      "Colfax av\n",
      "h211 W 31st \" Wm H (Bessie E) carrier PO h710 Delaware\n",
      "(Verna) parts mgr Lake S@\" wm att euiley A) collr Mutual Serv Corp h\n",
      "noka 463' easant av\n",
      "p Mpls Gas r736 E 18th apt 3\" Willie M (Freda) hi407 Irving av N\n",
      "ree Pr ener Bartley Arlene AIT opr Myndall Cain Beauty\n",
      "‘ Salon r 2d av.\n",
      "\" Carrie (wid John) 13937 20th av S\n",
      "ary) emp Stockland Roaggu Edw We (Margie S; Bartley Sales Co) h120\n",
      "Groveland av\n",
      "T2421 Butler pl \" Francis R (Lois A) mtcemn City Div Pub Re-\n",
      "ir Cheney Fdry h701 Laure lief h3417 22d av §\n",
      "o \" Gerald P field eng r4609 33d av S\n",
      "ental Laby 12421 Butler Dj Howard A (Vera D) mech h3713 29th av S\n",
      "nn Cheney Fdry h261 20th avin John J (Olga) partsmn hl1415 Grand av NE\n",
      "\" John P studt r3308 19th av S apt 4\n",
      "Fe Fary 4630 dist. av Lewis E (Agnes P) clk Western Union h4609\n",
      "33d av\n",
      "\" Lewis R (Mae) adv slsmn Tel Co h5805 Newton\n",
      "Pee art SE aS\n",
      "r 6 27th av \" i ,\n",
      ": Keller Mfg héé 27th a Margie S Mrs (Bartley Sales Co) h120 Groveland\n",
      "+4 h : \" Maynard M (Ellrith M) ofc wkr h2630 Grand av\n",
      "tionmn TORT h2421 Butlem,, Merton K (Mary J) slsmn Kee-Lox Mfg h700\n",
      "‘ Morgan av\n",
      "yaa av S apt 2 \" Sadie J clk Smith Wldg Equip r300 Ridgewood\n",
      "av\n",
      ") gro 1500 NE 6th h do \" Sales Co (Edw W and Mrs Margie S Bartley)\n",
      "es P) supvr US Prod & Marg, Tho 5 (Millie) urch agt DeSoto Crmy & Prod\n",
      "iry Br h#517 Washburn a 19123 44th eM\n",
      "M 74517 Washburn av Ss - Vem hi nurse Eliz Kenny Institute h3713 29th\n",
      "Larson 1310 irard av \" Warr ‘ =\n",
      "> en A (Lucille) slsmn r921 25th av 8S\n",
      "r Sawyer Cleator Lbr 193 \" Willard E pntr 2349 Dupont av Srdo 7 \n",
      "\n",
      "----- Region 7 -----\n",
      "PrED 3 StPaul ¢ fubemn Siawik Mtrs r Como Sta Martleman Elmer piler Sawyer Cleator Lbr 1934, Willard E pntr 2549 Dupowt po Srd e, ©\n",
      "2 au 14th av S }\n",
      "rel olen Irene J Mrs proof rdr Miller Publ h4314 pantie Amanda E (wid Henry) h3020 16th ave’ Vitesd F (Gertrude K) pntr 2549 Dupont av S$\n",
      "enn av } 94 :\n",
      "Jeanne A studt r4314 Penn av N Anna J Mrs slswn Sears 11701 Portland ay gg Wm (Arlene) slsmn r6032 2d av S\n",
      "Paul F (Irene J) electn h4314 Penn av N apt 15 Bartness Royal V (Esther) hlipr Dayton Rogers\n",
      "arehoomael aNbanh colin mgr Safety Loan h Archie W (Helen A) mtcemn Pure Oil h1104 § ' (Mig hss snox ae P *\n",
      "‘ nox av 8th artno orris Rev ! ames av %\n",
      "artholome Earl F (Lauretta) slsmn Insulation J Betty J emp Forum Cafeteria 1438 Main NE Barto Edna smstrs h3046 Blaisdell av apt 16\n",
      "SIs r StLouis Pk Chas H (Mary) h3918 Vincent av N \" Fred W (Marion M) barber Paris Beauty Salon\n",
      "Judith E slswn Woolworth’s r_StLouis Pk laude tstr NSP 1712400 Fairfield W h5720 Pillsbury av\n",
      "i\n",
      "PIPER, JAFFRAY & HOPWOOD\n",
      ": sae ~ i\n",
      "Investment Securities |\n",
      "t :\n",
      "115 SOUTH 7th ST. : TEL. BRIDGEPORT 4141 _- MINNEAPOLIS | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Segment into 7 large regions (margin, 3 headers, 2 body columns, footer) via word clustering and spatial thresholds,\n",
    "then OCR each region separately using pytesseract.\n",
    "\"\"\"\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "IMAGE_PATH      = Path(\"/Users/darshilshukla/Desktop/104 copy.jpeg\")\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "EPS_PIXELS      = 100      # clustering radius for DBSCAN fallback (px)\n",
    "MIN_SAMPLES     = 5        # min words per cluster\n",
    "PADDING         = 10       # px padding around each region\n",
    "MARGIN_RATIO    = 0.15     # fraction of page width considered left margin\n",
    "HEADER_RATIO    = 0.18     # fraction of page height for header stripe\n",
    "FOOTER_RATIO    = 0.82     # fraction of page height for footer stripe\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG)\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        conf = int(data['conf'][i])\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l = data['left'][i]; t = data['top'][i]\n",
    "        w = data['width'][i]; h = data['height'][i]\n",
    "        cx = l + w/2; cy = t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left+b.width for b in boxes]\n",
    "    ys = [b.top for b in boxes] + [b.top+b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2-x1, y2-y1\n",
    "\n",
    "\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    # cluster by x-centroid\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for i in range(n_clusters):\n",
    "        members = [b for b, lbl in zip(boxes, km.labels_) if lbl == i]\n",
    "        regions.append(compute_bbox(members))\n",
    "    # sort left->right\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    # left margin region\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem = [b for b in boxes if b.cx >= margin_thresh]\n",
    "\n",
    "    # stripe thresholds\n",
    "    header_h = h * HEADER_RATIO\n",
    "    footer_h = h * FOOTER_RATIO\n",
    "    header_boxes = [b for b in rem if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    # margin\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    # header -> 3 regions\n",
    "    regions += cluster_stripe(header_boxes, n_clusters=3)\n",
    "    # body -> 2 columns\n",
    "    regions += cluster_stripe(body_boxes, n_clusters=2)\n",
    "    # footer single\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    # add padding\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x-PADDING)); ya = max(0, int(y-PADDING))\n",
    "        xb = min(w, int(x+rw+PADDING)); yb = min(h, int(y+rh+PADDING))\n",
    "        padded.append((xa, ya, xb-xa, yb-ya))\n",
    "    return padded\n",
    "\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> str:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    return pytesseract.image_to_string(crop, config=TS_CONFIG).strip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    img = cv2.imread(str(IMAGE_PATH))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot load image: {IMAGE_PATH}\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # get word boxes\n",
    "    word_boxes = get_word_boxes(gray)\n",
    "    print(f\"Detected {len(word_boxes)} words, extracting 7 regions...\")\n",
    "\n",
    "    # compute 7 regions (margin + 3 headers + 2 body + footer)\n",
    "    regions = extract_regions(word_boxes, img.shape[:2])\n",
    "    print(f\"Found {len(regions)} regions\\n\")\n",
    "\n",
    "    # OCR each region\n",
    "    for i, reg in enumerate(regions, 1):\n",
    "        print(f\"----- Region {i} -----\")\n",
    "        text = ocr_region(img, reg)\n",
    "        print(text, \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb99f382-0207-40ba-b447-3404d2c83421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR text saved to: /Users/darshilshukla/Desktop/text.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2-x1, y2-y1\n",
    "\n",
    "\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for label in range(n_clusters):\n",
    "        members = [b for b, lbl in zip(boxes, km.labels_) if lbl == label]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem          = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, n_clusters=3)\n",
    "    regions += cluster_stripe(body_boxes,   n_clusters=2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb-xa, yb-ya))\n",
    "    return padded\n",
    "\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> str:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    return pytesseract.image_to_string(crop, config=TS_CONFIG).strip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for img_path in IMAGE_PATHS:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            word_boxes = get_word_boxes(gray)\n",
    "            regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "            for reg in regions:\n",
    "                block = ocr_region(img, reg)\n",
    "                if block:\n",
    "                    out_f.write(block + \"\\n\")\n",
    "    print(f\"All OCR text saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d6839d-65e2-4439-84a3-3370bcfaf848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR text saved to: /Users/darshilshukla/Desktop/textnew.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "All extracted text from each region of each image is concatenated into one output file named text.txt on the desktop.\n",
    "Lines consisting solely of '|' are skipped.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"textnew.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level bounding boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box around a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2-x1, y2-y1\n",
    "\n",
    "# Cluster stripes (headers/body) into columns via x-centroids\n",
    "\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for label in range(n_clusters):\n",
    "        members = [b for b, lbl in zip(boxes, km.labels_) if lbl == label]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Extract 7 standard regions per page\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, n_clusters=3)\n",
    "    regions += cluster_stripe(body_boxes,   n_clusters=2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    # Add padding and constrain to image bounds\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb-xa, yb-ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a single region and return text\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> str:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    return pytesseract.image_to_string(crop, config=TS_CONFIG).strip()\n",
    "\n",
    "# Main execution: batch process images, write single output file\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for img_path in IMAGE_PATHS:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                continue\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            word_boxes = get_word_boxes(gray)\n",
    "            regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "            for region in regions:\n",
    "                text = ocr_region(img, region)\n",
    "                if not text:\n",
    "                    continue\n",
    "                for line in text.splitlines():\n",
    "                    stripped = line.strip()\n",
    "                    # skip partition-only lines\n",
    "                    if not stripped or set(stripped) == {'|'}:\n",
    "                        continue\n",
    "                    out_f.write(stripped + \"\\n\")\n",
    "    print(f\"All OCR text saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79146845-80e1-4e31-bee4-37960a15747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR entries saved to: /Users/darshilshukla/Desktop/textlast.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "All extracted entries (starting with '\"') from each region of each image are concatenated into one output file named text.txt on the desktop.\n",
    "Partition lines consisting solely of '|' mark the end of an entry.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"textlast.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level bounding boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box around a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top for b in boxes]  + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2-x1, y2-y1\n",
    "\n",
    "# Cluster stripes into columns\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, km.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Extract seven regions per page: margin, 3 headers, 2 body, footer\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, 3)\n",
    "    regions += cluster_stripe(body_boxes,   2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    # Pad and clamp to bounds\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb-xa, yb-ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a region and return text block\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> str:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    return pytesseract.image_to_string(crop, config=TS_CONFIG).strip()\n",
    "\n",
    "# Main: process images, extract entries, write single output file\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        word_boxes = get_word_boxes(gray)\n",
    "        regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "        for region in regions:\n",
    "            block = ocr_region(img, region)\n",
    "            # parse block into entries\n",
    "            current = None\n",
    "            for line in block.splitlines():\n",
    "                stripped = line.strip()\n",
    "                if not stripped:\n",
    "                    continue\n",
    "                # skip partition lines\n",
    "                if set(stripped) == {'|'}:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                # new entry starts with '\"'\n",
    "                if stripped.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = stripped\n",
    "                else:\n",
    "                    if current:\n",
    "                        current += ' ' + stripped\n",
    "            if current:\n",
    "                entries.append(current)\n",
    "    # write all entries to single text file\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in entries:\n",
    "            out_f.write(ent + \"\\n\")\n",
    "    print(f\"All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413715f0-6f53-4b28-b477-9258b3cc13b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR entries saved to: /Users/darshilshukla/Desktop/text_new.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "Extracts entries that start with '\"', continues until a line of '|', then writes each entry on a new line in text.txt.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_new.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box for a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "# Cluster WordBoxes into columns (headers/body)\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, km.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Divide into 7 regions: margin, 3 header cols, 2 body cols, footer\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, 3)\n",
    "    regions += cluster_stripe(body_boxes,   2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a region and return its text block\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG).strip()\n",
    "    return text.splitlines()\n",
    "\n",
    "# Main: process each image, extract entries, write to single file\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        word_boxes = get_word_boxes(gray)\n",
    "        regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "\n",
    "        current: str = None\n",
    "        for region in regions:\n",
    "            lines = ocr_region(img, region)\n",
    "            for line in lines:\n",
    "                stripped = line.strip()\n",
    "                if not stripped:\n",
    "                    continue\n",
    "                # partition line => end of entry\n",
    "                if stripped and set(stripped) == {'|'}:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                # new entry starts with '\"'\n",
    "                if stripped.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = stripped\n",
    "                else:\n",
    "                    # continuation of same entry\n",
    "                    if current:\n",
    "                        current += ' ' + stripped\n",
    "        # flush last entry for this page\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "    # write all entries to text.txt\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in entries:\n",
    "            out_f.write(ent + \"\\n\")\n",
    "\n",
    "    print(f\"All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a062bd-3733-4885-857d-211620182e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR entries saved to: /Users/darshilshukla/Desktop/text_another.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "Extracts entries that start with '\"', continues until a '|' partition, removes all '|' characters,\n",
    "and writes each entry on a new line in text.txt.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_another.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box for a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "# Cluster WordBoxes into columns (headers/body)\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, km.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Extract seven regions per page: margin, 3 header cols, 2 body cols, footer\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, 3)\n",
    "    regions += cluster_stripe(body_boxes,   2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a region and return its text lines\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "# Main: process images, parse entries starting with '\"', end on '|', remove all '|'\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        word_boxes = get_word_boxes(gray)\n",
    "        regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "\n",
    "        current: str = None\n",
    "        for region in regions:\n",
    "            lines = ocr_region(img, region)\n",
    "            for line in lines:\n",
    "                raw = line.strip().replace('|', '')\n",
    "                if not raw:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if raw.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = raw\n",
    "                else:\n",
    "                    if current:\n",
    "                        current += ' ' + raw\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in entries:\n",
    "            out_f.write(ent + \"\\n\")\n",
    "\n",
    "    print(f\"All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b63e7b2-0733-4d45-b4b0-1f5bd65af0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined JSON saved to: /Users/darshilshukla/Desktop/combined.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR = Path(\"/Users/darshilshukla/Desktop\")\n",
    "INPUT_FILE = BASE_DIR / \"text_another.txt\"\n",
    "OUTPUT_FILE = BASE_DIR / \"combined.json\"\n",
    "DIRECTORY_NAME = \"Minneapolis 1900\"\n",
    "\n",
    "# Known occupation keywords for optional checking\n",
    "OCCUPATIONS = {\n",
    "    'Salesman', 'Merchant', 'Clerk', 'Engineer', 'Teacher', 'Laborer', 'Driver',\n",
    "    'Teacher', 'Professor', 'Carpenter', 'Baker', 'Barber', 'Doctor', 'Physician'\n",
    "}\n",
    "\n",
    "def parse_entry(line: str):\n",
    "    \"\"\"\n",
    "    Parse a single entry line into the JSON schema.\n",
    "    \"\"\"\n",
    "    # Remove leading quote if present\n",
    "    line = line.lstrip('\"').strip()\n",
    "    tokens = line.split()\n",
    "    \n",
    "    # First name and last name\n",
    "    first_name = tokens[0]\n",
    "    last_name = tokens[1] if len(tokens) > 1 else None\n",
    "    \n",
    "    # Find address start (first numeric token)\n",
    "    addr_idx = next((i for i, tok in enumerate(tokens) if tok.isdigit()), len(tokens))\n",
    "    address_tokens = tokens[addr_idx:]\n",
    "    \n",
    "    # Determine occupation and company name\n",
    "    middle_tokens = tokens[2:addr_idx]\n",
    "    occupation = None\n",
    "    company = None\n",
    "    if middle_tokens:\n",
    "        # If first middle token matches known occupations, assign\n",
    "        if middle_tokens[0].rstrip(',') in OCCUPATIONS:\n",
    "            occupation = middle_tokens[0].rstrip(',')\n",
    "            company = \" \".join(middle_tokens[1:]) or None\n",
    "        else:\n",
    "            company = \" \".join(middle_tokens)\n",
    "    \n",
    "    # Parse address\n",
    "    street_number = address_tokens[0] if address_tokens else None\n",
    "    street_name = \" \".join(address_tokens[1:]) if len(address_tokens) > 1 else None\n",
    "    \n",
    "    return {\n",
    "        \"FirstName\": first_name,\n",
    "        \"LastName\": last_name,\n",
    "        \"Spouse\": None,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": street_number,\n",
    "            \"StreetName\": street_name,\n",
    "            \"ApartmentOrUnit\": None,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": None  # page number info unavailable in this file\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    entries = []\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or not line.startswith('\"'):\n",
    "                continue\n",
    "            entry = parse_entry(line)\n",
    "            entries.append(entry)\n",
    "    \n",
    "    # Write combined JSON\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(entries, f, indent=2)\n",
    "    \n",
    "    print(f\"Combined JSON saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf02e31c-82b6-47a6-9a11-4f70ff60a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All OCR entries saved to: /Users/darshilshukla/Desktop/text_Kmeans.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved OCR segmentation via morphological text‐block detection\n",
    "→ single text file on Desktop, parsing entries starting with '\"' \n",
    "until a '|' line, then writing each entry on its own line.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# ——— CONFIG ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_Kmeans.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 5    # small padding around each detected block\n",
    "\n",
    "def detect_blocks(img: np.ndarray) -> List[tuple]:\n",
    "    \"\"\"Detect large text blocks by dilating horizontal strokes then vertical strokes.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Binary inverted threshold: text=white, bg=black\n",
    "    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 1) Connect horizontally (merge words into lines)\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    hor = cv2.dilate(bw, h_kernel, iterations=2)\n",
    "\n",
    "    # 2) Connect vertically (merge lines into paragraphs)\n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 20))\n",
    "    ver = cv2.dilate(hor, v_kernel, iterations=2)\n",
    "\n",
    "    # 3) Find external contours of those paragraph‐shaped blobs\n",
    "    contours, _ = cv2.findContours(ver, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    blocks = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # ignore very small artifacts\n",
    "        if w * h < 1000:\n",
    "            continue\n",
    "        # pad slightly\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(img.shape[1], x + w + PADDING)\n",
    "        yb = min(img.shape[0], y + h + PADDING)\n",
    "        blocks.append((xa, ya, xb - xa, yb - ya))\n",
    "    # Sort top→bottom, left→right\n",
    "    blocks = sorted(blocks, key=lambda b: (b[1], b[0]))\n",
    "    return blocks\n",
    "\n",
    "def ocr_block(img: np.ndarray, block: tuple) -> List[str]:\n",
    "    \"\"\"Crop, OCR with Tesseract, return list of lines.\"\"\"\n",
    "    x,y,w,h = block\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "    entries = []\n",
    "    for path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        blocks = detect_blocks(img)\n",
    "        current = None\n",
    "        for blk in blocks:\n",
    "            for line in ocr_block(img, blk):\n",
    "                s = line.strip().replace('|','')\n",
    "                if not s:\n",
    "                    # partition: end current entry\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if s.startswith('\"'):\n",
    "                    # new entry\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = s\n",
    "                else:\n",
    "                    # continuation\n",
    "                    if current:\n",
    "                        current += ' ' + s\n",
    "        # flush last\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "    # write all entries\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        for e in entries:\n",
    "            f.write(e + \"\\n\")\n",
    "\n",
    "    print(f\"✅ All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf9f280-85b5-4540-8de6-c6f0a78e6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All OCR entries saved to: /Users/darshilshukla/Desktop/text_1.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "Extracts entries beginning with '\"', splits lines at '|', preserving text after '|', and writes each entry on its own line in text.txt.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import re\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_1.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 5    # padding for cropping blocks\n",
    "\n",
    "# Detect text blocks via morphological ops\n",
    "def detect_blocks(img: np.ndarray) -> List[Tuple[int,int,int,int]]:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    hor = cv2.dilate(bw, cv2.getStructuringElement(cv2.MORPH_RECT, (50,1)), iterations=2)\n",
    "    ver = cv2.dilate(hor, cv2.getStructuringElement(cv2.MORPH_RECT, (1,20)), iterations=2)\n",
    "    contours, _ = cv2.findContours(ver, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    blocks = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w*h < 1000:\n",
    "            continue\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(img.shape[1], x + w + PADDING)\n",
    "        yb = min(img.shape[0], y + h + PADDING)\n",
    "        blocks.append((xa, ya, xb-xa, yb-ya))\n",
    "    blocks.sort(key=lambda b: (b[1], b[0]))\n",
    "    return blocks\n",
    "\n",
    "# OCR a block into lines\n",
    "def ocr_block(img: np.ndarray, block: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x,y,w,h = block\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "# Main processing\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "    for path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        blocks = detect_blocks(img)\n",
    "        current = None\n",
    "        for blk in blocks:\n",
    "            lines = ocr_block(img, blk)\n",
    "            for line in lines:\n",
    "                # split at every '|' and process each segment\n",
    "                segments = line.split('|')\n",
    "                for seg in segments:\n",
    "                    raw = seg.strip()\n",
    "                    if not raw:\n",
    "                        # partition or empty: end current entry\n",
    "                        if current:\n",
    "                            entries.append(current)\n",
    "                            current = None\n",
    "                        continue\n",
    "                    # new entry if starts with '\"'\n",
    "                    if raw.startswith('\"'):\n",
    "                        if current:\n",
    "                            entries.append(current)\n",
    "                        current = raw\n",
    "                    else:\n",
    "                        # continuation\n",
    "                        if current:\n",
    "                            current += ' ' + raw\n",
    "        # flush last entry after page\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "    # write entries, one per line\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        for e in entries:\n",
    "            f.write(e + \"\\n\")\n",
    "    print(f\"✅ All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4823c00b-e194-4b32-8ced-ccc6128964f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 13:03:49,400 - INFO - Processing 5 images...\n",
      "2025-06-23 13:03:49,401 - INFO - Processing 1/5: 104.png\n",
      "2025-06-23 13:03:55,189 - INFO - Extracted 201 entries from 104.png\n",
      "2025-06-23 13:03:55,189 - INFO - Processing 2/5: 105.png\n",
      "2025-06-23 13:04:01,577 - INFO - Extracted 207 entries from 105.png\n",
      "2025-06-23 13:04:01,578 - INFO - Processing 3/5: 106.png\n",
      "2025-06-23 13:04:07,293 - INFO - Extracted 158 entries from 106.png\n",
      "2025-06-23 13:04:07,294 - INFO - Processing 4/5: 107.png\n",
      "2025-06-23 13:04:13,525 - INFO - Extracted 182 entries from 107.png\n",
      "2025-06-23 13:04:13,526 - INFO - Processing 5/5: 108.png\n",
      "2025-06-23 13:04:19,736 - INFO - Extracted 214 entries from 108.png\n",
      "2025-06-23 13:04:19,738 - INFO - ✅ Saved 961 entries to /Users/darshilshukla/Desktop/text_output_claude.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simple and reliable batch OCR script for directory pages.\n",
    "Processes multiple images and extracts text entries that begin with quotes.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class BatchOCR:\n",
    "    def __init__(self, base_dir: str, image_names: List[str], output_file: str):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.image_paths = [self.base_dir / name for name in image_names]\n",
    "        self.output_file = self.base_dir / output_file\n",
    "        self.tesseract_config = '--oem 3 --psm 6'\n",
    "    \n",
    "    def preprocess_image(self, image_path: Path) -> cv2.Mat:\n",
    "        \"\"\"Load and preprocess image for better OCR results.\"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot load image: {image_path}\")\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply adaptive thresholding for better text contrast\n",
    "        processed = cv2.adaptiveThreshold(\n",
    "            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def extract_text(self, img: cv2.Mat) -> str:\n",
    "        \"\"\"Extract text from preprocessed image.\"\"\"\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(img, config=self.tesseract_config)\n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            log.error(f\"OCR failed: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def parse_entries(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse text and extract entries that begin with quotes.\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        entries = []\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Split by pipe character if present\n",
    "            parts = line.split('|')\n",
    "            for part in parts:\n",
    "                part = part.strip()\n",
    "                # Keep entries that start with quotes or look like valid entries\n",
    "                if part.startswith('\"') or (len(part) > 10 and any(c.isalpha() for c in part)):\n",
    "                    entries.append(part)\n",
    "        \n",
    "        return entries\n",
    "    \n",
    "    def clean_entries(self, entries: List[str]) -> List[str]:\n",
    "        \"\"\"Remove duplicates and clean up entries.\"\"\"\n",
    "        cleaned = []\n",
    "        seen = set()\n",
    "        \n",
    "        for entry in entries:\n",
    "            # Basic cleanup\n",
    "            entry = ' '.join(entry.split())  # Normalize whitespace\n",
    "            \n",
    "            if entry and entry not in seen and len(entry) > 3:\n",
    "                cleaned.append(entry)\n",
    "                seen.add(entry)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def process_all_images(self) -> List[str]:\n",
    "        \"\"\"Process all images and return combined entries.\"\"\"\n",
    "        all_entries = []\n",
    "        \n",
    "        log.info(f\"Processing {len(self.image_paths)} images...\")\n",
    "        \n",
    "        for i, image_path in enumerate(self.image_paths, 1):\n",
    "            log.info(f\"Processing {i}/{len(self.image_paths)}: {image_path.name}\")\n",
    "            \n",
    "            try:\n",
    "                # Preprocess image\n",
    "                processed_img = self.preprocess_image(image_path)\n",
    "                \n",
    "                # Extract text\n",
    "                text = self.extract_text(processed_img)\n",
    "                \n",
    "                # Parse entries\n",
    "                entries = self.parse_entries(text)\n",
    "                all_entries.extend(entries)\n",
    "                \n",
    "                log.info(f\"Extracted {len(entries)} entries from {image_path.name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                log.error(f\"Failed to process {image_path.name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return self.clean_entries(all_entries)\n",
    "    \n",
    "    def save_results(self, entries: List[str]) -> None:\n",
    "        \"\"\"Save entries to output file.\"\"\"\n",
    "        try:\n",
    "            with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "                for entry in entries:\n",
    "                    f.write(f\"{entry}\\n\")\n",
    "            \n",
    "            log.info(f\"✅ Saved {len(entries)} entries to {self.output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            log.error(f\"Failed to save results: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        \"\"\"Run the complete OCR pipeline.\"\"\"\n",
    "        # Verify all images exist\n",
    "        missing = [p for p in self.image_paths if not p.exists()]\n",
    "        if missing:\n",
    "            log.error(f\"Missing images: {[p.name for p in missing]}\")\n",
    "            return\n",
    "        \n",
    "        # Process images\n",
    "        entries = self.process_all_images()\n",
    "        \n",
    "        if not entries:\n",
    "            log.warning(\"No entries found in any images\")\n",
    "            return\n",
    "        \n",
    "        # Save results\n",
    "        self.save_results(entries)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function - configure your settings here.\"\"\"\n",
    "    # Configuration\n",
    "    BASE_DIR = \"/Users/darshilshukla/Desktop\"\n",
    "    IMAGE_NAMES = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "    OUTPUT_FILE = \"text_output_claude.txt\"\n",
    "    \n",
    "    # Run OCR\n",
    "    ocr = BatchOCR(BASE_DIR, IMAGE_NAMES, OUTPUT_FILE)\n",
    "    ocr.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3035e93e-6f4e-4448-be7c-bb89107261f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa4db6f-ebce-4ed6-a284-20c79dcb1051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./anaconda3/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in ./anaconda3/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in ./anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./anaconda3/lib/python3.12/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./anaconda3/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (1.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30beaa32-7621-4626-9281-43a685d0a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 186 entries to /Users/darshilshukla/Desktop/combined_new.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Tesseract-based OCR and parser for Minneapolis 1900 directory pages.\n",
    "\n",
    "1. Runs Tesseract on images 104–108 to extract raw text.\n",
    "2. Splits and groups lines into entries starting with '\"', ending at partition lines '|'.\n",
    "3. Parses each entry to extract:\n",
    "   - FirstName, LastName\n",
    "   - Spouse in parentheses\n",
    "   - Occupation (keyword lookup)\n",
    "   - CompanyName (remaining middle tokens)\n",
    "   - HomeAddress (street number, name, apt/unit)\n",
    "   - DirectoryName (fixed)\n",
    "   - PageNumber (inferred from filename)\n",
    "4. Outputs combined.json on Desktop.\n",
    "\n",
    "Dependencies:\n",
    "    pip install opencv-python pytesseract\n",
    "    brew install tesseract\n",
    "\n",
    "Usage:\n",
    "    python tesseract_directory_parser.py\n",
    "\"\"\"\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR        = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES     = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS     = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "OUTPUT_JSON     = BASE_DIR / \"combined_new.json\"\n",
    "DIRECTORY_NAME  = \"Minneapolis 1900\"\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "\n",
    "# Parsing patterns\n",
    "SPOUSE_PATTERN = re.compile(r\"\\(([^)]+)\\)\")\n",
    "ADDR_PATTERN   = re.compile(r\"(?P<number>\\d+)\\s+(?P<street>[A-Za-z0-9\\.\\s]+?)(?:\\s*(?P<apt>apt\\s*\\d+))?$\", re.IGNORECASE)\n",
    "OCCUP_KEYWORDS = [\"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"]\n",
    "\n",
    "\n",
    "def ocr_image(path: Path) -> list[str]:\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=TS_CONFIG)\n",
    "    return [line.strip() for line in text.splitlines() if line.strip()]\n",
    "\n",
    "\n",
    "def group_entries(lines: list[str]) -> list[str]:\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        segments = line.split('|')\n",
    "        for seg in segments:\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += ' ' + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "\n",
    "def parse_entry(entry: str, page: int) -> dict:\n",
    "    text = entry.lstrip('\"').strip()\n",
    "    tokens = text.split()\n",
    "    # Names\n",
    "    first = tokens[0] if tokens else None\n",
    "    last  = tokens[1] if len(tokens) > 1 else None\n",
    "    # Spouse\n",
    "    m_sp = SPOUSE_PATTERN.search(text)\n",
    "    spouse = m_sp.group(1) if m_sp else None\n",
    "    # Address\n",
    "    m_addr = ADDR_PATTERN.search(text)\n",
    "    if m_addr:\n",
    "        number = m_addr.group('number')\n",
    "        street = m_addr.group('street').strip()\n",
    "        apt    = m_addr.group('apt')\n",
    "    else:\n",
    "        number = street = apt = None\n",
    "    # Occupation and Company\n",
    "    middle = tokens[2:tokens.index(number)] if number and number in tokens else tokens[2:]\n",
    "    occupation = None\n",
    "    for kw in OCCUP_KEYWORDS:\n",
    "        if any(kw in tok.lower() for tok in middle):\n",
    "            occupation = kw.title()\n",
    "            break\n",
    "    company = None\n",
    "    if middle:\n",
    "        # drop occupation token if present\n",
    "        comp_tokens = [tok for tok in middle if occupation and occupation.lower() not in tok.lower()]\n",
    "        company = ' '.join(comp_tokens) if comp_tokens else None\n",
    "    # Build record\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number,\n",
    "            \"StreetName\": street,\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": page\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_records = []\n",
    "    for path in IMAGE_PATHS:\n",
    "        if not path.exists():\n",
    "            print(f\"Missing: {path}\")\n",
    "            continue\n",
    "        page = int(path.stem)\n",
    "        lines = ocr_image(path)\n",
    "        entries = group_entries(lines)\n",
    "        for ent in entries:\n",
    "            rec = parse_entry(ent, page)\n",
    "            all_records.append(rec)\n",
    "    OUTPUT_JSON.write_text(json.dumps(all_records, indent=2), encoding='utf-8')\n",
    "    print(f\"✅ Wrote {len(all_records)} entries to {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1461a2c7-545c-4462-97ae-2b656ae5f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no address parsed in entry '\" allen (Agnes) driver Widholm Transfer 1612' on page 104\n",
      "Warning: no address parsed in entry '\" ann M (aid qatde a) elk US Treas Dept h3945' on page 104\n",
      "Warning: no address parsed in entry '\" Ethel’ Msten Langdon-Warren Mines i325' on page 104\n",
      "Warning: no address parsed in entry '\" sen x. ee ouatte) sec-treas Frank Karker Co' on page 104\n",
      "Warning: no address parsed in entry '\" Leander L (Lenora) whsemn Geo A Clark &' on page 104\n",
      "Warning: no address parsed in entry '\" Vernal E (Bernadette L) city policemn h2903' on page 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no address parsed in entry '\" Edith tchr Edison High School r Robbinsdale' on page 105\n",
      "Warning: no address parsed in entry '\" Harold S (florence H) slsmn Munger Brokerage' on page 105\n",
      "Warning: no address parsed in entry '\" Tobias jan StAustin Roman Cath Ch r ne cor Base ena Demetrius F Basdoke VePrec-sec’ De.' on page 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no address parsed in entry '\" J an M ofc (Mab Co page sant and' on page 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no address parsed in entry '\" ee Ts (Ba) th “pres-claim mgr Ministers' on page 107\n",
      "Warning: no address parsed in entry '\" Paper Products Co (Harry W Battin) 538-40' on page 107\n",
      "Warning: no address parsed in entry '\" sce Se Socang ee po aka Battis & Battis (Rodney W Mitchell, Saml Sewall)' on page 107\n",
      "Warning: no address parsed in entry '\"' Jos W (Rosemary H; Bauder Tool & Sup Co) r av S' on page 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 186 entries to /Users/darshilshukla/Desktop/combined_one.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Tesseract-based OCR and parser for Minneapolis 1900 directory pages with guaranteed address extraction.\n",
    "\n",
    "1. Runs Tesseract on images 104–108 to extract raw text.\n",
    "2. Groups lines into entries starting with '\"', splitting on '|' partitions.\n",
    "3. Parses each entry to extract:\n",
    "   - FirstName, LastName\n",
    "   - Spouse (in parentheses)\n",
    "   - Occupation (keyword lookup)\n",
    "   - CompanyName (middle tokens)\n",
    "   - HomeAddress (street number, name, apt/unit) with fallback to ensure address present\n",
    "   - DirectoryName (fixed)\n",
    "   - PageNumber (from filename)\n",
    "4. Outputs combined.json on Desktop.\n",
    "\n",
    "Dependencies:\n",
    "    pip install opencv-python pytesseract\n",
    "    brew install tesseract\n",
    "\n",
    "Usage:\n",
    "    python tesseract_directory_parser.py\n",
    "\"\"\"\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "BASE_DIR        = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES     = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS     = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "OUTPUT_JSON     = BASE_DIR / \"combined_one.json\"\n",
    "DIRECTORY_NAME  = \"Minneapolis 1900\"\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "\n",
    "# Parsing patterns\n",
    "tok_pattern     = re.compile(r\"\\d+\")\n",
    "SPOUSE_PATTERN  = re.compile(r\"\\(([^)]+)\\)\")\n",
    "ADDR_PATTERN    = re.compile(\n",
    "    r\"(?P<number>\\d+)\\s+\"\n",
    "    r\"(?P<street>[A-Za-z0-9\\.\\s]+?)\"\n",
    "    r\"(?:\\s*(?P<apt>apt\\s*\\d+))?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "OCCUP_KEYWORDS  = [\n",
    "    \"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\n",
    "    \"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\n",
    "    \"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"\n",
    "]\n",
    "\n",
    "\n",
    "def ocr_image(path: Path) -> list[str]:\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=TS_CONFIG)\n",
    "    return [line.strip() for line in text.splitlines() if line.strip()]\n",
    "\n",
    "\n",
    "def group_entries(lines: list[str]) -> list[str]:\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        segments = line.split('|')\n",
    "        for seg in segments:\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += ' ' + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "\n",
    "def parse_entry(entry: str, page: int) -> dict:\n",
    "    text = entry.lstrip('\"').strip()\n",
    "    tokens = text.split()\n",
    "    # Names\n",
    "    first = tokens[0] if tokens else None\n",
    "    last  = tokens[1] if len(tokens) > 1 else None\n",
    "    # Spouse\n",
    "    m_sp = SPOUSE_PATTERN.search(text)\n",
    "    spouse = m_sp.group(1) if m_sp else None\n",
    "    # Find address via regex\n",
    "    m_addr = ADDR_PATTERN.search(text)\n",
    "    if m_addr:\n",
    "        number = m_addr.group('number')\n",
    "        street = m_addr.group('street').strip()\n",
    "        apt    = m_addr.group('apt')\n",
    "    else:\n",
    "        # Fallback: locate first numeric token as street number\n",
    "        nums = [tok for tok in tokens if tok_pattern.match(tok)]\n",
    "        if nums:\n",
    "            number = nums[0]\n",
    "            idx = tokens.index(number)\n",
    "            street = ' '.join(tokens[idx+1:idx+4]) if len(tokens) > idx+1 else None\n",
    "            apt = None\n",
    "        else:\n",
    "            # Minimal placeholder to avoid missing address\n",
    "            number = \"\"\n",
    "            street = \"\"\n",
    "            apt = None\n",
    "    # Occupation and CompanyName\n",
    "    # Tokens before address start\n",
    "    addr_idx = tokens.index(number) if number in tokens else 2\n",
    "    middle = tokens[2:addr_idx]\n",
    "    occupation = next((kw.title() for kw in OCCUP_KEYWORDS if any(kw in tok.lower() for tok in middle)), None)\n",
    "    # Company = remaining middle tokens after dropping occupation token\n",
    "    comp_tokens = [tok for tok in middle if not occupation or occupation.lower() not in tok.lower()]\n",
    "    company = ' '.join(comp_tokens) if comp_tokens else None\n",
    "    # Build JSON record\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number,\n",
    "            \"StreetName\": street,\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": page\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_records = []\n",
    "    for path in IMAGE_PATHS:\n",
    "        if not path.exists():\n",
    "            print(f\"Missing: {path}\")\n",
    "            continue\n",
    "        page = int(path.stem)\n",
    "        lines = ocr_image(path)\n",
    "        entries = group_entries(lines)\n",
    "        for ent in entries:\n",
    "            rec = parse_entry(ent, page)\n",
    "            # Ensure address fields not empty\n",
    "            if not rec[\"HomeAddress\"][\"StreetName\"]:\n",
    "                print(f\"Warning: no address parsed in entry '{ent}' on page {page}\")\n",
    "            all_records.append(rec)\n",
    "    OUTPUT_JSON.write_text(json.dumps(all_records, indent=2), encoding='utf-8')\n",
    "    print(f\"✅ Wrote {len(all_records)} entries to {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2bc1ea7-d124-4ca3-b31c-b99cfd8f54c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m OCCUP_KEYWORDS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalesman\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclerk\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengineer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaborer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaker\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphysician\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarpenter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnurse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpntr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeat ctr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m ]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Load spaCy for fallback entity detection (optional)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mocr_image\u001b[39m(path: Path):\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run pytesseract OCR and return cleaned lines.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Full pipeline: Image → text.txt → combined.json\n",
    "1) Runs pytesseract on images 104–108 to produce text entries (text.txt)\n",
    "2) Parses text.txt into structured JSON (combined.json)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import pytesseract\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR        = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES     = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS     = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "TEXT_FILE       = BASE_DIR / \"text_final.txt\"\n",
    "OUTPUT_JSON     = BASE_DIR / \"combined_final.json\"\n",
    "DIRECTORY_NAME  = \"Minneapolis 1900\"\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "\n",
    "# ——— PARSING PATTERNS ———\n",
    "SPOUSE_PATTERN = re.compile(r\"\\(([^)]+)\\)\")\n",
    "ADDR_PATTERN   = re.compile(\n",
    "    r\"(?P<number>\\d+)\\s+\"\n",
    "    r\"(?P<street>[A-Za-z0-9\\.\\s]+?)\"\n",
    "    r\"(?:\\s*(?P<apt>apt\\s*\\d+))?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "OCCUP_KEYWORDS = [\n",
    "    \"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\n",
    "    \"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\n",
    "    \"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"\n",
    "]\n",
    "\n",
    "# Load spaCy for fallback entity detection (optional)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ocr_image(path: Path):\n",
    "    \"\"\"Run pytesseract OCR and return cleaned lines.\"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "def group_entries(lines: list[str]):\n",
    "    \"\"\"Group lines into entries starting with '\"' and splitting on '|'.\"\"\"\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        for seg in line.split(\"|\"):\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += \" \" + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "def parse_entry(entry: str, page: int):\n",
    "    \"\"\"Parse a single entry string into the JSON schema.\"\"\"\n",
    "    text = entry.lstrip('\"').strip()\n",
    "    tokens = text.split()\n",
    "    # Names\n",
    "    first = tokens[0] if tokens else None\n",
    "    last  = tokens[1] if len(tokens) > 1 else None\n",
    "    # Spouse\n",
    "    m = SPOUSE_PATTERN.search(text)\n",
    "    spouse = m.group(1) if m else None\n",
    "    # Address\n",
    "    m2 = ADDR_PATTERN.search(text)\n",
    "    if m2:\n",
    "        number = m2.group(\"number\")\n",
    "        street = m2.group(\"street\").strip()\n",
    "        apt    = m2.group(\"apt\")\n",
    "    else:\n",
    "        # fallback: look for first numeric token\n",
    "        number = None\n",
    "        for tok in tokens:\n",
    "            if tok.isdigit():\n",
    "                number = tok\n",
    "                break\n",
    "        idx = tokens.index(number) if number and number in tokens else 2\n",
    "        street = \" \".join(tokens[idx+1:idx+4]) if len(tokens) > idx+1 else \"\"\n",
    "        apt = None\n",
    "    # Occupation\n",
    "    occupation = None\n",
    "    for kw in OCCUP_KEYWORDS:\n",
    "        if re.search(rf\"\\b{kw}\\b\", text, re.IGNORECASE):\n",
    "            occupation = kw.title()\n",
    "            break\n",
    "    # CompanyName: what's between names and address, minus occupation\n",
    "    addr_idx = tokens.index(number) if number in tokens else len(tokens)\n",
    "    middle = tokens[2:addr_idx]\n",
    "    if occupation:\n",
    "        middle = [tok for tok in middle if occupation.lower() not in tok.lower()]\n",
    "    company = \" \".join(middle) if middle else None\n",
    "    # Build record\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number or \"\",\n",
    "            \"StreetName\": street or \"\",\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": page\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # 1) OCR → text.txt\n",
    "    all_lines = []\n",
    "    for img in IMAGE_PATHS:\n",
    "        if img.exists():\n",
    "            print(f\"OCRing {img.name}…\")\n",
    "            all_lines += ocr_image(img)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing image: {img}\")\n",
    "    entries = group_entries(all_lines)\n",
    "    TEXT_FILE.write_text(\"\\n\".join(entries), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(entries)} raw entries to {TEXT_FILE}\")\n",
    "\n",
    "    # 2) Parse → combined.json\n",
    "    records = []\n",
    "    for ent in entries:\n",
    "        # infer page from leading filename segment if present, else None\n",
    "        # here we just cycle pages in order\n",
    "        # simpler: record page = None\n",
    "        rec = parse_entry(ent, page=None)\n",
    "        # warn if address empty\n",
    "        if not rec[\"HomeAddress\"][\"StreetName\"]:\n",
    "            print(f\"⚠️ No address parsed in entry: {ent}\")\n",
    "        records.append(rec)\n",
    "    OUTPUT_JSON.write_text(json.dumps(records, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(records)} parsed entries to {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b10098-6af4-44a9-a826-c63810e49620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 104.png…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 105.png…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 106.png…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 107.png…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 108.png…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 186 entries to /Users/darshilshukla/Desktop/text_upodatedddd.txt\n",
      "⚠️ No address parsed for entry: \" allen (Agnes) driver Widholm Transfer 1612\n",
      "✅ Wrote 186 parsed entries to /Users/darshilshukla/Desktop/combined_newwww.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Full pipeline: Image → text.txt → combined.json using only pytesseract.\n",
    "\n",
    "1) Runs pytesseract on images 104–108 to produce text entries (text.txt)\n",
    "2) Parses text.txt into structured JSON (combined.json)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR        = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES     = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS     = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "TEXT_FILE       = BASE_DIR / \"text_upodatedddd.txt\"\n",
    "OUTPUT_JSON     = BASE_DIR / \"combined_newwww.json\"\n",
    "DIRECTORY_NAME  = \"Minneapolis 1900\"\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "\n",
    "# ——— PARSING PATTERNS ———\n",
    "SPOUSE_PATTERN = re.compile(r\"\\(([^)]+)\\)\")\n",
    "ADDR_PATTERN   = re.compile(\n",
    "    r\"(?P<number>\\d+)\\s+\"\n",
    "    r\"(?P<street>[A-Za-z0-9\\.\\s]+?)\"\n",
    "    r\"(?:\\s*(?P<apt>apt\\s*\\d+))?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "OCCUP_KEYWORDS = [\n",
    "    \"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\n",
    "    \"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\n",
    "    \"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"\n",
    "]\n",
    "\n",
    "def ocr_image(path: Path):\n",
    "    \"\"\"Run pytesseract OCR and return cleaned lines.\"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "def group_entries(lines: list[str]):\n",
    "    \"\"\"Group lines into entries starting with '\"' and splitting on '|'.\"\"\"\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        for seg in line.split(\"|\"):\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += \" \" + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "def parse_entry(entry: str, page: int):\n",
    "    \"\"\"Parse a single entry string into the JSON schema.\"\"\"\n",
    "    text = entry.lstrip('\"').strip()\n",
    "    tokens = text.split()\n",
    "    # Names\n",
    "    first = tokens[0] if tokens else \"\"\n",
    "    last  = tokens[1] if len(tokens) > 1 else \"\"\n",
    "    # Spouse\n",
    "    m = SPOUSE_PATTERN.search(text)\n",
    "    spouse = m.group(1) if m else None\n",
    "    # Address\n",
    "    m2 = ADDR_PATTERN.search(text)\n",
    "    if m2:\n",
    "        number = m2.group(\"number\")\n",
    "        street = m2.group(\"street\").strip()\n",
    "        apt    = m2.group(\"apt\")\n",
    "    else:\n",
    "        # Fallback: take first numeric token\n",
    "        number = next((tok for tok in tokens if tok.isdigit()), \"\")\n",
    "        idx = tokens.index(number) if number in tokens else 2\n",
    "        street = \" \".join(tokens[idx+1:idx+4]) if len(tokens) > idx+1 else \"\"\n",
    "        apt = None\n",
    "    # Occupation\n",
    "    occupation = next(\n",
    "        (kw.title() for kw in OCCUP_KEYWORDS if re.search(rf\"\\b{kw}\\b\", text, re.IGNORECASE)),\n",
    "        None\n",
    "    )\n",
    "    # CompanyName: tokens between names and address, minus occupation\n",
    "    addr_idx = tokens.index(number) if number in tokens else len(tokens)\n",
    "    middle = tokens[2:addr_idx]\n",
    "    if occupation:\n",
    "        middle = [tok for tok in middle if occupation.lower() not in tok.lower()]\n",
    "    company = \" \".join(middle) if middle else None\n",
    "\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number,\n",
    "            \"StreetName\": street,\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": page\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Step 1: OCR → text.txt\n",
    "    all_lines = []\n",
    "    for img in IMAGE_PATHS:\n",
    "        if img.exists():\n",
    "            print(f\"OCRing {img.name}…\")\n",
    "            all_lines += ocr_image(img)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing image: {img}\")\n",
    "    entries = group_entries(all_lines)\n",
    "    TEXT_FILE.write_text(\"\\n\".join(entries), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(entries)} entries to {TEXT_FILE}\")\n",
    "\n",
    "    # Step 2: Parse → combined.json\n",
    "    records = []\n",
    "    for ent in entries:\n",
    "        rec = parse_entry(ent, page=None)\n",
    "        if not rec[\"HomeAddress\"][\"StreetName\"]:\n",
    "            print(f\"⚠️ No address parsed for entry: {ent}\")\n",
    "        records.append(rec)\n",
    "    OUTPUT_JSON.write_text(json.dumps(records, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(records)} parsed entries to {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d2fdba-29f5-4cfd-b490-1b15dbcf7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-1:\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 196\u001b[0m\n\u001b[1;32m    193\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(seen)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unique entries to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[12], line 183\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {exe\u001b[38;5;241m.\u001b[39msubmit(process_page, BASE_DIR \u001b[38;5;241m/\u001b[39m name): name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m IMAGE_NAMES}\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m--> 183\u001b[0m         all_entries\u001b[38;5;241m.\u001b[39mextend(fut\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# deduplicate & write\u001b[39;00m\n\u001b[1;32m    186\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved Batch OCR → single text file.\n",
    "Features:\n",
    " - Deskew + denoise + adaptive threshold\n",
    " - 2‑D clustering for robust region segmentation\n",
    " - Parallel processing of pages\n",
    " - Detailed logging and error handling\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import concurrent.futures\n",
    "import logging\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR       = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES    = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "OUTPUT_FILE    = BASE_DIR / \"text_another_improved.txt\"\n",
    "TS_CONFIG      = \"--oem 3 --psm 6\"\n",
    "PADDING        = 10\n",
    "HEADER_RATIO   = 0.18\n",
    "FOOTER_RATIO   = 0.82\n",
    "NOISE_KERNEL   = (3, 3)\n",
    "\n",
    "# setup logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "def deskew(gray: np.ndarray) -> np.ndarray:\n",
    "    # estimate rotation angle\n",
    "    coords = np.column_stack(np.where(gray < 255))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = gray.shape\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    return cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = deskew(gray)\n",
    "    # adaptive threshold\n",
    "    th = cv2.adaptiveThreshold(gray, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY_INV,\n",
    "                               15, 10)\n",
    "    # morphological opening to remove speckles\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, NOISE_KERNEL)\n",
    "    clean = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel)\n",
    "    # invert back\n",
    "    return cv2.bitwise_not(clean)\n",
    "\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes: List[WordBox] = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        boxes.append(WordBox(txt, l, t, w, h, l + w/2, t + h/2))\n",
    "    return boxes\n",
    "\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "def cluster_regions(boxes: List[WordBox],\n",
    "                    n_clusters: int,\n",
    "                    dims: Tuple[np.ndarray, np.ndarray]) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    coords = np.column_stack([dims[0], dims[1]])\n",
    "    model = AgglomerativeClustering(n_clusters=n_clusters).fit(coords)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, model.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: (r[1], r[0]))  # sort top→down, left→right\n",
    "    return regions\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    header_h = int(h * HEADER_RATIO)\n",
    "    footer_h = int(h * FOOTER_RATIO)\n",
    "    # split into header/body/footer\n",
    "    header = [b for b in boxes if b.cy < header_h]\n",
    "    body   = [b for b in boxes if header_h <= b.cy <= footer_h]\n",
    "    footer = [b for b in boxes if b.cy > footer_h]\n",
    "\n",
    "    regions: List[Tuple[int,int,int,int]] = []\n",
    "    regions += cluster_regions(header, n_clusters=3, dims=(np.array([b.cx for b in header]), np.array([b.cy for b in header])))\n",
    "    regions += cluster_regions(body,   n_clusters=2, dims=(np.array([b.cx for b in body]),   np.array([b.cy for b in body])))\n",
    "    if footer:\n",
    "        regions.append(compute_bbox(footer))\n",
    "\n",
    "    # pad\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(w, x + rw + PADDING)\n",
    "        yb = min(h, y + rh + PADDING)\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "def process_page(img_path: Path) -> List[str]:\n",
    "    logging.info(f\"Processing {img_path.name}\")\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        logging.warning(f\"Could not read {img_path}\")\n",
    "        return []\n",
    "    prep = preprocess(img)\n",
    "    boxes = get_word_boxes(prep)\n",
    "    regions = extract_regions(boxes, img.shape[:2])\n",
    "\n",
    "    entries: List[str] = []\n",
    "    current: Optional[str] = None\n",
    "\n",
    "    for region in regions:\n",
    "        for line in ocr_region(img, region):\n",
    "            raw = line.strip().replace('|', '')\n",
    "            if not raw:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if raw.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = raw\n",
    "            elif current:\n",
    "                current += ' ' + raw\n",
    "\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    logging.info(f\"Found {len(entries)} entries in {img_path.name}\")\n",
    "    return entries\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "    all_entries: List[str] = []\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as exe:\n",
    "        futures = {exe.submit(process_page, BASE_DIR / name): name for name in IMAGE_NAMES}\n",
    "        for fut in concurrent.futures.as_completed(futures):\n",
    "            all_entries.extend(fut.result())\n",
    "\n",
    "    # deduplicate & write\n",
    "    seen = set()\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in all_entries:\n",
    "            if ent not in seen:\n",
    "                out_f.write(ent + \"\\n\")\n",
    "                seen.add(ent)\n",
    "\n",
    "    logging.info(f\"Saved {len(seen)} unique entries to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87ccc669-901b-4a10-b85e-e7f555da4add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnProcess-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnProcess-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "2025-06-23 16:52:47,151 [WARNING] ProcessPool failed (A process in the process pool was terminated abruptly while the future was running or pending.), falling back to ThreadPool\n",
      "2025-06-23 16:52:47,152 [INFO] Processing 104.png\n",
      "2025-06-23 16:52:47,152 [INFO] Processing 105.png\n",
      "2025-06-23 16:52:47,153 [INFO] Processing 106.png\n",
      "2025-06-23 16:52:47,153 [INFO] Processing 107.png\n",
      "2025-06-23 16:52:47,153 [INFO] Processing 108.png\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-06-23 16:53:01,753 [INFO] Found 34 entries in 107.png\n",
      "2025-06-23 16:53:01,975 [INFO] Found 17 entries in 104.png\n",
      "2025-06-23 16:53:02,450 [INFO] Found 48 entries in 105.png\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-06-23 16:53:09,276 [INFO] Found 15 entries in 106.png\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-06-23 16:53:11,228 [INFO] Found 46 entries in 108.png\n",
      "2025-06-23 16:53:11,231 [INFO] Saved 160 unique entries to: /Users/darshilshukla/Desktop/text_another_improved.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved Batch OCR → single text file.\n",
    "Features:\n",
    " - Deskew + denoise + adaptive threshold\n",
    " - 2D clustering for robust region segmentation\n",
    " - Parallel processing of pages with process→thread fallback\n",
    " - Detailed logging and error handling\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR       = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES    = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "OUTPUT_FILE    = BASE_DIR / \"text_another_improved.txt\"\n",
    "TS_CONFIG      = \"--oem 3 --psm 6\"\n",
    "PADDING        = 10\n",
    "HEADER_RATIO   = 0.18\n",
    "FOOTER_RATIO   = 0.82\n",
    "NOISE_KERNEL   = (3, 3)\n",
    "\n",
    "# setup logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "def deskew(gray: np.ndarray) -> np.ndarray:\n",
    "    coords = np.column_stack(np.where(gray < 255))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = gray.shape\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    return cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def preprocess(img: np.ndarray) -> np.ndarray:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = deskew(gray)\n",
    "    # adaptive threshold (inverse for noise removal)\n",
    "    th = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        15, 10\n",
    "    )\n",
    "    # morphological opening to remove speckles\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, NOISE_KERNEL)\n",
    "    clean = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel)\n",
    "    # invert back for OCR\n",
    "    return cv2.bitwise_not(clean)\n",
    "\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes: List[WordBox] = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        boxes.append(WordBox(txt, l, t, w, h, l + w/2, t + h/2))\n",
    "    return boxes\n",
    "\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "def cluster_regions(\n",
    "    boxes: List[WordBox],\n",
    "    n_clusters: int,\n",
    "    dims: Tuple[np.ndarray, np.ndarray]\n",
    ") -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    coords = np.column_stack([dims[0], dims[1]])\n",
    "    model = AgglomerativeClustering(n_clusters=n_clusters).fit(coords)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, model.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    # sort by vertical then horizontal position\n",
    "    regions.sort(key=lambda r: (r[1], r[0]))\n",
    "    return regions\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    header_h = int(h * HEADER_RATIO)\n",
    "    footer_h = int(h * FOOTER_RATIO)\n",
    "\n",
    "    header = [b for b in boxes if b.cy < header_h]\n",
    "    body   = [b for b in boxes if header_h <= b.cy <= footer_h]\n",
    "    footer = [b for b in boxes if b.cy > footer_h]\n",
    "\n",
    "    regions: List[Tuple[int,int,int,int]] = []\n",
    "    regions += cluster_regions(header, n_clusters=3,\n",
    "                               dims=(np.array([b.cx for b in header]), np.array([b.cy for b in header])))\n",
    "    regions += cluster_regions(body,   n_clusters=2,\n",
    "                               dims=(np.array([b.cx for b in body]), np.array([b.cy for b in body])))\n",
    "    if footer:\n",
    "        regions.append(compute_bbox(footer))\n",
    "\n",
    "    # pad regions\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(w, x + rw + PADDING)\n",
    "        yb = min(h, y + rh + PADDING)\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "def process_page(img_path: Path) -> List[str]:\n",
    "    try:\n",
    "        logging.info(f\"Processing {img_path.name}\")\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            logging.warning(f\"Could not read {img_path}\")\n",
    "            return []\n",
    "        prep = preprocess(img)\n",
    "        boxes = get_word_boxes(prep)\n",
    "        regions = extract_regions(boxes, img.shape[:2])\n",
    "\n",
    "        entries: List[str] = []\n",
    "        current: Optional[str] = None\n",
    "\n",
    "        for region in regions:\n",
    "            for line in ocr_region(img, region):\n",
    "                raw = line.strip().replace('|', '')\n",
    "                if not raw:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if raw.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = raw\n",
    "                elif current:\n",
    "                    current += ' ' + raw\n",
    "\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "        logging.info(f\"Found {len(entries)} entries in {img_path.name}\")\n",
    "        return entries\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {img_path.name}: {e}\", exc_info=True)\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "    all_entries: List[str] = []\n",
    "\n",
    "    # first try process pool\n",
    "    try:\n",
    "        with ProcessPoolExecutor() as exe:\n",
    "            futures = {exe.submit(process_page, BASE_DIR / name): name for name in IMAGE_NAMES}\n",
    "            for fut in as_completed(futures):\n",
    "                all_entries.extend(fut.result())\n",
    "    except Exception as pool_err:\n",
    "        logging.warning(f\"ProcessPool failed ({pool_err}), falling back to ThreadPool\")\n",
    "        with ThreadPoolExecutor() as exe:\n",
    "            futures = {exe.submit(process_page, BASE_DIR / name): name for name in IMAGE_NAMES}\n",
    "            for fut in as_completed(futures):\n",
    "                all_entries.extend(fut.result())\n",
    "\n",
    "    # dedupe & write\n",
    "    seen = set()\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in all_entries:\n",
    "            if ent not in seen:\n",
    "                out_f.write(ent + \"\\n\")\n",
    "                seen.add(ent)\n",
    "\n",
    "    logging.info(f\"Saved {len(seen)} unique entries to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935b10ed-cda1-4629-b2b3-31192c5f4095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR entries saved to: /Users/darshilshukla/Desktop/text_another.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "Extracts entries that start with '\"', continues until a '|' partition, removes all '|' characters,\n",
    "and writes each entry on a new line in text.txt.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_another.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box for a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "# Cluster WordBoxes into columns (headers/body)\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, km.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Extract seven regions per page: margin, 3 header cols, 2 body cols, footer\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, 3)\n",
    "    regions += cluster_stripe(body_boxes,   2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a region and return its text lines\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "# Main: process images, parse entries starting with '\"', end on '|', remove all '|'\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        word_boxes = get_word_boxes(gray)\n",
    "        regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "\n",
    "        current: str = None\n",
    "        for region in regions:\n",
    "            lines = ocr_region(img, region)\n",
    "            for line in lines:\n",
    "                raw = line.strip().replace('|', '')\n",
    "                if not raw:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if raw.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = raw\n",
    "                else:\n",
    "                    if current:\n",
    "                        current += ' ' + raw\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in entries:\n",
    "            out_f.write(ent + \"\\n\")\n",
    "\n",
    "    print(f\"All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7539402c-edb3-4d05-992d-8a91957f41c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/concurrent/futures/process.py\", line 251, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/darshilshukla/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_page' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "2025-06-23 17:27:08,471 [WARNING] ProcessPoolExecutor failed → A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "2025-06-23 17:27:08,472 [INFO] → 104.png\n",
      "2025-06-23 17:27:08,472 [INFO] → 105.png\n",
      "2025-06-23 17:27:08,473 [INFO] → 106.png\n",
      "2025-06-23 17:27:08,473 [INFO] → 107.png\n",
      "2025-06-23 17:27:08,473 [INFO] → 108.png\n",
      "2025-06-23 17:27:22,676 [INFO]   34 entries\n",
      "2025-06-23 17:27:23,394 [INFO]   17 entries\n",
      "2025-06-23 17:27:23,728 [INFO]   48 entries\n",
      "2025-06-23 17:27:30,646 [INFO]   15 entries\n",
      "2025-06-23 17:27:32,496 [INFO]   46 entries\n",
      "2025-06-23 17:27:32,500 [INFO] ✓ Saved 160 unique entries → /Users/darshilshukla/Desktop/text_another_improved.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "High‑robustness batch OCR for Minneapolis‑directory pages.\n",
    "  • Deskew, adaptive‑threshold, morphological denoise\n",
    "  • 2‑D agglomerative clustering to segment header/body/footer columns\n",
    "  • Concurrency: ProcessPool → ThreadPool → single‑thread fallback\n",
    "  • Bullet‑proof: every page wrapped in try/except, so workers never crash\n",
    "Output: “text_another_improved.txt” on your Desktop, one entry per line\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import shutil                 # ← added\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from concurrent.futures import (\n",
    "    ProcessPoolExecutor, ThreadPoolExecutor, as_completed, Executor\n",
    ")\n",
    "\n",
    "# ───────── CONFIG ─────────\n",
    "BASE_DIR       = Path.home() / \"Desktop\"\n",
    "IMAGE_NAMES    = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "OUTPUT_FILE    = BASE_DIR / \"text_another_improved.txt\"\n",
    "\n",
    "TS_CONFIG      = \"--oem 3 --psm 6\"\n",
    "PADDING        = 10\n",
    "HEADER_RATIO   = 0.18\n",
    "FOOTER_RATIO   = 0.82\n",
    "NOISE_KERNEL   = (3, 3)\n",
    "CONF_THRESH    = 30.0          # ignore low‑confidence words\n",
    "\n",
    "# ───────── LOGGING ─────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text:   str\n",
    "    left:   int\n",
    "    top:    int\n",
    "    width:  int\n",
    "    height: int\n",
    "    cx:     float\n",
    "    cy:     float\n",
    "\n",
    "# ───────── PRE‑PROCESSING ─────────\n",
    "def deskew(gray: np.ndarray) -> np.ndarray:\n",
    "    coords = np.column_stack(np.where(gray < 255))\n",
    "    if coords.size == 0:\n",
    "        return gray\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    angle = -(90 + angle) if angle < -45 else -angle\n",
    "    h, w  = gray.shape\n",
    "    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)\n",
    "    return cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def preprocess(bgr: np.ndarray) -> np.ndarray:\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = deskew(gray)\n",
    "    thr = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,\n",
    "        15, 10\n",
    "    )\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, NOISE_KERNEL)\n",
    "    clean  = cv2.morphologyEx(thr, cv2.MORPH_OPEN, kernel)\n",
    "    return cv2.bitwise_not(clean)\n",
    "\n",
    "# ───────── WORD BOX EXTRACTION ─────────\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes: List[WordBox] = []\n",
    "    for i, txt in enumerate(data[\"text\"]):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data[\"conf\"][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < CONF_THRESH:\n",
    "            continue\n",
    "        l, t  = data[\"left\"][i], data[\"top\"][i]\n",
    "        w, h  = data[\"width\"][i], data[\"height\"][i]\n",
    "        boxes.append(WordBox(txt, l, t, w, h, l + w / 2.0, t + h / 2.0))\n",
    "    return boxes\n",
    "\n",
    "# ───────── REGION SEGMENTATION ─────────\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int, int, int, int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    return min(xs), min(ys), max(xs) - min(xs), max(ys) - min(ys)\n",
    "\n",
    "def cluster_regions(boxes: List[WordBox], n_clusters: int) \\\n",
    "        -> List[Tuple[int, int, int, int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    coords = np.column_stack([[b.cx for b in boxes], [b.cy for b in boxes]])\n",
    "    labels = AgglomerativeClustering(n_clusters=n_clusters).fit_predict(coords)\n",
    "    reg = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, labels) if l == lbl]\n",
    "        reg.append(compute_bbox(members))\n",
    "    reg.sort(key=lambda r: (r[1], r[0]))  # sort top→bottom, left→right\n",
    "    return reg\n",
    "\n",
    "def extract_regions(boxes: List[WordBox], shape: Tuple[int, int]) \\\n",
    "        -> List[Tuple[int, int, int, int]]:\n",
    "    h, w = shape\n",
    "    header_cut = int(h * HEADER_RATIO)\n",
    "    footer_cut = int(h * FOOTER_RATIO)\n",
    "\n",
    "    header = [b for b in boxes if b.cy < header_cut]\n",
    "    body   = [b for b in boxes if header_cut <= b.cy <= footer_cut]\n",
    "    footer = [b for b in boxes if b.cy > footer_cut]\n",
    "\n",
    "    regions: List[Tuple[int, int, int, int]] = []\n",
    "    regions += cluster_regions(header, 3)\n",
    "    regions += cluster_regions(body,   2)\n",
    "    if footer:\n",
    "        regions.append(compute_bbox(footer))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(w, x + rw + PADDING)\n",
    "        yb = min(h, y + rh + PADDING)\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "# ───────── REGION OCR ─────────\n",
    "def ocr_region(bgr: np.ndarray, region: Tuple[int, int, int, int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = bgr[y : y + rh, x : x + rw]\n",
    "    return pytesseract.image_to_string(crop, config=TS_CONFIG).splitlines()\n",
    "\n",
    "# ───────── PER‑PAGE PIPELINE ─────────\n",
    "def process_page(img_path: Path) -> List[str]:\n",
    "    try:\n",
    "        logging.info(f\"→ {img_path.name}\")\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            logging.warning(f\"Cannot read {img_path}\")\n",
    "            return []\n",
    "\n",
    "        prep    = preprocess(img)\n",
    "        boxes   = get_word_boxes(prep)\n",
    "        regions = extract_regions(boxes, img.shape[:2])\n",
    "\n",
    "        entries, current = [], None\n",
    "        for reg in regions:\n",
    "            for line in ocr_region(img, reg):\n",
    "                raw = line.strip().replace(\"|\", \"\")\n",
    "                if not raw:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if raw.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = raw\n",
    "                elif current:\n",
    "                    current += \" \" + raw\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "        logging.info(f\"  {len(entries)} entries\")\n",
    "        return entries\n",
    "\n",
    "    except Exception as exc:\n",
    "        logging.error(f\"[{img_path.name}] {exc}\", exc_info=True)\n",
    "        return []\n",
    "\n",
    "# ───────── EXECUTION HELPERS ─────────\n",
    "def run_with_executor(executor_cls: type[Executor]) -> List[str]:\n",
    "    entries: List[str] = []\n",
    "    with executor_cls() as ex:\n",
    "        futs = {ex.submit(process_page, BASE_DIR / n): n for n in IMAGE_NAMES}\n",
    "        for fut in as_completed(futs):\n",
    "            entries.extend(fut.result())\n",
    "    return entries\n",
    "\n",
    "def main() -> None:\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "\n",
    "    for executor in (ProcessPoolExecutor, ThreadPoolExecutor):\n",
    "        try:\n",
    "            all_entries = run_with_executor(executor)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{executor.__name__} failed → {e}\")\n",
    "    else:  # if both pools fail, run single‑threaded\n",
    "        logging.warning(\"Falling back to single‑thread mode.\")\n",
    "        all_entries = [e for n in IMAGE_NAMES\n",
    "                       for e in process_page(BASE_DIR / n)]\n",
    "\n",
    "    # deduplicate + write\n",
    "    seen = set()\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ent in all_entries:\n",
    "            if ent not in seen:\n",
    "                f.write(ent + \"\\n\")\n",
    "                seen.add(ent)\n",
    "\n",
    "    logging.info(f\"✓ Saved {len(seen)} unique entries → {OUTPUT_FILE}\")\n",
    "\n",
    "# ───────── RUN ─────────\n",
    "if __name__ == \"__main__\":\n",
    "    if not shutil.which(\"tesseract\"):\n",
    "        logging.warning(\"Tesseract binary not found on PATH; install or add it.\")\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b670959-d69f-4f6a-9703-9a411bd8af36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRing 104.png…\n",
      "OCRing 105.png…\n",
      "OCRing 106.png…\n",
      "OCRing 107.png…\n",
      "OCRing 108.png…\n",
      "✅ Wrote 186 entries to /Users/darshilshukla/Desktop/text.txt\n",
      "⚠️ No address parsed for entry: \" allen (Agnes) driver Widholm Transfer 1612\n",
      "✅ Wrote 186 parsed entries to /Users/darshilshukla/Desktop/combined.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Full pipeline: Image → text.txt → combined.json using only pytesseract.\n",
    "\n",
    "1) Runs pytesseract on images 104–108 to produce text entries (text.txt)\n",
    "2) Parses text.txt into structured JSON (combined.json)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR        = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES     = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS     = [BASE_DIR / n for n in IMAGE_NAMES]\n",
    "TEXT_FILE       = BASE_DIR / \"text.txt\"\n",
    "OUTPUT_JSON     = BASE_DIR / \"combined.json\"\n",
    "DIRECTORY_NAME  = \"Minneapolis 1900\"\n",
    "TS_CONFIG       = \"--oem 3 --psm 6\"\n",
    "\n",
    "# ——— PARSING PATTERNS ———\n",
    "SPOUSE_PATTERN = re.compile(r\"\\(([^)]+)\\)\")\n",
    "ADDR_PATTERN   = re.compile(\n",
    "    r\"(?P<number>\\d+)\\s+\"\n",
    "    r\"(?P<street>[A-Za-z0-9\\.\\s]+?)\"\n",
    "    r\"(?:\\s*(?P<apt>apt\\s*\\d+))?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "OCCUP_KEYWORDS = [\n",
    "    \"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\n",
    "    \"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\n",
    "    \"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"\n",
    "]\n",
    "\n",
    "def ocr_image(path: Path):\n",
    "    \"\"\"Run pytesseract OCR and return cleaned lines.\"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "def group_entries(lines: list[str]):\n",
    "    \"\"\"Group lines into entries starting with '\"' and splitting on '|'.\"\"\"\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        for seg in line.split(\"|\"):\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += \" \" + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "def parse_entry(entry: str, page: int):\n",
    "    \"\"\"Parse a single entry string into the JSON schema.\"\"\"\n",
    "    text = entry.lstrip('\"').strip()\n",
    "    tokens = text.split()\n",
    "    # Names\n",
    "    first = tokens[0] if tokens else \"\"\n",
    "    last  = tokens[1] if len(tokens) > 1 else \"\"\n",
    "    # Spouse\n",
    "    m = SPOUSE_PATTERN.search(text)\n",
    "    spouse = m.group(1) if m else None\n",
    "    # Address\n",
    "    m2 = ADDR_PATTERN.search(text)\n",
    "    if m2:\n",
    "        number = m2.group(\"number\")\n",
    "        street = m2.group(\"street\").strip()\n",
    "        apt    = m2.group(\"apt\")\n",
    "    else:\n",
    "        # Fallback: take first numeric token\n",
    "        number = next((tok for tok in tokens if tok.isdigit()), \"\")\n",
    "        idx = tokens.index(number) if number in tokens else 2\n",
    "        street = \" \".join(tokens[idx+1:idx+4]) if len(tokens) > idx+1 else \"\"\n",
    "        apt = None\n",
    "    # Occupation\n",
    "    occupation = next(\n",
    "        (kw.title() for kw in OCCUP_KEYWORDS if re.search(rf\"\\b{kw}\\b\", text, re.IGNORECASE)),\n",
    "        None\n",
    "    )\n",
    "    # CompanyName: tokens between names and address, minus occupation\n",
    "    addr_idx = tokens.index(number) if number in tokens else len(tokens)\n",
    "    middle = tokens[2:addr_idx]\n",
    "    if occupation:\n",
    "        middle = [tok for tok in middle if occupation.lower() not in tok.lower()]\n",
    "    company = \" \".join(middle) if middle else None\n",
    "\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number,\n",
    "            \"StreetName\": street,\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": page\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Step 1: OCR → text.txt\n",
    "    all_lines = []\n",
    "    for img in IMAGE_PATHS:\n",
    "        if img.exists():\n",
    "            print(f\"OCRing {img.name}…\")\n",
    "            all_lines += ocr_image(img)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing image: {img}\")\n",
    "    entries = group_entries(all_lines)\n",
    "    TEXT_FILE.write_text(\"\\n\".join(entries), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(entries)} entries to {TEXT_FILE}\")\n",
    "\n",
    "    # Step 2: Parse → combined.json\n",
    "    records = []\n",
    "    for ent in entries:\n",
    "        rec = parse_entry(ent, page=None)\n",
    "        if not rec[\"HomeAddress\"][\"StreetName\"]:\n",
    "            print(f\"⚠️ No address parsed for entry: {ent}\")\n",
    "        records.append(rec)\n",
    "    OUTPUT_JSON.write_text(json.dumps(records, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✅ Wrote {len(records)} parsed entries to {OUTPUT_JSON}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1551de2-fc55-4838-a28d-fe1ead376141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: pytesseract in ./anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: opencv-python in ./anaconda3/lib/python3.12/site-packages (4.10.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in ./anaconda3/lib/python3.12/site-packages (from pytesseract) (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow pytesseract opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace7e3e7-8028-4b7c-9f53-38a736ea8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 104.png …\n",
      "Processing 105.png …\n",
      "Processing 106.png …\n",
      "Processing 107.png …\n",
      "Processing 108.png …\n",
      "✅ Saved 186 entries → /Users/darshilshukla/Desktop/text.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Pillow + OpenCV Box‑based OCR → text.txt (final newline fix)\n",
    "\"\"\"\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# CONFIG\n",
    "BASE_DIR = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE = BASE_DIR / \"text.txt\"\n",
    "TS_CONFIG = \"--oem 3 --psm 6\"\n",
    "PADDING = 5\n",
    "\n",
    "# Preprocess image ➜ binary numpy array\n",
    "def preprocess(img_pil: Image.Image) -> np.ndarray:\n",
    "    gray = ImageOps.grayscale(img_pil).filter(ImageFilter.SHARPEN)\n",
    "    bw = gray.point(lambda x: 0 if x < 128 else 255, mode=\"1\")\n",
    "    return np.array(bw, dtype=np.uint8)\n",
    "\n",
    "# Detect block boxes\n",
    "def detect_boxes(bw: np.ndarray):\n",
    "    inv = cv2.bitwise_not(bw)\n",
    "    hor_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    hor = cv2.dilate(inv, hor_kernel, iterations=2)\n",
    "    ver_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 20))\n",
    "    ver = cv2.dilate(hor, ver_kernel, iterations=2)\n",
    "    contours, _ = cv2.findContours(ver, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    h, w = bw.shape\n",
    "    for c in contours:\n",
    "        x, y, cw, ch = cv2.boundingRect(c)\n",
    "        if cw * ch < 1000:\n",
    "            continue\n",
    "        xa = max(0, x - PADDING)\n",
    "        ya = max(0, y - PADDING)\n",
    "        xb = min(w, x + cw + PADDING)\n",
    "        yb = min(h, y + ch + PADDING)\n",
    "        boxes.append((xa, ya, xb - xa, yb - ya))\n",
    "    boxes.sort(key=lambda b: (b[1], b[0]))\n",
    "    return boxes\n",
    "\n",
    "# OCR a single box\n",
    "def ocr_box(img_pil: Image.Image, box):\n",
    "    x, y, w, h = box\n",
    "    crop = img_pil.crop((x, y, x + w, y + h))\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "# Group lines into directory entries\n",
    "def group_entries(lines):\n",
    "    entries, current = [], None\n",
    "    for line in lines:\n",
    "        for seg in line.split(\"|\"):\n",
    "            seg = seg.strip()\n",
    "            if not seg:\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                    current = None\n",
    "                continue\n",
    "            if seg.startswith('\"'):\n",
    "                if current:\n",
    "                    entries.append(current)\n",
    "                current = seg\n",
    "            else:\n",
    "                if current is not None:\n",
    "                    current += \" \" + seg\n",
    "    if current:\n",
    "        entries.append(current)\n",
    "    return entries\n",
    "\n",
    "# MAIN\n",
    "def main():\n",
    "    all_lines: list[str] = []\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        if not img_path.exists():\n",
    "            print(f\"⚠️ Missing image {img_path}\")\n",
    "            continue\n",
    "        print(f\"Processing {img_path.name} …\")\n",
    "        img_pil = Image.open(img_path)\n",
    "        bw = preprocess(img_pil)\n",
    "        boxes = detect_boxes(bw)\n",
    "        for box in boxes:\n",
    "            all_lines.extend(ocr_box(img_pil, box))\n",
    "\n",
    "    entries = group_entries(all_lines)\n",
    "    OUTPUT_FILE.parent.mkdir(exist_ok=True)\n",
    "    with OUTPUT_FILE.open('w', encoding='utf-8') as f:\n",
    "        for ent in entries:\n",
    "            f.write(ent + \"\\n\")\n",
    "    print(f\"✅ Saved {len(entries)} entries → {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1af6ab1-6c4b-47ff-bbdc-3831de6fda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed: 104.png → 31 entries\n",
      "✅ Processed: 105.png → 18 entries\n",
      "✅ Processed: 106.png → 23 entries\n",
      "✅ Processed: 107.png → 37 entries\n",
      "\n",
      "📄 Output written to: /Users/darshilshukla/Desktop/output/combined_entries.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "INPUT_DIR = Path(\"/Users/darshilshukla/Desktop/\")\n",
    "OUTPUT_FILE = Path(\"/Users/darshilshukla/Desktop/output/combined_entries.txt\")\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def extract_sorted_text_boxes(image_path):\n",
    "    \"\"\"Run OCR and return boxes sorted top-down, left-right\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "    n_boxes = len(data['text'])\n",
    "\n",
    "    boxes = []\n",
    "    for i in range(n_boxes):\n",
    "        if int(data['conf'][i]) > 20 and data['text'][i].strip():\n",
    "            left, top, width, height = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "            word = data['text'][i].strip()\n",
    "            boxes.append((left, top, word))\n",
    "\n",
    "    # Sort top-to-bottom, then left-to-right\n",
    "    boxes.sort(key=lambda b: (b[1], b[0]))\n",
    "    return boxes\n",
    "\n",
    "def assemble_entries(boxes):\n",
    "    \"\"\"Assemble OCR text into entries starting with `\"` and ignoring text after `|`\"\"\"\n",
    "    lines = []\n",
    "    line = \"\"\n",
    "    current_y = None\n",
    "\n",
    "    for i, (x, y, word) in enumerate(boxes):\n",
    "        if current_y is None or abs(y - current_y) > 15:\n",
    "            if line.strip():\n",
    "                lines.append(line.strip())\n",
    "            line = word\n",
    "            current_y = y\n",
    "        else:\n",
    "            line += \" \" + word\n",
    "    if line.strip():\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    # Now clean and extract full entries\n",
    "    entries = []\n",
    "    current_entry = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(\"|\")[0].strip()  # stop reading at \"|\"\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith('\"'):\n",
    "            if current_entry:\n",
    "                entries.append(current_entry.strip())\n",
    "            current_entry = line\n",
    "        else:\n",
    "            current_entry += \" \" + line\n",
    "    if current_entry:\n",
    "        entries.append(current_entry.strip())\n",
    "    return entries\n",
    "\n",
    "def main():\n",
    "    all_entries = []\n",
    "    for i in range(104, 108):\n",
    "        img_path = INPUT_DIR / f\"{i}.png\"\n",
    "        if not img_path.exists():\n",
    "            print(f\"⚠️ Image not found: {img_path}\")\n",
    "            continue\n",
    "        boxes = extract_sorted_text_boxes(img_path)\n",
    "        entries = assemble_entries(boxes)\n",
    "        all_entries.extend(entries)\n",
    "        print(f\"✅ Processed: {img_path.name} → {len(entries)} entries\")\n",
    "\n",
    "    # Write to text file\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ent in all_entries:\n",
    "            f.write(ent + \"\\n\")\n",
    "\n",
    "    print(f\"\\n📄 Output written to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff9fb51-7882-4e3a-9100-cbf07418aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OCR entries saved to: /Users/darshilshukla/Desktop/text_another_one.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch OCR for multiple directory pages → single text file using user’s default Desktop path.\n",
    "Extracts entries that start with '\"', continues until a '|' partition, removes all '|' characters,\n",
    "and writes each entry on a new line in text.txt.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ——— CONFIGURATION ———\n",
    "BASE_DIR      = Path(\"/Users/darshilshukla/Desktop\")\n",
    "IMAGE_NAMES   = [\"104.png\", \"105.png\", \"106.png\", \"107.png\", \"108.png\"]\n",
    "IMAGE_PATHS   = [BASE_DIR / name for name in IMAGE_NAMES]\n",
    "OUTPUT_FILE   = BASE_DIR / \"text_another_one.txt\"\n",
    "TS_CONFIG     = \"--oem 3 --psm 6\"\n",
    "PADDING       = 10\n",
    "MARGIN_RATIO  = 0.15\n",
    "HEADER_RATIO  = 0.18\n",
    "FOOTER_RATIO  = 0.82\n",
    "\n",
    "@dataclass\n",
    "class WordBox:\n",
    "    text: str\n",
    "    left: int\n",
    "    top: int\n",
    "    width: int\n",
    "    height: int\n",
    "    cx: float\n",
    "    cy: float\n",
    "\n",
    "# Extract word-level boxes via Tesseract\n",
    "def get_word_boxes(gray: np.ndarray) -> List[WordBox]:\n",
    "    data = pytesseract.image_to_data(\n",
    "        gray, output_type=pytesseract.Output.DICT, config=TS_CONFIG\n",
    "    )\n",
    "    boxes = []\n",
    "    for i, txt in enumerate(data['text']):\n",
    "        txt = txt.strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "        try:\n",
    "            conf = float(data['conf'][i])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if conf < 30:\n",
    "            continue\n",
    "        l, t = data['left'][i], data['top'][i]\n",
    "        w, h = data['width'][i], data['height'][i]\n",
    "        cx, cy = l + w/2, t + h/2\n",
    "        boxes.append(WordBox(txt, l, t, w, h, cx, cy))\n",
    "    return boxes\n",
    "\n",
    "# Compute bounding box for a list of WordBoxes\n",
    "def compute_bbox(boxes: List[WordBox]) -> Tuple[int,int,int,int]:\n",
    "    xs = [b.left for b in boxes] + [b.left + b.width for b in boxes]\n",
    "    ys = [b.top  for b in boxes] + [b.top  + b.height for b in boxes]\n",
    "    x1, x2 = min(xs), max(xs)\n",
    "    y1, y2 = min(ys), max(ys)\n",
    "    return x1, y1, x2 - x1, y2 - y1\n",
    "\n",
    "# Cluster WordBoxes into columns (headers/body)\n",
    "def cluster_stripe(boxes: List[WordBox], n_clusters: int) -> List[Tuple[int,int,int,int]]:\n",
    "    if not boxes:\n",
    "        return []\n",
    "    X = np.array([[b.cx] for b in boxes])\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    regions = []\n",
    "    for lbl in range(n_clusters):\n",
    "        members = [b for b, l in zip(boxes, km.labels_) if l == lbl]\n",
    "        regions.append(compute_bbox(members))\n",
    "    regions.sort(key=lambda r: r[0])\n",
    "    return regions\n",
    "\n",
    "# Extract seven regions per page: margin, 3 header cols, 2 body cols, footer\n",
    "def extract_regions(boxes: List[WordBox], img_shape: Tuple[int,int]) -> List[Tuple[int,int,int,int]]:\n",
    "    h, w = img_shape\n",
    "    margin_thresh = w * MARGIN_RATIO\n",
    "    margin_boxes = [b for b in boxes if b.cx < margin_thresh]\n",
    "    rem_boxes    = [b for b in boxes if b.cx >= margin_thresh]\n",
    "    header_h     = h * HEADER_RATIO\n",
    "    footer_h     = h * FOOTER_RATIO\n",
    "\n",
    "    header_boxes = [b for b in rem_boxes if b.cy < header_h]\n",
    "    body_boxes   = [b for b in rem_boxes if header_h <= b.cy <= footer_h]\n",
    "    footer_boxes = [b for b in rem_boxes if b.cy > footer_h]\n",
    "\n",
    "    regions = []\n",
    "    if margin_boxes:\n",
    "        regions.append(compute_bbox(margin_boxes))\n",
    "    regions += cluster_stripe(header_boxes, 3)\n",
    "    regions += cluster_stripe(body_boxes,   2)\n",
    "    if footer_boxes:\n",
    "        regions.append(compute_bbox(footer_boxes))\n",
    "\n",
    "    padded = []\n",
    "    for x, y, rw, rh in regions:\n",
    "        xa = max(0, int(x - PADDING))\n",
    "        ya = max(0, int(y - PADDING))\n",
    "        xb = min(w, int(x + rw + PADDING))\n",
    "        yb = min(h, int(y + rh + PADDING))\n",
    "        padded.append((xa, ya, xb - xa, yb - ya))\n",
    "    return padded\n",
    "\n",
    "# OCR a region and return its text lines\n",
    "def ocr_region(img: np.ndarray, region: Tuple[int,int,int,int]) -> List[str]:\n",
    "    x, y, rw, rh = region\n",
    "    crop = img[y:y+rh, x:x+rw]\n",
    "    text = pytesseract.image_to_string(crop, config=TS_CONFIG)\n",
    "    return text.splitlines()\n",
    "\n",
    "# Main: process images, parse entries starting with '\"', end on '|', remove all '|'\n",
    "\n",
    "def main():\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    entries: List[str] = []\n",
    "\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        word_boxes = get_word_boxes(gray)\n",
    "        regions    = extract_regions(word_boxes, img.shape[:2])\n",
    "\n",
    "        current: str = None\n",
    "        for region in regions:\n",
    "            lines = ocr_region(img, region)\n",
    "            for line in lines:\n",
    "                raw = line.strip().replace('|', '')\n",
    "                if not raw:\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                        current = None\n",
    "                    continue\n",
    "                if raw.startswith('\"'):\n",
    "                    if current:\n",
    "                        entries.append(current)\n",
    "                    current = raw\n",
    "                else:\n",
    "                    if current:\n",
    "                        current += ' ' + raw\n",
    "        if current:\n",
    "            entries.append(current)\n",
    "\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_f:\n",
    "        for ent in entries:\n",
    "            out_f.write(ent + \"\\n\")\n",
    "\n",
    "    print(f\"All OCR entries saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcbf5b3a-af76-46d5-96bc-027daf9e6b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./anaconda3/lib/python3.12/site-packages (3.8.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./anaconda3/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./anaconda3/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./anaconda3/lib/python3.12/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./anaconda3/lib/python3.12/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Requirement already satisfied: cloudpickle>=2.2.0 in ./anaconda3/lib/python3.12/site-packages (from srsly<3.0.0,>=2.4.3->spacy) (3.0.0)\n",
      "Requirement already satisfied: ujson>=1.35 in ./anaconda3/lib/python3.12/site-packages (from srsly<3.0.0,>=2.4.3->spacy) (5.10.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.3.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in ./anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Using cached numpy-2.3.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.1 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.1 which is incompatible.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.1 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed numpy-2.3.1\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "✅ Parsed 248 entries to /Users/darshilshukla/Desktop/combined_lastone.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Parser: Text file → structured JSON (paths in code) with auto-install of spaCy model\n",
    "\n",
    "Reads a text file where each line starts with '\"' and represents a directory entry.\n",
    "Extracts:\n",
    "  - FirstName, LastName\n",
    "  - Spouse (in parentheses)\n",
    "  - Occupation (keyword lookup + NER fallback)\n",
    "  - CompanyName (remaining ORG entities)\n",
    "  - HomeAddress (number, street, apt/unit)\n",
    "  - DirectoryName (fixed)\n",
    "  - PageNumber (fixed or None)\n",
    "\n",
    "Outputs combined JSON file.\n",
    "\n",
    "Usage:\n",
    "  pip install spacy\n",
    "  python text_to_json.py\n",
    "\"\"\"\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# ——— CONFIGURATION: set file paths here ———\n",
    "INPUT_FILE = Path(\"/Users/darshilshukla/Desktop/text_another_one.txt\")\n",
    "OUTPUT_FILE = Path(\"/Users/darshilshukla/Desktop/combined_lastone.json\")\n",
    "\n",
    "DIRECTORY_NAME = \"Minneapolis 1900\"\n",
    "PAGE_NUMBER = None  # or set to a specific page if known\n",
    "OCCUP_KEYWORDS = [\n",
    "    \"salesman\",\"merchant\",\"clerk\",\"engineer\",\"teacher\",\n",
    "    \"laborer\",\"driver\",\"barber\",\"baker\",\"physician\",\n",
    "    \"carpenter\",\"nurse\",\"pntr\",\"meat ctr\"\n",
    "]\n",
    "ADDR_RE = re.compile(\n",
    "    r\"(?P<number>\\d+)\\s+\"\n",
    "    r\"(?P<street>[A-Za-z0-9\\.\\s]+?)\"\n",
    "    r\"(?:\\s*(?P<apt>apt\\s*\\d+))?$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "SPOUSE_RE = re.compile(r\"\\(([^)]+)\\)\")\n",
    "\n",
    "# Ensure spaCy and model installed\n",
    "try:\n",
    "    import spacy\n",
    "    from spacy.cli import download as spacy_download\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except (ImportError, OSError):\n",
    "    # Install spaCy if missing\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"spacy\"] )\n",
    "    except subprocess.CalledProcessError:\n",
    "        pass\n",
    "    # Download model\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"] )\n",
    "    except subprocess.CalledProcessError:\n",
    "        pass\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def parse_line(line: str) -> dict:\n",
    "    text = line.lstrip('\"').strip()\n",
    "    doc = nlp(text)\n",
    "    # FirstName / LastName\n",
    "    first = last = None\n",
    "    persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "    if persons:\n",
    "        parts = persons[0].split()\n",
    "        first, last = parts[0], parts[-1] if len(parts)>1 else None\n",
    "    else:\n",
    "        toks = text.split()\n",
    "        first = toks[0] if toks else None\n",
    "        last = toks[1] if len(toks)>1 else None\n",
    "    # Spouse\n",
    "    spouse = None\n",
    "    m_sp = SPOUSE_RE.search(text)\n",
    "    if m_sp:\n",
    "        spouse = m_sp.group(1)\n",
    "    # Address\n",
    "    number = street = apt = None\n",
    "    m_addr = ADDR_RE.search(text)\n",
    "    if m_addr:\n",
    "        number = m_addr.group('number')\n",
    "        street = m_addr.group('street').strip()\n",
    "        apt = m_addr.group('apt')\n",
    "    # Occupation\n",
    "    occupation = None\n",
    "    for kw in OCCUP_KEYWORDS:\n",
    "        if re.search(rf\"\\b{kw}\\b\", text, re.IGNORECASE):\n",
    "            occupation = kw.title()\n",
    "            break\n",
    "    # CompanyName from ORG\n",
    "    orgs = [ent.text for ent in doc.ents if ent.label_ == 'ORG']\n",
    "    company = orgs[-1] if orgs else None\n",
    "\n",
    "    return {\n",
    "        \"FirstName\": first,\n",
    "        \"LastName\": last,\n",
    "        \"Spouse\": spouse,\n",
    "        \"Occupation\": occupation,\n",
    "        \"CompanyName\": company,\n",
    "        \"HomeAddress\": {\n",
    "            \"StreetNumber\": number,\n",
    "            \"StreetName\": street,\n",
    "            \"ApartmentOrUnit\": apt,\n",
    "            \"ResidenceIndicator\": \"h\"\n",
    "        },\n",
    "        \"WorkAddress\": None,\n",
    "        \"Telephone\": None,\n",
    "        \"DirectoryName\": DIRECTORY_NAME,\n",
    "        \"PageNumber\": PAGE_NUMBER\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not INPUT_FILE.exists():\n",
    "        print(f\"Input file not found: {INPUT_FILE}\")\n",
    "        sys.exit(1)\n",
    "    lines = INPUT_FILE.read_text(encoding='utf-8').splitlines()\n",
    "    records = []\n",
    "    for line in lines:\n",
    "        if line.strip().startswith('\"'):\n",
    "            rec = parse_line(line)\n",
    "            records.append(rec)\n",
    "    OUTPUT_FILE.write_text(json.dumps(records, indent=2), encoding='utf-8')\n",
    "    print(f\"✅ Parsed {len(records)} entries to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea81d9b-f180-48e1-994d-8eb05ed94953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
